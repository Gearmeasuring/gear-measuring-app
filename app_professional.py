"""
================================================================================
é½¿è½®æ³¢çº¹åº¦è½¯ä»¶ - å®Œæ•´ä¸“ä¸šç‰ˆ (ä½¿ç”¨ gear_analysis_refactored)
================================================================================

ä½¿ç”¨ gear_analysis_refactored æ¨¡å—çš„å®Œæ•´åŠŸèƒ½
æ”¯æŒç”¨æˆ·æ³¨å†Œå’Œç™»å½•
"""

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.colors import LinearSegmentedColormap
import sys
import os
import re
from datetime import datetime
from io import BytesIO
import tempfile
import pandas as pd

# è®¾ç½®ä¸­æ–‡å­—ä½“ - ä½¿ç”¨ç³»ç»Ÿå¯ç”¨å­—ä½“
import matplotlib.font_manager as fm

# å°è¯•æŸ¥æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
def get_chinese_font():
    """è·å–ç³»ç»Ÿä¸­å¯ç”¨çš„ä¸­æ–‡å­—ä½“"""
    chinese_fonts = ['SimHei', 'Microsoft YaHei', 'SimSun', 'NSimSun', 'FangSong', 'KaiTi',
                     'WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'Source Han Sans CN',
                     'AR PL UMing CN', 'Droid Sans Fallback', 'DejaVu Sans']

    available_fonts = [f.name for f in fm.fontManager.ttflist]

    for font in chinese_fonts:
        if font in available_fonts:
            return font

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œè¿”å›é»˜è®¤å­—ä½“
    return 'DejaVu Sans'

chinese_font = get_chinese_font()
rcParams['font.sans-serif'] = [chinese_font, 'DejaVu Sans', 'Arial Unicode MS']
rcParams['axes.unicode_minus'] = False

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ç”¨æˆ·è®¤è¯æ¨¡å—
from auth import (
    init_session_state, login_page, logout, get_current_user,
    register_user, login_user, change_password, admin_panel, is_admin
)

# å¯¼å…¥ gear_analysis_refactored æ¨¡å—
try:
    from gear_analysis_refactored.models.gear_data import (
        GearMeasurementData, GearBasicInfo, MeasurementData, PitchData
    )
    from gear_analysis_refactored.utils.file_parser import parse_mka_file
    GEAR_ANALYSIS_AVAILABLE = True
except ImportError as e:
    GEAR_ANALYSIS_AVAILABLE = False

# å¯¼å…¥æœ¬åœ°åˆ†æå™¨ä½œä¸ºå¤‡ç”¨
from ripple_waviness_analyzer import RippleWavinessAnalyzer

# å¯¼å…¥PDFæŠ¥å‘Šç”Ÿæˆå™¨
try:
    from klingelnberg_report_generator import KlingelnbergReportGenerator
    PDF_GENERATOR_AVAILABLE = True
except ImportError as e:
    print(f"KlingelnbergReportGenerator import error: {e}")
    PDF_GENERATOR_AVAILABLE = False

# åˆå§‹åŒ–ç”¨æˆ·è®¤è¯çŠ¶æ€
init_session_state()

# å¦‚æœç”¨æˆ·æœªç™»å½•ï¼Œæ˜¾ç¤ºç™»å½•é¡µé¢
if not st.session_state.authenticated:
    login_page()
    st.stop()

# ç”¨æˆ·å·²ç™»å½•ï¼Œæ˜¾ç¤ºä¸»åº”ç”¨
st.set_page_config(
    page_title="é½¿è½®æµ‹é‡åˆ†æç³»ç»Ÿ - ä¸“ä¸šç‰ˆ",
    page_icon="âš™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== è‡ªå®šä¹‰CSSæ ·å¼ ==========
st.markdown("""
<style>
    /* å¯¼å…¥Googleå­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;700&display=swap');
    
    /* å…¨å±€æ ·å¼ */
    * {
        font-family: 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    }
    
    /* ä¸»è‰²è°ƒ */
    :root {
        --primary-color: #2563eb;
        --primary-dark: #1d4ed8;
        --primary-light: #3b82f6;
        --secondary-color: #f59e0b;
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --danger-color: #ef4444;
        --info-color: #06b6d4;
        --gray-50: #f9fafb;
        --gray-100: #f3f4f6;
        --gray-200: #e5e7eb;
        --gray-300: #d1d5db;
        --gray-600: #4b5563;
        --gray-700: #374151;
        --gray-800: #1f2937;
        --gray-900: #111827;
    }
    
    /* ä¸»å®¹å™¨ */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        max-width: 1400px;
    }
    
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 2.8rem;
        font-weight: 700;
        text-align: center;
        padding: 1.5rem;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        letter-spacing: 2px;
    }
    
    .sub-title {
        font-size: 1.2rem;
        color: #6b7280;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 400;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .card {
        background: #ffffff;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 0.75rem 0;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1), 0 1px 2px rgba(0, 0, 0, 0.06);
        border: 1px solid #e5e7eb;
        transition: all 0.3s ease;
    }
    
    .card:hover {
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        transform: translateY(-2px);
    }
    
    .card-header {
        font-size: 1.1rem;
        font-weight: 600;
        color: #1f2937;
        border-bottom: 2px solid #e5e7eb;
        padding-bottom: 0.75rem;
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
    }
    
    .card-header::before {
        content: '';
        width: 4px;
        height: 20px;
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
        border-radius: 2px;
        margin-right: 10px;
    }
    
    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        padding: 1.25rem;
        text-align: center;
        margin: 0.25rem;
        box-shadow: 0 4px 6px rgba(102, 126, 234, 0.3);
    }
    
    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        line-height: 1.2;
    }
    
    .metric-label {
        font-size: 0.85rem;
        opacity: 0.9;
        margin-top: 0.25rem;
    }
    
    /* çŠ¶æ€æ ‡ç­¾ */
    .status-excellent {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
        padding: 0.35rem 1rem;
        border-radius: 50px;
        font-weight: 600;
        font-size: 0.9rem;
        box-shadow: 0 2px 4px rgba(16, 185, 129, 0.3);
    }
    
    .status-good {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
        color: white;
        padding: 0.35rem 1rem;
        border-radius: 50px;
        font-weight: 600;
        font-size: 0.9rem;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.3);
    }
    
    .status-warning {
        background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
        color: white;
        padding: 0.35rem 1rem;
        border-radius: 50px;
        font-weight: 600;
        font-size: 0.9rem;
        box-shadow: 0 2px 4px rgba(245, 158, 11, 0.3);
    }
    
    .status-danger {
        background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
        color: white;
        padding: 0.35rem 1rem;
        border-radius: 50px;
        font-weight: 600;
        font-size: 0.9rem;
        box-shadow: 0 2px 4px rgba(239, 68, 68, 0.3);
    }
    
    /* æ•°æ®è¡¨æ ¼æ ·å¼ */
    .stDataFrame {
        border: none !important;
        border-radius: 12px;
        overflow: hidden;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    .stDataFrame table {
        border-collapse: separate !important;
        border-spacing: 0 !important;
    }
    
    .stDataFrame th {
        background: linear-gradient(135deg, #1f77b4 0%, #2563eb 100%) !important;
        color: white !important;
        font-weight: 600 !important;
        padding: 0.875rem 1rem !important;
        text-transform: uppercase;
        font-size: 0.75rem;
        letter-spacing: 0.5px;
    }
    
    .stDataFrame td {
        padding: 0.75rem 1rem !important;
        border-bottom: 1px solid #e5e7eb !important;
        font-size: 0.9rem;
    }
    
    .stDataFrame tr:nth-child(even) {
        background-color: #f9fafb !important;
    }
    
    .stDataFrame tr:hover {
        background-color: #f3f4f6 !important;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    section[data-testid="stSidebar"] {
        background: linear-gradient(180deg, #f8fafc 0%, #e2e8f0 100%) !important;
    }
    
    section[data-testid="stSidebar"] .stMarkdown,
    section[data-testid="stSidebar"] .stRadio > label,
    section[data-testid="stSidebar"] label {
        color: #1e293b !important;
        font-weight: 500 !important;
    }
    
    section[data-testid="stSidebar"] h1,
    section[data-testid="stSidebar"] h2,
    section[data-testid="stSidebar"] h3 {
        color: #1e293b !important;
        font-weight: 600 !important;
    }
    
    section[data-testid="stSidebar"] .stRadio > div {
        background: rgba(255, 255, 255, 0.7);
        border-radius: 12px;
        padding: 0.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    section[data-testid="stSidebar"] .stRadio > div > label {
        background: transparent;
        border-radius: 8px;
        padding: 0.75rem 1rem;
        margin: 0.25rem 0;
        transition: all 0.2s ease;
        color: #334155 !important;
        font-weight: 500 !important;
    }
    
    section[data-testid="stSidebar"] .stRadio > div > label:hover {
        background: rgba(102, 126, 234, 0.1);
        color: #667eea !important;
    }
    
    section[data-testid="stSidebar"] .stRadio > div > label[data-checked="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white !important;
        font-weight: 600 !important;
        box-shadow: 0 2px 4px rgba(102, 126, 234, 0.3);
    }
    
    section[data-testid="stSidebar"] .stSuccess {
        background: rgba(16, 185, 129, 0.1);
        border: 1px solid rgba(16, 185, 129, 0.3);
        border-radius: 8px;
        color: #059669 !important;
    }
    
    section[data-testid="stSidebar"] .stButton > button {
        background: linear-gradient(135deg, #374151 0%, #1f2937 100%);
        border: 1px solid #4b5563;
        color: white;
        border-radius: 8px;
        font-weight: 500;
        transition: all 0.2s ease;
    }
    
    section[data-testid="stSidebar"] .stButton > button:hover {
        background: linear-gradient(135deg, #4b5563 0%, #374151 100%);
        border-color: #6b7280;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
        border: none;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
    }
    
    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
    }
    
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
    }
    
    .stProgress > div > div {
        background: #e5e7eb;
        border-radius: 10px;
        height: 8px;
    }
    
    /* é—®é¢˜åˆ—è¡¨æ ·å¼ */
    .issue-critical {
        border-left: 4px solid #ef4444;
        background: linear-gradient(90deg, rgba(239, 68, 68, 0.1) 0%, transparent 100%);
        padding: 0.75rem 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
    }
    
    .issue-warning {
        border-left: 4px solid #f59e0b;
        background: linear-gradient(90deg, rgba(245, 158, 11, 0.1) 0%, transparent 100%);
        padding: 0.75rem 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
    }
    
    .issue-info {
        border-left: 4px solid #06b6d4;
        background: linear-gradient(90deg, rgba(6, 182, 212, 0.1) 0%, transparent 100%);
        padding: 0.75rem 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
    }
    
    .issue-success {
        border-left: 4px solid #10b981;
        background: linear-gradient(90deg, rgba(16, 185, 129, 0.1) 0%, transparent 100%);
        padding: 0.75rem 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
    }
    
    /* å›¾è¡¨å®¹å™¨ */
    .chart-container {
        background: white;
        border-radius: 12px;
        padding: 1rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        margin: 0.75rem 0;
        border: 1px solid #e5e7eb;
    }
    
    /* åˆ†éš”çº¿ */
    hr {
        border: none;
        height: 1px;
        background: linear-gradient(90deg, transparent, #d1d5db, transparent);
        margin: 2rem 0;
    }
    
    /* æ ‡é¢˜è£…é¥° */
    h1 {
        font-weight: 700;
        color: #111827;
    }
    
    h2 {
        border-left: 4px solid #667eea;
        padding-left: 1rem;
        font-weight: 600;
        color: #1f2937;
    }
    
    h3 {
        border-left: 3px solid #764ba2;
        padding-left: 0.75rem;
        font-weight: 600;
        color: #374151;
    }
    
    h4 {
        font-weight: 600;
        color: #4b5563;
    }
    
    /* Expanderæ ·å¼ */
    .streamlit-expanderHeader {
        background: #f9fafb;
        border-radius: 8px;
        border: 1px solid #e5e7eb;
        font-weight: 500;
    }
    
    /* éšè—Streamlité»˜è®¤å…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* æ»šåŠ¨æ¡æ ·å¼ */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(180deg, #5a67d8 0%, #6b46c1 100%);
    }
    
    /* åŠ¨ç”»æ•ˆæœ */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .card, .stDataFrame, .chart-container {
        animation: fadeIn 0.5s ease-out;
    }
    
    /* å·¥å…·æç¤º */
    .tooltip {
        position: relative;
        display: inline-block;
    }
    
    .tooltip .tooltiptext {
        visibility: hidden;
        background-color: #1f2937;
        color: #fff;
        text-align: center;
        padding: 0.5rem;
        border-radius: 6px;
        position: absolute;
        z-index: 1;
        font-size: 0.8rem;
        white-space: nowrap;
    }
    
    .tooltip:hover .tooltiptext {
        visibility: visible;
    }
    
    /* å¾½ç«  */
    .badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        font-size: 0.75rem;
        font-weight: 600;
        border-radius: 50px;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    .badge-primary {
        background: #dbeafe;
        color: #1d4ed8;
    }
    
    .badge-success {
        background: #d1fae5;
        color: #059669;
    }
    
    .badge-warning {
        background: #fef3c7;
        color: #d97706;
    }
    
    .badge-danger {
        background: #fee2e2;
        color: #dc2626;
    }
</style>
""", unsafe_allow_html=True)

with st.sidebar:
    # æ˜¾ç¤ºç”¨æˆ·ä¿¡æ¯
    user = get_current_user()
    if user:
        st.success(f"ğŸ‘¤ æ¬¢è¿, {user['username']}!")
        if user.get('company'):
            st.caption(f"å…¬å¸: {user['company']}")

    st.markdown("---")

    # æ·»åŠ ç®¡ç†å‘˜é¢æ¿æŒ‰é’®ï¼ˆä»…ç®¡ç†å‘˜å¯è§ï¼‰
    if user and is_admin(user["username"]):
        if st.button("ğŸ”§ ç®¡ç†å‘˜é¢æ¿", use_container_width=True):
            st.session_state.show_admin = True
            st.rerun()

    # æ·»åŠ ç™»å‡ºæŒ‰é’®
    if st.button("ğŸšª é€€å‡ºç™»å½•", use_container_width=True):
        logout()

    st.markdown("---")
    st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼  MKA æ–‡ä»¶",
        type=['mka'],
        help="æ”¯æŒ Klingenberg MKA æ ¼å¼çš„é½¿è½®æ³¢çº¹åº¦æ•°æ®æ–‡ä»¶"
    )

    if uploaded_file is not None:
        st.success(f"å·²åŠ è½½: {uploaded_file.name}")

    st.markdown("---")
    st.header("ğŸ“‹ åŠŸèƒ½å¯¼èˆª")
    page = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ['ğŸ¤– AIç»¼åˆåˆ†ææŠ¥å‘Š', 'ğŸ“„ ä¸“ä¸šæŠ¥å‘Š', 'ğŸ” ä¸‰æˆªé¢æ‰­æ›²æ•°æ®', 'ğŸ—ºï¸ é½¿é¢æ‹“æ™®å›¾', 'ğŸ“Š å‘¨èŠ‚è¯¦ç»†æŠ¥è¡¨', 'ğŸ“ˆ å•é½¿åˆ†æ', 'ğŸ“‰ åˆå¹¶æ›²çº¿', 'ğŸ“Š é¢‘è°±åˆ†æ'],
        index=0
    )
    
    # åˆ†é¡µçŠ¶æ€ç®¡ç†
    if 'pagination' not in st.session_state:
        st.session_state.pagination = {'profile_page': 1, 'helix_page': 1}

# æ£€æŸ¥æ˜¯å¦æ˜¾ç¤ºç®¡ç†å‘˜é¢æ¿
if st.session_state.get('show_admin', False):
    admin_panel()
    st.stop()

if uploaded_file is not None:
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    temp_dir = tempfile.gettempdir()
    temp_path = os.path.join(temp_dir, "temp.mka")
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getvalue())
    
    with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
        analyzer = RippleWavinessAnalyzer(temp_path)
        analyzer.load_file()
        
        # å»¶è¿ŸåŠ è½½ï¼šåªåœ¨éœ€è¦æ—¶è®¡ç®—åˆ†æç»“æœ
        # ä½¿ç”¨session_stateç¼“å­˜ç»“æœé¿å…é‡å¤è®¡ç®—
        if 'analyzer' not in st.session_state:
            st.session_state.analyzer = analyzer
        
        # é¢„è®¡ç®—è½»é‡çº§ç»“æœï¼ˆé½¿è½®å‚æ•°ç­‰åŸºæœ¬ä¿¡æ¯ï¼‰
        pitch_left = analyzer.analyze_pitch('left')
        pitch_right = analyzer.analyze_pitch('right')
    
    profile_eval = analyzer.reader.profile_eval_range
    helix_eval = analyzer.reader.helix_eval_range
    gear_params = analyzer.gear_params
    
    # è·å–æ•°æ® - æ‰€æœ‰é¡µé¢å…±ç”¨
    profile_data = analyzer.reader.profile_data
    helix_data = analyzer.reader.helix_data
    
    # è·å– b1, b2, d1, d2 ç”¨äºè®¡ç®—èŒƒå›´
    b1 = analyzer.reader.b1 if hasattr(analyzer.reader, 'b1') else 0
    b2 = analyzer.reader.b2 if hasattr(analyzer.reader, 'b2') else 78
    d1 = analyzer.reader.d1 if hasattr(analyzer.reader, 'd1') else 0
    d2 = analyzer.reader.d2 if hasattr(analyzer.reader, 'd2') else 8
    
    # è·å–æµ‹é‡èŒƒå›´ da, de, ba, be
    da = analyzer.reader.da if hasattr(analyzer.reader, 'da') else d1
    de = analyzer.reader.de if hasattr(analyzer.reader, 'de') else d2
    ba = analyzer.reader.ba if hasattr(analyzer.reader, 'ba') else b1
    be = analyzer.reader.be if hasattr(analyzer.reader, 'be') else b2
    
    # åŒæ—¶å°è¯•ä½¿ç”¨ gear_analysis_refactored è·å–é¢å¤–ä¿¡æ¯
    if GEAR_ANALYSIS_AVAILABLE:
        try:
            gear_data_dict = parse_mka_file(temp_path)
            use_gear_analysis = True
        except Exception as e:
            gear_data_dict = None
            use_gear_analysis = False
    else:
        gear_data_dict = None
        use_gear_analysis = False
    
    # è¾…åŠ©å‡½æ•°ï¼šé½¿å·æ’åºï¼ˆå¤„ç†æ•°å­—å’Œå¸¦åç¼€çš„é½¿å·å¦‚ 1, 1a, 2, 10ï¼‰- æ‰€æœ‰é¡µé¢å…±ç”¨
    def tooth_sort_key(tooth_id):
        """å°†é½¿å·è½¬æ¢ä¸ºæ’åºé”®ï¼Œå¦‚ '1a' -> (1, 'a'), '10' -> (10, '')"""
        match = re.match(r'(\d+)([a-z]?)', str(tooth_id))
        if match:
            num = int(match.group(1))
            suffix = match.group(2)
            return (num, suffix)
        return (0, str(tooth_id))
    
    # DIN 3962 å…¬å·®è¡¨ - æ‰€æœ‰é¡µé¢å…±ç”¨
    DIN3962_PROFILE_TOLERANCES = {
        1: {'fHa': 3.0, 'ffa': 4.0, 'Fa': 5.0},
        2: {'fHa': 4.0, 'ffa': 6.0, 'Fa': 7.0},
        3: {'fHa': 5.5, 'ffa': 8.0, 'Fa': 10.0},
        4: {'fHa': 8.0, 'ffa': 12.0, 'Fa': 14.0},
        5: {'fHa': 11.0, 'ffa': 16.0, 'Fa': 20.0},
        6: {'fHa': 16.0, 'ffa': 22.0, 'Fa': 28.0},
        7: {'fHa': 22.0, 'ffa': 32.0, 'Fa': 40.0},
        8: {'fHa': 28.0, 'ffa': 45.0, 'Fa': 56.0},
        9: {'fHa': 40.0, 'ffa': 63.0, 'Fa': 80.0},
        10: {'fHa': 71.0, 'ffa': 110.0, 'Fa': 125.0},
        11: {'fHa': 110.0, 'ffa': 160.0, 'Fa': 200.0},
        12: {'fHa': 180.0, 'ffa': 250.0, 'Fa': 320.0}
    }
    
    DIN3962_LEAD_TOLERANCES = {
        1: {'fHb': 2.5, 'ffb': 2.0, 'Fb': 3.0},
        2: {'fHb': 3.5, 'ffb': 5.0, 'Fb': 6.0},
        3: {'fHb': 4.5, 'ffb': 7.0, 'Fb': 8.0},
        4: {'fHb': 6.0, 'ffb': 8.0, 'Fb': 10.0},
        5: {'fHb': 8.0, 'ffb': 9.0, 'Fb': 12.0},
        6: {'fHb': 11.0, 'ffb': 12.0, 'Fb': 16.0},
        7: {'fHb': 16.0, 'ffb': 16.0, 'Fb': 22.0},
        8: {'fHb': 22.0, 'ffb': 25.0, 'Fb': 32.0},
        9: {'fHb': 32.0, 'ffb': 40.0, 'Fb': 50.0},
        10: {'fHb': 50.0, 'ffb': 63.0, 'Fb': 80.0},
        11: {'fHb': 80.0, 'ffb': 100.0, 'Fb': 125.0},
        12: {'fHb': 125.0, 'ffb': 160.0, 'Fb': 200.0}
    }
    
    DEFAULT_QUALITY = 5  # é»˜è®¤è´¨é‡ç­‰çº§
    
    def get_tolerance(param_type, param_code, quality=DEFAULT_QUALITY):
        """è·å–å…¬å·®å€¼"""
        if param_type == 'profile':
            table = DIN3962_PROFILE_TOLERANCES
        elif param_type == 'lead':
            table = DIN3962_LEAD_TOLERANCES
        else:
            return None
        if quality in table and param_code in table[quality]:
            return table[quality][param_code]
        return None
    
    def calculate_quality_grade(measured_value, param_type, param_code):
        """æ ¹æ®æµ‹é‡å€¼è®¡ç®—è´¨é‡ç­‰çº§"""
        if measured_value is None:
            return None
        abs_value = abs(measured_value)
        if param_type == 'profile':
            table = DIN3962_PROFILE_TOLERANCES
        elif param_type == 'lead':
            table = DIN3962_LEAD_TOLERANCES
        else:
            return None
        for quality in range(1, 13):
            if quality in table and param_code in table[quality]:
                if abs_value <= table[quality][param_code]:
                    return quality
        return 12
    
    # è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—åå·®å‚æ•°ï¼ˆä¸PDFæŠ¥å‘Šå®Œå…¨ä¸€è‡´ï¼‰- æ‰€æœ‰é¡µé¢å…±ç”¨
    def calc_profile_deviations(values):
        """è®¡ç®—é½¿å½¢åå·®å‚æ•° - ä¸PDFæŠ¥å‘Šç®—æ³•ä¸€è‡´"""
        if values is None or len(values) < 10:
            return None, None, None, None
        
        data = np.array(values)
        n = len(data)
        idx_start = int(n * 0.15)
        idx_end = int(n * 0.85)
        eval_values = data[idx_start:idx_end]
        
        if len(eval_values) < 2:
            return None, None, None, None
        
        # æ€»åå·® F_alphaï¼ˆå³°å³°å€¼ï¼‰
        F_alpha = np.max(eval_values) - np.min(eval_values)
        
        # æ‹Ÿåˆç›´çº¿ï¼ˆæœ€å°äºŒä¹˜æ³•ï¼‰
        x = np.arange(len(eval_values))
        coeffs = np.polyfit(x, eval_values, 1)
        trend = coeffs[0] * x + coeffs[1]
        
        # fH_alpha - é½¿å½¢å€¾æ–œåå·®ï¼ˆè¶‹åŠ¿çº¿çš„å·®å€¼ï¼‰
        fH_alpha = trend[-1] - trend[0]
        
        # ff_alpha - é½¿å½¢å½¢çŠ¶åå·®ï¼ˆå»é™¤è¶‹åŠ¿åçš„æ®‹ä½™åˆ†é‡å³°å³°å€¼ï¼‰
        residual = eval_values - trend
        ff_alpha = np.max(residual) - np.min(residual)
        
        # Ca - é¼“å½¢é‡ï¼ˆæŠ›ç‰©çº¿æ‹Ÿåˆï¼‰
        if len(eval_values) >= 3:
            x2 = np.arange(len(eval_values))
            coeffs2 = np.polyfit(x2, eval_values, 2)
            a = coeffs2[0]
            L = len(eval_values)
            Ca = -a * (L ** 2) / 4
        else:
            Ca = 0.0
        
        return F_alpha, fH_alpha, ff_alpha, Ca
    
    def calc_lead_deviations(values):
        """è®¡ç®—é½¿å‘åå·®å‚æ•° - ä¸PDFæŠ¥å‘Šç®—æ³•ä¸€è‡´"""
        if values is None or len(values) < 10:
            return None, None, None, None
        
        data = np.array(values)
        n = len(data)
        idx_start = int(n * 0.15)
        idx_end = int(n * 0.85)
        eval_values = data[idx_start:idx_end]
        
        if len(eval_values) < 2:
            return None, None, None, None
        
        # æ€»åå·® F_betaï¼ˆå³°å³°å€¼ï¼‰
        F_beta = np.max(eval_values) - np.min(eval_values)
        
        # æ‹Ÿåˆç›´çº¿ï¼ˆæœ€å°äºŒä¹˜æ³•ï¼‰
        x = np.arange(len(eval_values))
        coeffs = np.polyfit(x, eval_values, 1)
        trend = coeffs[0] * x + coeffs[1]
        
        # fH_beta - é½¿å‘å€¾æ–œåå·®ï¼ˆè¶‹åŠ¿çº¿çš„å·®å€¼ï¼‰
        fH_beta = trend[-1] - trend[0]
        
        # ff_beta - é½¿å‘å½¢çŠ¶åå·®ï¼ˆå»é™¤è¶‹åŠ¿åçš„æ®‹ä½™åˆ†é‡å³°å³°å€¼ï¼‰
        residual = eval_values - trend
        ff_beta = np.max(residual) - np.min(residual)
        
        # Cb - é¼“å½¢é‡ï¼ˆæŠ›ç‰©çº¿æ‹Ÿåˆï¼‰
        if len(eval_values) >= 3:
            x2 = np.arange(len(eval_values))
            coeffs2 = np.polyfit(x2, eval_values, 2)
            a = coeffs2[0]
            L = len(eval_values)
            Cb = -a * (L ** 2) / 4
        else:
            Cb = 0.0
        
        return F_beta, fH_beta, ff_beta, Cb
    
    if page == 'ğŸ“„ ä¸“ä¸šæŠ¥å‘Š':
        st.markdown("## Gear Profile/Lead Report")
        
        # ========== å¤´éƒ¨å‚æ•°è¡¨æ ¼ ==========
        info = analyzer.reader.info if hasattr(analyzer.reader, 'info') else {}
        
        col1, col2 = st.columns(2)
        with col1:
            header_data1 = {
                'Parameter': ['Prog.No.', 'Type', 'Drawing No.', 'Order No.', 'Cust./Mach. No.', 'Loc. of check'],
                'Value': [
                    uploaded_file.name,
                    info.get('type_', 'gear'),
                    info.get('drawing_no', uploaded_file.name),
                    info.get('order_no', '-'),
                    info.get('customer', '-'),
                    info.get('location', '-')
                ]
            }
            st.table(header_data1)

        with col2:
            if gear_params:
                import math
                beta = math.radians(abs(gear_params.helix_angle))
                alpha_n = math.radians(gear_params.pressure_angle)
                alpha_t = math.atan(math.tan(alpha_n) / math.cos(beta)) if abs(beta) > 1e-6 else alpha_n
                pitch_diameter = gear_params.teeth_count * gear_params.module / math.cos(beta)
                base_diameter = pitch_diameter * math.cos(alpha_t)

                header_data2 = {
                    'Parameter': ['Operator', 'No. of teeth', 'Module m', 'Pressure angle', 'Helix angle', 'Base Cir. db'],
                    'Value': [
                        info.get('operator', 'Operator'),
                        str(gear_params.teeth_count),
                        f"{gear_params.module:.3f}mm",
                        f"{gear_params.pressure_angle}Â°",
                        f"{gear_params.helix_angle}Â°",
                        f"{base_diameter:.3f}mm"
                    ]
                }
            else:
                header_data2 = {
                    'Parameter': ['Operator', 'No. of teeth', 'Module m', 'Pressure angle', 'Helix angle', 'Base Cir. db'],
                    'Value': ['Operator', '-', '-', '-', '-', '-']
                }
            st.table(header_data2)
        
        st.markdown("---")
        
        # ========== è·å–é½¿å·æ•°æ® ==========
        profile_teeth_left = sorted(list(profile_data.get('left', {}).keys()), key=tooth_sort_key)
        profile_teeth_right = sorted(list(profile_data.get('right', {}).keys()), key=tooth_sort_key)
        helix_teeth_left = sorted(list(helix_data.get('left', {}).keys()), key=tooth_sort_key)
        helix_teeth_right = sorted(list(helix_data.get('right', {}).keys()), key=tooth_sort_key)
        
        TEETH_PER_PAGE = 6  # æ¯é¡µæ˜¾ç¤º6ä¸ªé½¿
        
        # è®¡ç®—æ€»é¡µæ•°ï¼ˆé½¿å½¢å’Œé½¿å‘ä½¿ç”¨ç›¸åŒçš„é¡µæ•°ï¼‰
        profile_max_teeth = max(len(profile_teeth_left), len(profile_teeth_right))
        helix_max_teeth = max(len(helix_teeth_left), len(helix_teeth_right))
        max_teeth = max(profile_max_teeth, helix_max_teeth)
        total_pages = max(1, (max_teeth + TEETH_PER_PAGE - 1) // TEETH_PER_PAGE)
        
        # ========== ç»Ÿä¸€åˆ†é¡µæ§åˆ¶ ==========
        current_page = st.session_state.pagination.get('current_page', 1)
        
        col_prev, col_info, col_next = st.columns([1, 3, 1])
        with col_prev:
            if st.button("â¬…ï¸ ä¸Šä¸€é¡µ", key="page_prev") and current_page > 1:
                st.session_state.pagination['current_page'] = current_page - 1
                st.rerun()
        with col_info:
            st.markdown(f"**ç¬¬ {current_page} / {total_pages} é¡µ**")
        with col_next:
            if st.button("â¡ï¸ ä¸‹ä¸€é¡µ", key="page_next") and current_page < total_pages:
                st.session_state.pagination['current_page'] = current_page + 1
                st.rerun()
        
        # è®¡ç®—å½“å‰é¡µçš„é½¿å·èŒƒå›´
        start_idx = (current_page - 1) * TEETH_PER_PAGE
        end_idx = start_idx + TEETH_PER_PAGE
        
        current_profile_left = profile_teeth_left[start_idx:end_idx]
        current_profile_right = profile_teeth_right[start_idx:end_idx]
        current_helix_left = helix_teeth_left[start_idx:end_idx]
        current_helix_right = helix_teeth_right[start_idx:end_idx]
        
        # ========== Profile é½¿å½¢åˆ†æ ==========
        st.markdown("### Profile é½¿å½¢åˆ†æ")
        
        # ========== å·¦å³é½¿å½¢å›¾è¡¨å¹¶æ’æ˜¾ç¤º ==========
        left_profile_results = []
        right_profile_results = []
        
        # åˆ›å»º12åˆ—ï¼šå·¦6ä¸ª + å³6ä¸ª
        profile_cols = st.columns(12)
        
        # å·¦é½¿é¢å›¾è¡¨ï¼ˆå‰6åˆ—ï¼‰
        for i, tooth_id in enumerate(current_profile_left):
            with profile_cols[i]:
                if tooth_id in profile_data.get('left', {}):
                    tooth_profiles = profile_data['left'][tooth_id]
                    if tooth_profiles:
                        helix_mid = (helix_eval.eval_start + helix_eval.eval_end) / 2
                        best_z = min(tooth_profiles.keys(), key=lambda z: abs(z - helix_mid))
                        values = np.array(tooth_profiles[best_z])
                        
                        fig, ax = plt.subplots(figsize=(1.8, 4.5))
                        y_positions = np.linspace(da, de, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'r-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = de - da
                        idx_eval_start = int((d1 - da) / meas_length * (n - 1))
                        idx_eval_end = int((d2 - da) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=6, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=6, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=6, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=6, color='red')
                        
                        ax.set_ylim(da - 1, de + 1)
                        ax.set_yticks([da, d1, d2, de])
                        ax.set_yticklabels([f'{da:.1f}', f'{d1:.1f}', f'{d2:.1f}', f'{de:.1f}'], fontsize=7)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=7)
                        ax.grid(True, linestyle=':', linewidth=0.3, color='gray')
                        ax.set_xlabel(f'{tooth_id}', fontsize=9, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                        
                        F_a, fH_a, ff_a, Ca = calc_profile_deviations(values)
                        if F_a is not None:
                            left_profile_results.append({
                                'Tooth': tooth_id,
                                'fHÎ±': fH_a,
                                'ffÎ±': ff_a,
                                'FÎ±': F_a,
                                'Ca': Ca
                            })
        
        # å³é½¿é¢å›¾è¡¨ï¼ˆå6åˆ—ï¼‰
        for i, tooth_id in enumerate(current_profile_right):
            with profile_cols[i + 6]:
                if tooth_id in profile_data.get('right', {}):
                    tooth_profiles = profile_data['right'][tooth_id]
                    if tooth_profiles:
                        helix_mid = (helix_eval.eval_start + helix_eval.eval_end) / 2
                        best_z = min(tooth_profiles.keys(), key=lambda z: abs(z - helix_mid))
                        values = np.array(tooth_profiles[best_z])
                        
                        fig, ax = plt.subplots(figsize=(1.8, 4.5))
                        y_positions = np.linspace(da, de, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'r-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = de - da
                        idx_eval_start = int((d1 - da) / meas_length * (n - 1))
                        idx_eval_end = int((d2 - da) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=6, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=6, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=6, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=6, color='red')
                        
                        ax.set_ylim(da - 1, de + 1)
                        ax.set_yticks([da, d1, d2, de])
                        ax.set_yticklabels([f'{da:.1f}', f'{d1:.1f}', f'{d2:.1f}', f'{de:.1f}'], fontsize=7)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=7)
                        ax.grid(True, linestyle=':', linewidth=0.3, color='gray')
                        ax.set_xlabel(f'{tooth_id}', fontsize=9, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                        
                        F_a, fH_a, ff_a, Ca = calc_profile_deviations(values)
                        if F_a is not None:
                            right_profile_results.append({
                                'Tooth': tooth_id,
                                'fHÎ±': fH_a,
                                'ffÎ±': ff_a,
                                'FÎ±': F_a,
                                'Ca': Ca
                            })
        
        # ========== é½¿å½¢åå·®æ•°æ®è¡¨ ==========
        st.markdown("#### é½¿å½¢åå·®æ•°æ®è¡¨")
        
        # å·¦é½¿é¢æ•°æ®è¡¨
        if left_profile_results:
            st.markdown("**Left Flank å·¦é½¿é¢**")
            df_left = pd.DataFrame(left_profile_results)
            
            mean_row = {'Tooth': 'Mean'}
            max_row = {'Tooth': 'Max'}
            for col in ['fHÎ±', 'ffÎ±', 'FÎ±', 'Ca']:
                mean_row[col] = df_left[col].mean()
                max_row[col] = df_left[col].max()
            mean_row['fHÎ±m'] = df_left['fHÎ±'].mean()
            max_row['fHÎ±m'] = np.nan
            df_left['fHÎ±m'] = np.nan
            
            tol_row = {'Tooth': f'Lim.{DEFAULT_QUALITY}'}
            for col, tol_code in [('fHÎ±', 'fHa'), ('ffÎ±', 'ffa'), ('FÎ±', 'Fa')]:
                tol_val = get_tolerance('profile', tol_code, DEFAULT_QUALITY)
                tol_row[col] = f'Â±{int(tol_val)}' if tol_val else ''
            tol_row['Ca'] = ''
            tol_row['fHÎ±m'] = ''
            
            for col, tol_code in [('fHÎ±', 'fHa'), ('ffÎ±', 'ffa'), ('FÎ±', 'Fa')]:
                max_val = max_row[col]
                if max_val is not None and not np.isnan(max_val):
                    quality = calculate_quality_grade(max_val, 'profile', tol_code)
                    if quality:
                        max_row[col] = f"{max_val:.2f} Q{quality}"
            
            df_left = pd.concat([df_left, pd.DataFrame([mean_row]), pd.DataFrame([max_row]), pd.DataFrame([tol_row])], ignore_index=True)
            
            def format_value(x):
                if pd.isna(x):
                    return ''
                if isinstance(x, str):
                    return x
                if isinstance(x, (int, float)):
                    return f'{x:.2f}'
                return str(x)
            
            df_display = df_left[['Tooth', 'fHÎ±', 'fHÎ±m', 'ffÎ±', 'FÎ±', 'Ca']].copy()
            for col in ['fHÎ±', 'fHÎ±m', 'ffÎ±', 'FÎ±', 'Ca']:
                df_display[col] = df_display[col].apply(format_value)
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        
        # å³é½¿é¢æ•°æ®è¡¨
        if right_profile_results:
            st.markdown("**Right Flank å³é½¿é¢**")
            df_right = pd.DataFrame(right_profile_results)
            
            mean_row = {'Tooth': 'Mean'}
            max_row = {'Tooth': 'Max'}
            for col in ['fHÎ±', 'ffÎ±', 'FÎ±', 'Ca']:
                mean_row[col] = df_right[col].mean()
                max_row[col] = df_right[col].max()
            mean_row['fHÎ±m'] = df_right['fHÎ±'].mean()
            max_row['fHÎ±m'] = np.nan
            df_right['fHÎ±m'] = np.nan
            
            tol_row = {'Tooth': f'Lim.{DEFAULT_QUALITY}'}
            for col, tol_code in [('fHÎ±', 'fHa'), ('ffÎ±', 'ffa'), ('FÎ±', 'Fa')]:
                tol_val = get_tolerance('profile', tol_code, DEFAULT_QUALITY)
                tol_row[col] = f'Â±{int(tol_val)}' if tol_val else ''
            tol_row['Ca'] = ''
            tol_row['fHÎ±m'] = ''
            
            for col, tol_code in [('fHÎ±', 'fHa'), ('ffÎ±', 'ffa'), ('FÎ±', 'Fa')]:
                max_val = max_row[col]
                if max_val is not None and not np.isnan(max_val):
                    quality = calculate_quality_grade(max_val, 'profile', tol_code)
                    if quality:
                        max_row[col] = f"{max_val:.2f} Q{quality}"
            
            df_right = pd.concat([df_right, pd.DataFrame([mean_row]), pd.DataFrame([max_row]), pd.DataFrame([tol_row])], ignore_index=True)
            
            df_display = df_right[['Tooth', 'fHÎ±', 'fHÎ±m', 'ffÎ±', 'FÎ±', 'Ca']].copy()
            for col in ['fHÎ±', 'fHÎ±m', 'ffÎ±', 'FÎ±', 'Ca']:
                df_display[col] = df_display[col].apply(format_value)
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        # ========== Helix é½¿å‘åˆ†æ ==========
        st.markdown("### Helix é½¿å‘åˆ†æ")
        
        # ========== å·¦å³é½¿å‘å›¾è¡¨å¹¶æ’æ˜¾ç¤º ==========
        left_helix_results = []
        right_helix_results = []
        
        # åˆ›å»º12åˆ—ï¼šå·¦6ä¸ª + å³6ä¸ª
        helix_cols = st.columns(12)
        
        # å·¦é½¿é¢å›¾è¡¨ï¼ˆå‰6åˆ—ï¼‰
        for i, tooth_id in enumerate(current_helix_left):
            with helix_cols[i]:
                if tooth_id in helix_data.get('left', {}):
                    tooth_helix = helix_data['left'][tooth_id]
                    if tooth_helix:
                        profile_mid = (profile_eval.eval_start + profile_eval.eval_end) / 2
                        best_d = min(tooth_helix.keys(), key=lambda d: abs(d - profile_mid))
                        values = np.array(tooth_helix[best_d])
                        
                        fig, ax = plt.subplots(figsize=(1.8, 4.5))
                        y_positions = np.linspace(ba, be, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'k-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = be - ba
                        idx_eval_start = int((b1 - ba) / meas_length * (n - 1))
                        idx_eval_end = int((b2 - ba) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=6, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=6, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=6, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=6, color='red')
                        
                        ax.set_ylim(ba - 1, be + 1)
                        ax.set_yticks([ba, b1, b2, be])
                        ax.set_yticklabels([f'{ba:.1f}', f'{b1:.1f}', f'{b2:.1f}', f'{be:.1f}'], fontsize=7)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=7)
                        ax.grid(True, linestyle=':', linewidth=0.3, color='gray')
                        ax.set_xlabel(f'{tooth_id}', fontsize=9, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                        
                        F_b, fH_b, ff_b, Cb = calc_lead_deviations(values)
                        if F_b is not None:
                            left_helix_results.append({
                                'Tooth': tooth_id,
                                'fHÎ²': fH_b,
                                'ffÎ²': ff_b,
                                'FÎ²': F_b,
                                'Cb': Cb
                            })
        
        # å³é½¿é¢å›¾è¡¨ï¼ˆå6åˆ—ï¼‰
        for i, tooth_id in enumerate(current_helix_right):
            with helix_cols[i + 6]:
                if tooth_id in helix_data.get('right', {}):
                    tooth_helix = helix_data['right'][tooth_id]
                    if tooth_helix:
                        profile_mid = (profile_eval.eval_start + profile_eval.eval_end) / 2
                        best_d = min(tooth_helix.keys(), key=lambda d: abs(d - profile_mid))
                        values = np.array(tooth_helix[best_d])
                        
                        fig, ax = plt.subplots(figsize=(1.8, 4.5))
                        y_positions = np.linspace(ba, be, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'k-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = be - ba
                        idx_eval_start = int((b1 - ba) / meas_length * (n - 1))
                        idx_eval_end = int((b2 - ba) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=6, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=6, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=6, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=6, color='red')
                        
                        ax.set_ylim(ba - 1, be + 1)
                        ax.set_yticks([ba, b1, b2, be])
                        ax.set_yticklabels([f'{ba:.1f}', f'{b1:.1f}', f'{b2:.1f}', f'{be:.1f}'], fontsize=7)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=7)
                        ax.grid(True, linestyle=':', linewidth=0.3, color='gray')
                        ax.set_xlabel(f'{tooth_id}', fontsize=9, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                        
                        F_b, fH_b, ff_b, Cb = calc_lead_deviations(values)
                        if F_b is not None:
                            right_helix_results.append({
                                'Tooth': tooth_id,
                                'fHÎ²': fH_b,
                                'ffÎ²': ff_b,
                                'FÎ²': F_b,
                                'Cb': Cb
                            })
        
        # ========== é½¿å‘åå·®æ•°æ®è¡¨ ==========
        st.markdown("#### é½¿å‘åå·®æ•°æ®è¡¨")
        
        # å·¦é½¿é¢æ•°æ®è¡¨
        if left_helix_results:
            st.markdown("**Left Flank å·¦é½¿é¢**")
            df_left_h = pd.DataFrame(left_helix_results)
            
            mean_row = {'Tooth': 'Mean'}
            max_row = {'Tooth': 'Max'}
            for col in ['fHÎ²', 'ffÎ²', 'FÎ²', 'Cb']:
                mean_row[col] = df_left_h[col].mean()
                max_row[col] = df_left_h[col].max()
            mean_row['fHÎ²m'] = df_left_h['fHÎ²'].mean()
            max_row['fHÎ²m'] = np.nan
            df_left_h['fHÎ²m'] = np.nan
            
            tol_row = {'Tooth': f'Lim.{DEFAULT_QUALITY}'}
            for col, tol_code in [('fHÎ²', 'fHb'), ('ffÎ²', 'ffb'), ('FÎ²', 'Fb')]:
                tol_val = get_tolerance('lead', tol_code, DEFAULT_QUALITY)
                tol_row[col] = f'Â±{int(tol_val)}' if tol_val else ''
            tol_row['Cb'] = ''
            tol_row['fHÎ²m'] = ''
            
            for col, tol_code in [('fHÎ²', 'fHb'), ('ffÎ²', 'ffb'), ('FÎ²', 'Fb')]:
                max_val = max_row[col]
                if max_val is not None and not np.isnan(max_val):
                    quality = calculate_quality_grade(max_val, 'lead', tol_code)
                    if quality:
                        max_row[col] = f"{max_val:.2f} Q{quality}"
            
            df_left_h = pd.concat([df_left_h, pd.DataFrame([mean_row]), pd.DataFrame([max_row]), pd.DataFrame([tol_row])], ignore_index=True)
            
            df_display = df_left_h[['Tooth', 'fHÎ²', 'fHÎ²m', 'ffÎ²', 'FÎ²', 'Cb']].copy()
            for col in ['fHÎ²', 'fHÎ²m', 'ffÎ²', 'FÎ²', 'Cb']:
                df_display[col] = df_display[col].apply(format_value)
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        
        # å³é½¿é¢æ•°æ®è¡¨
        if right_helix_results:
            st.markdown("**Right Flank å³é½¿é¢**")
            df_right_h = pd.DataFrame(right_helix_results)
            
            mean_row = {'Tooth': 'Mean'}
            max_row = {'Tooth': 'Max'}
            for col in ['fHÎ²', 'ffÎ²', 'FÎ²', 'Cb']:
                mean_row[col] = df_right_h[col].mean()
                max_row[col] = df_right_h[col].max()
            mean_row['fHÎ²m'] = df_right_h['fHÎ²'].mean()
            max_row['fHÎ²m'] = np.nan
            df_right_h['fHÎ²m'] = np.nan
            
            tol_row = {'Tooth': f'Lim.{DEFAULT_QUALITY}'}
            for col, tol_code in [('fHÎ²', 'fHb'), ('ffÎ²', 'ffb'), ('FÎ²', 'Fb')]:
                tol_val = get_tolerance('lead', tol_code, DEFAULT_QUALITY)
                tol_row[col] = f'Â±{int(tol_val)}' if tol_val else ''
            tol_row['Cb'] = ''
            tol_row['fHÎ²m'] = ''
            
            for col, tol_code in [('fHÎ²', 'fHb'), ('ffÎ²', 'ffb'), ('FÎ²', 'Fb')]:
                max_val = max_row[col]
                if max_val is not None and not np.isnan(max_val):
                    quality = calculate_quality_grade(max_val, 'lead', tol_code)
                    if quality:
                        max_row[col] = f"{max_val:.2f} Q{quality}"
            
            df_right_h = pd.concat([df_right_h, pd.DataFrame([mean_row]), pd.DataFrame([max_row]), pd.DataFrame([tol_row])], ignore_index=True)
            
            df_display = df_right_h[['Tooth', 'fHÎ²', 'fHÎ²m', 'ffÎ²', 'FÎ²', 'Cb']].copy()
            for col in ['fHÎ²', 'fHÎ²m', 'ffÎ²', 'FÎ²', 'Cb']:
                df_display[col] = df_display[col].apply(format_value)
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        
        # PDFä¸‹è½½æŒ‰é’®
        st.markdown("---")
        st.markdown("### ğŸ“‹ PDFæŠ¥å‘Šç”Ÿæˆ")
        if PDF_GENERATOR_AVAILABLE:
            if st.button("ğŸ“¥ ç”Ÿæˆå®Œæ•´PDFæŠ¥å‘Š"):
                with st.spinner("æ­£åœ¨ç”ŸæˆPDFæŠ¥å‘Šï¼Œè¯·ç¨å€™..."):
                    try:
                        generator = KlingelnbergReportGenerator()
                        pdf_buffer = generator.generate_full_report(
                            analyzer,
                            output_filename=f"gear_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                        )

                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½PDFæŠ¥å‘Š",
                            data=pdf_buffer,
                            file_name=f"gear_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                            mime="application/pdf"
                        )
                        st.success("âœ… PDFæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"ç”ŸæˆPDFå¤±è´¥: {e}")
        else:
            st.warning("PDFç”Ÿæˆå™¨ä¸å¯ç”¨")
    
    elif page == 'ğŸ“Š å‘¨èŠ‚è¯¦ç»†æŠ¥è¡¨':
        st.markdown("## Gear Spacing Report - å‘¨èŠ‚è¯¦ç»†æŠ¥è¡¨")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**åŸºæœ¬ä¿¡æ¯**")
            header_data1 = {
                'å‚æ•°': ['Prog.No.', 'Type', 'Drawing No.', 'Operator', 'Date'],
                'å€¼': [uploaded_file.name, 'gear', uploaded_file.name, 'Operator', datetime.now().strftime('%d.%m.%y')]
            }
            st.table(header_data1)
        
        with col2:
            st.markdown("**é½¿è½®å‚æ•°**")
            if gear_params:
                import math
                beta = math.radians(abs(gear_params.helix_angle))
                pitch_diameter = gear_params.teeth_count * gear_params.module / math.cos(beta) if gear_params.module > 0 else 0
                header_data2 = {
                    'å‚æ•°': ['No. of teeth', 'Module m', 'Pressure angle', 'Helix angle', 'Pitch diameter'],
                    'å€¼': [
                        str(gear_params.teeth_count),
                        f"{gear_params.module:.3f}mm",
                        f"{gear_params.pressure_angle}Â°",
                        f"{gear_params.helix_angle}Â°",
                        f"{pitch_diameter:.3f}mm"
                    ]
                }
                st.table(header_data2)
        
        st.markdown("---")
        st.markdown("### å‘¨èŠ‚åå·®ç»Ÿè®¡")
        
        cols = st.columns(4)
        
        if pitch_left:
            with cols[0]:
                st.metric("å·¦é½¿é¢ fp max", f"{pitch_left.fp_max:.2f} Î¼m")
            with cols[1]:
                st.metric("å·¦é½¿é¢ Fp max", f"{pitch_left.Fp_max:.2f} Î¼m")
            with cols[2]:
                st.metric("å·¦é½¿é¢ Fp min", f"{pitch_left.Fp_min:.2f} Î¼m")
            with cols[3]:
                st.metric("å·¦é½¿é¢ Fr", f"{pitch_left.Fr:.2f} Î¼m")
        
        if pitch_right:
            cols2 = st.columns(4)
            with cols2[0]:
                st.metric("å³é½¿é¢ fp max", f"{pitch_right.fp_max:.2f} Î¼m")
            with cols2[1]:
                st.metric("å³é½¿é¢ Fp max", f"{pitch_right.Fp_max:.2f} Î¼m")
            with cols2[2]:
                st.metric("å³é½¿é¢ Fp min", f"{pitch_right.Fp_min:.2f} Î¼m")
            with cols2[3]:
                st.metric("å³é½¿é¢ Fr", f"{pitch_right.Fr:.2f} Î¼m")
        
        st.markdown("---")
        st.markdown("### Pitch Deviation Charts")

        # è·å–pitchæ•°æ®
        pitch_data_left = analyzer.reader.pitch_data.get('left', {})
        pitch_data_right = analyzer.reader.pitch_data.get('right', {})

        # å·¦é½¿é¢å›¾è¡¨
        if pitch_data_left and 'teeth' in pitch_data_left:
            st.subheader("Left Flank Pitch Deviation")
            teeth_left = pitch_data_left['teeth']
            fp_values_left = pitch_data_left['fp_values']
            Fp_values_left = pitch_data_left['Fp_values']

            # è°ƒæ•´Fpå€¼ï¼ˆä»0å¼€å§‹ï¼‰
            if Fp_values_left:
                first_value = Fp_values_left[0]
                Fp_values_adjusted = [fp - first_value for fp in Fp_values_left]
            else:
                Fp_values_adjusted = []

            col1, col2 = st.columns(2)

            with col1:
                # fpæŸ±çŠ¶å›¾
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.bar(teeth_left, fp_values_left, color='white', edgecolor='black', width=1.0, linewidth=0.5)
                ax.set_title('Tooth to tooth spacing fp left flank', fontsize=10, fontweight='bold')
                ax.set_xlabel('Tooth Number')
                ax.set_ylabel('fp (Î¼m)')
                ax.grid(True, linestyle=':', alpha=0.5)
                ax.set_xlim(0, len(teeth_left)+1)
                st.pyplot(fig)
                plt.close(fig)

            with col2:
                # Fpæ›²çº¿å›¾
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(teeth_left, Fp_values_adjusted, 'k-', linewidth=1.0)
                ax.set_title('Index Fp left flank', fontsize=10, fontweight='bold')
                ax.set_xlabel('Tooth Number')
                ax.set_ylabel('Fp (Î¼m)')
                ax.grid(True, linestyle=':', alpha=0.5)
                ax.set_xlim(0, len(teeth_left)+1)
                st.pyplot(fig)
                plt.close(fig)

        # å³é½¿é¢å›¾è¡¨
        if pitch_data_right and 'teeth' in pitch_data_right:
            st.subheader("Right Flank Pitch Deviation")
            teeth_right = pitch_data_right['teeth']
            fp_values_right = pitch_data_right['fp_values']
            Fp_values_right = pitch_data_right['Fp_values']

            # è°ƒæ•´Fpå€¼ï¼ˆä»0å¼€å§‹ï¼‰
            if Fp_values_right:
                first_value = Fp_values_right[0]
                Fp_values_adjusted = [fp - first_value for fp in Fp_values_right]
            else:
                Fp_values_adjusted = []

            col1, col2 = st.columns(2)

            with col1:
                # fpæŸ±çŠ¶å›¾
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.bar(teeth_right, fp_values_right, color='white', edgecolor='black', width=1.0, linewidth=0.5)
                ax.set_title('Tooth to tooth spacing fp right flank', fontsize=10, fontweight='bold')
                ax.set_xlabel('Tooth Number')
                ax.set_ylabel('fp (Î¼m)')
                ax.grid(True, linestyle=':', alpha=0.5)
                ax.set_xlim(0, len(teeth_right)+1)
                st.pyplot(fig)
                plt.close(fig)

            with col2:
                # Fpæ›²çº¿å›¾
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(teeth_right, Fp_values_adjusted, 'k-', linewidth=1.0)
                ax.set_title('Index Fp right flank', fontsize=10, fontweight='bold')
                ax.set_xlabel('Tooth Number')
                ax.set_ylabel('Fp (Î¼m)')
                ax.grid(True, linestyle=':', alpha=0.5)
                ax.set_xlim(0, len(teeth_right)+1)
                st.pyplot(fig)
                plt.close(fig)

        st.markdown("---")
        st.markdown("### Runout")

        # Runoutå›¾è¡¨
        if pitch_data_left and 'teeth' in pitch_data_left:
            teeth = pitch_data_left['teeth']
            runout_values = pitch_data_left['Fp_values']

            if teeth and runout_values:
                fig, ax = plt.subplots(figsize=(12, 5))

                # ç»˜åˆ¶æŸ±çŠ¶å›¾
                ax.bar(teeth, runout_values, color='white', edgecolor='black', width=1.0, linewidth=0.5, label='Runout')

                # ç»˜åˆ¶æ­£å¼¦æ‹Ÿåˆæ›²çº¿
                if len(teeth) > 2:
                    import numpy as np
                    x_smooth = np.linspace(min(teeth), max(teeth), 200)
                    amplitude = (max(runout_values) - min(runout_values)) / 2
                    mid = (max(runout_values) + min(runout_values)) / 2
                    period = len(teeth)
                    y_smooth = mid + amplitude * np.sin(2 * np.pi * (x_smooth - min(teeth)) / period)
                    ax.plot(x_smooth, y_smooth, 'k-', linewidth=1.5, label='Sine fit')

                ax.set_title('Runout Fr (Ball-Ã˜ =3mm)', fontsize=12, fontweight='bold')
                ax.set_xlabel('Tooth Number')
                ax.set_ylabel('Fr (Î¼m)')
                ax.grid(True, linestyle=':', alpha=0.5)
                ax.set_xlim(0, len(teeth)+1)
                ax.legend()
                st.pyplot(fig)
                plt.close(fig)

        st.markdown("---")
        st.markdown("### Pitch Deviation Statistics")

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        def calc_pitch_stats(pitch_data):
            """Calculate pitch deviation statistics"""
            if not pitch_data or 'teeth' not in pitch_data:
                return {}

            teeth = pitch_data['teeth']
            fp_vals = pitch_data['fp_values']
            Fp_vals = pitch_data['Fp_values']

            if not fp_vals or not Fp_vals:
                return {}

            # Worst single pitch deviation fp max
            fp_max = max([abs(x) for x in fp_vals]) if fp_vals else 0

            # Worst spacing deviation fu max (ç›¸é‚»é½¿è·åå·®çš„æœ€å¤§å·®å€¼)
            fu_max = max([abs(fp_vals[i] - fp_vals[i-1]) for i in range(1, len(fp_vals))]) if len(fp_vals) > 1 else 0

            # Range of Pitch Error Rp
            Rp = max(fp_vals) - min(fp_vals) if fp_vals else 0

            # Total cum. pitch dev. Fp
            Fp_total = max(Fp_vals) - min(Fp_vals) if Fp_vals else 0

            # Cum. pitch deviation Fp10 (k=10çš„ç´¯ç§¯åå·®)
            k = 10
            Fp10_max = 0
            if len(fp_vals) > k:
                extended_fp = fp_vals + fp_vals[:k]
                window_sums = []
                for i in range(len(fp_vals)):
                    window_sum = sum(extended_fp[i:i+k])
                    window_sums.append(window_sum)
                Fp10_max = max([abs(x) for x in window_sums]) if window_sums else 0

            return {
                'fp_max': fp_max,
                'fu_max': fu_max,
                'Rp': Rp,
                'Fp': Fp_total,
                'Fp10': Fp10_max
            }

        left_stats = calc_pitch_stats(pitch_data_left)
        right_stats = calc_pitch_stats(pitch_data_right)

        # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
        if left_stats or right_stats:
            st.subheader("Pitch measuring circle:")

            # æ„å»ºè¡¨æ ¼æ•°æ®
            table_data = {
                '': [
                    'Worst single pitch deviation fp max',
                    'Worst spacing deviation fu max',
                    'Range of Pitch Error Rp',
                    'Total cum. pitch dev. Fp',
                    'Cum. pitch deviation Fp10'
                ],
                'left flank Act.value': [
                    f"{left_stats.get('fp_max', 0):.1f}" if left_stats else '',
                    f"{left_stats.get('fu_max', 0):.1f}" if left_stats else '',
                    f"{left_stats.get('Rp', 0):.1f}" if left_stats else '',
                    f"{left_stats.get('Fp', 0):.1f}" if left_stats else '',
                    f"{left_stats.get('Fp10', 0):.1f}" if left_stats else ''
                ],
                'left flank Qual.': ['', '', '', '', ''],
                'left flank Lim.value Qual.': ['12 5', '', '', '36 5', ''],
                'right flank Act.value': [
                    f"{right_stats.get('fp_max', 0):.1f}" if right_stats else '',
                    f"{right_stats.get('fu_max', 0):.1f}" if right_stats else '',
                    f"{right_stats.get('Rp', 0):.1f}" if right_stats else '',
                    f"{right_stats.get('Fp', 0):.1f}" if right_stats else '',
                    f"{right_stats.get('Fp10', 0):.1f}" if right_stats else ''
                ],
                'right flank Qual.': ['', '', '', '', ''],
                'right flank Lim.value Qual.': ['12 5', '', '', '36 5', '']
            }

            df_stats = pd.DataFrame(table_data)
            st.dataframe(df_stats, use_container_width=True, hide_index=True)

        st.markdown("---")
        st.markdown("### Pitch Deviation Detail Data")

        # å·¦é½¿é¢æ•°æ®è¡¨
        if pitch_left and pitch_left.teeth:
            st.subheader("Left Flank Pitch")
            df_left = pd.DataFrame({
                'Tooth Number': pitch_left.teeth,
                'fp (Î¼m)': pitch_left.fp_values,
                'Fp (Î¼m)': pitch_left.Fp_values
            })
            st.dataframe(df_left, use_container_width=True)

        # å³é½¿é¢æ•°æ®è¡¨
        if pitch_right and pitch_right.teeth:
            st.subheader("Right Flank Pitch")
            df_right = pd.DataFrame({
                'Tooth Number': pitch_right.teeth,
                'fp (Î¼m)': pitch_right.fp_values,
                'Fp (Î¼m)': pitch_right.Fp_values
            })
            st.dataframe(df_right, use_container_width=True)

        # ========== ç»¼åˆAIåˆ†æ ==========
        st.markdown("---")
        st.markdown("## ğŸ¤– ç»¼åˆAIåˆ†ææŠ¥å‘Š")
        
        # è®¡ç®—é¢‘è°±åˆ†æç»“æœ
        with st.spinner("æ­£åœ¨è®¡ç®—é¢‘è°±åˆ†æ..."):
            results = {
                'profile_left': analyzer.analyze_profile('left', verbose=False),
                'profile_right': analyzer.analyze_profile('right', verbose=False),
                'helix_left': analyzer.analyze_helix('left', verbose=False),
                'helix_right': analyzer.analyze_helix('right', verbose=False)
            }
        
        name_mapping = {
            'profile_left': 'Left Profile',
            'profile_right': 'Right Profile',
            'helix_left': 'Left Lead',
            'helix_right': 'Right Lead'
        }
        
        # æ”¶é›†æ‰€æœ‰åˆ†ææ•°æ®
        def generate_comprehensive_analysis():
            """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
            report = {
                'overall_score': 0,
                'status': 'æ­£å¸¸',
                'status_color': 'green',
                'profile_analysis': {},
                'helix_analysis': {},
                'pitch_analysis': {},
                'spectrum_analysis': {},
                'issues': [],
                'causes': [],
                'recommendations': [],
                'noise_prediction': 'ä½',
                'quality_grade': 'Q6'
            }
            
            scores = []
            
            # 1. é½¿å½¢åå·®åˆ†æ
            profile_score = 100
            profile_issues = []
            if profile_eval:
                # è·å–é½¿å½¢åå·®æ•°æ®
                for side in ['left', 'right']:
                    side_data = profile_data.get(side, {})
                    if side_data:
                        deviations = []
                        for tooth_id, tooth_profiles in side_data.items():
                            helix_mid = (helix_eval.eval_start + helix_eval.eval_end) / 2
                            best_z = min(tooth_profiles.keys(), key=lambda z: abs(z - helix_mid))
                            values = np.array(tooth_profiles[best_z])
                            F_a, fH_a, ff_a, Ca = calc_profile_deviations(values)
                            if F_a is not None:
                                deviations.append({'FÎ±': F_a, 'fHÎ±': fH_a, 'ffÎ±': ff_a})
                        
                        if deviations:
                            avg_Fa = np.mean([d['FÎ±'] for d in deviations])
                            avg_fHa = np.mean([d['fHÎ±'] for d in deviations])
                            avg_ffa = np.mean([d['ffÎ±'] for d in deviations])
                            
                            report['profile_analysis'][side] = {
                                'avg_FÎ±': avg_Fa,
                                'avg_fHÎ±': avg_fHa,
                                'avg_ffÎ±': avg_ffa
                            }
                            
                            # è¯„åˆ†
                            if avg_Fa > 15:
                                profile_score -= 20
                                profile_issues.append(f"{'å·¦' if side == 'left' else 'å³'}é½¿é¢é½¿å½¢æ€»åå·®FÎ±è¿‡å¤§({avg_Fa:.2f}Î¼m)")
                            elif avg_Fa > 10:
                                profile_score -= 10
                                profile_issues.append(f"{'å·¦' if side == 'left' else 'å³'}é½¿é¢é½¿å½¢æ€»åå·®FÎ±åå¤§({avg_Fa:.2f}Î¼m)")
                            
                            if avg_fHa > 8:
                                profile_score -= 10
                                profile_issues.append(f"{'å·¦' if side == 'left' else 'å³'}é½¿é¢é½¿å½¢å€¾æ–œåå·®fHÎ±è¿‡å¤§")
            
            scores.append(profile_score)
            report['profile_analysis']['score'] = profile_score
            report['profile_analysis']['issues'] = profile_issues
            
            # 2. é½¿å‘åå·®åˆ†æ
            helix_score = 100
            helix_issues = []
            if helix_eval:
                for side in ['left', 'right']:
                    side_data = helix_data.get(side, {})
                    if side_data:
                        deviations = []
                        for tooth_id, tooth_helix in side_data.items():
                            profile_mid = (profile_eval.eval_start + profile_eval.eval_end) / 2
                            best_d = min(tooth_helix.keys(), key=lambda d: abs(d - profile_mid))
                            values = np.array(tooth_helix[best_d])
                            F_b, fH_b, ff_b, Cb = calc_lead_deviations(values)
                            if F_b is not None:
                                deviations.append({'FÎ²': F_b, 'fHÎ²': fH_b, 'ffÎ²': ff_b})
                        
                        if deviations:
                            avg_Fb = np.mean([d['FÎ²'] for d in deviations])
                            avg_fHb = np.mean([d['fHÎ²'] for d in deviations])
                            avg_ffb = np.mean([d['ffÎ²'] for d in deviations])
                            
                            report['helix_analysis'][side] = {
                                'avg_FÎ²': avg_Fb,
                                'avg_fHÎ²': avg_fHb,
                                'avg_ffÎ²': avg_ffb
                            }
                            
                            if avg_Fb > 15:
                                helix_score -= 20
                                helix_issues.append(f"{'å·¦' if side == 'left' else 'å³'}é½¿é¢é½¿å‘æ€»åå·®FÎ²è¿‡å¤§({avg_Fb:.2f}Î¼m)")
                            elif avg_Fb > 10:
                                helix_score -= 10
                                helix_issues.append(f"{'å·¦' if side == 'left' else 'å³'}é½¿é¢é½¿å‘æ€»åå·®FÎ²åå¤§({avg_Fb:.2f}Î¼m)")
            
            scores.append(helix_score)
            report['helix_analysis']['score'] = helix_score
            report['helix_analysis']['issues'] = helix_issues
            
            # 3. å‘¨èŠ‚åå·®åˆ†æ
            pitch_score = 100
            pitch_issues = []
            if pitch_left:
                if pitch_left.fp_max > 10:
                    pitch_score -= 15
                    pitch_issues.append(f"å·¦é½¿é¢å•ä¸ªé½¿è·åå·®fpè¿‡å¤§({pitch_left.fp_max:.2f}Î¼m)")
                if pitch_left.Fp_max > 30:
                    pitch_score -= 15
                    pitch_issues.append(f"å·¦é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpè¿‡å¤§({pitch_left.Fp_max:.2f}Î¼m)")
                if pitch_left.Fr > 20:
                    pitch_score -= 10
                    pitch_issues.append(f"å·¦é½¿é¢å¾„å‘è·³åŠ¨Frè¿‡å¤§({pitch_left.Fr:.2f}Î¼m)")
                
                report['pitch_analysis']['left'] = {
                    'fp_max': pitch_left.fp_max,
                    'Fp_max': pitch_left.Fp_max,
                    'Fr': pitch_left.Fr
                }
            
            if pitch_right:
                if pitch_right.fp_max > 10:
                    pitch_score -= 15
                    pitch_issues.append(f"å³é½¿é¢å•ä¸ªé½¿è·åå·®fpè¿‡å¤§({pitch_right.fp_max:.2f}Î¼m)")
                if pitch_right.Fp_max > 30:
                    pitch_score -= 15
                    pitch_issues.append(f"å³é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpè¿‡å¤§({pitch_right.Fp_max:.2f}Î¼m)")
                if pitch_right.Fr > 20:
                    pitch_score -= 10
                    pitch_issues.append(f"å³é½¿é¢å¾„å‘è·³åŠ¨Frè¿‡å¤§({pitch_right.Fr:.2f}Î¼m)")
                
                report['pitch_analysis']['right'] = {
                    'fp_max': pitch_right.fp_max,
                    'Fp_max': pitch_right.Fp_max,
                    'Fr': pitch_right.Fr
                }
            
            scores.append(pitch_score)
            report['pitch_analysis']['score'] = pitch_score
            report['pitch_analysis']['issues'] = pitch_issues
            
            # 4. é¢‘è°±åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
            spectrum_score = 100
            spectrum_issues = []
            ze = gear_params.teeth_count if gear_params else 87
            
            for name in ['profile_left', 'profile_right', 'helix_left', 'helix_right']:
                if name in results and results[name]:
                    result = results[name]
                    sorted_components = sorted(result.spectrum_components[:10], key=lambda c: c.order)
                    
                    # æ£€æŸ¥ä¸»å¯¼é˜¶æ¬¡
                    for comp in sorted_components:
                        if abs(comp.order - ze) < 1:
                            if comp.amplitude > 0.1:
                                spectrum_score -= 10
                                spectrum_issues.append(f"{name_mapping.get(name, name)}ä¸»å¯¼é˜¶æ¬¡ZEå¹…å€¼è¿‡é«˜({comp.amplitude:.4f}Î¼m)")
                            break
            
            scores.append(spectrum_score)
            report['spectrum_analysis']['score'] = spectrum_score
            report['spectrum_analysis']['issues'] = spectrum_issues
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            overall_score = np.mean(scores) if scores else 100
            report['overall_score'] = overall_score
            
            # ç¡®å®šçŠ¶æ€
            if overall_score >= 90:
                report['status'] = 'ä¼˜ç§€'
                report['status_color'] = 'green'
                report['noise_prediction'] = 'å¾ˆä½'
                report['quality_grade'] = 'Q5'
            elif overall_score >= 80:
                report['status'] = 'è‰¯å¥½'
                report['status_color'] = 'lightgreen'
                report['noise_prediction'] = 'ä½'
                report['quality_grade'] = 'Q6'
            elif overall_score >= 70:
                report['status'] = 'åˆæ ¼'
                report['status_color'] = 'yellow'
                report['noise_prediction'] = 'ä¸­ç­‰'
                report['quality_grade'] = 'Q7'
            elif overall_score >= 60:
                report['status'] = 'éœ€å…³æ³¨'
                report['status_color'] = 'orange'
                report['noise_prediction'] = 'é«˜'
                report['quality_grade'] = 'Q8'
            else:
                report['status'] = 'ä¸åˆæ ¼'
                report['status_color'] = 'red'
                report['noise_prediction'] = 'å¾ˆé«˜'
                report['quality_grade'] = 'Q9+'
            
            # æ±‡æ€»é—®é¢˜
            all_issues = profile_issues + helix_issues + pitch_issues + spectrum_issues
            report['issues'] = all_issues
            
            # ç”ŸæˆåŸå› åˆ†æ
            if any('FÎ±' in issue for issue in all_issues):
                report['causes'].append("é½¿å½¢è¯¯å·®å¯èƒ½ç”±åˆ€å…·ç£¨æŸã€æœºåºŠåˆ†åº¦è¯¯å·®æˆ–åŠ å·¥å‚æ•°ä¸å½“å¼•èµ·")
            if any('FÎ²' in issue for issue in all_issues):
                report['causes'].append("é½¿å‘è¯¯å·®å¯èƒ½ç”±æœºåºŠå¯¼è½¨è¯¯å·®ã€å·¥ä»¶è£…å¤¹å˜å½¢æˆ–çƒ­å˜å½¢å¼•èµ·")
            if any('fp' in issue for issue in all_issues):
                report['causes'].append("é½¿è·è¯¯å·®å¯èƒ½ç”±åˆ†åº¦æœºæ„è¯¯å·®ã€åˆ€å…·è¯¯å·®æˆ–å·¥ä»¶åå¿ƒå¼•èµ·")
            if any('Fr' in issue for issue in all_issues):
                report['causes'].append("å¾„å‘è·³åŠ¨å¯èƒ½ç”±å·¥ä»¶å®‰è£…åå¿ƒã€è½´æ‰¿é—´éš™æˆ–ä¸»è½´è·³åŠ¨å¼•èµ·")
            if any('ZE' in issue for issue in all_issues):
                report['causes'].append("ä¸»å¯¼é˜¶æ¬¡å¹…å€¼é«˜å¯èƒ½ç”±åˆ†åº¦è¯¯å·®ã€åˆ€å…·è¯¯å·®æˆ–é½¿è½®åå¿ƒå¼•èµ·")
            
            if not report['causes']:
                report['causes'].append("é½¿è½®å„é¡¹æŒ‡æ ‡æ­£å¸¸ï¼ŒåŠ å·¥è´¨é‡è‰¯å¥½")
            
            # ç”Ÿæˆæ”¹è¿›å»ºè®®
            if overall_score < 80:
                report['recommendations'].append("å»ºè®®å…¨é¢æ£€æŸ¥åŠ å·¥æœºåºŠç²¾åº¦å’Œåˆ€å…·çŠ¶æ€")
            if any('FÎ±' in issue for issue in all_issues):
                report['recommendations'].append("ä¼˜åŒ–é½¿å½¢åŠ å·¥ï¼šæ£€æŸ¥åˆ€å…·ç£¨æŸï¼Œè°ƒæ•´åŠ å·¥å‚æ•°")
            if any('FÎ²' in issue for issue in all_issues):
                report['recommendations'].append("ä¼˜åŒ–é½¿å‘åŠ å·¥ï¼šæ£€æŸ¥æœºåºŠå¯¼è½¨ï¼Œæ”¹å–„è£…å¤¹æ–¹å¼")
            if any('fp' in issue or 'Fp' in issue for issue in all_issues):
                report['recommendations'].append("ä¼˜åŒ–é½¿è·ç²¾åº¦ï¼šæ£€æŸ¥åˆ†åº¦æœºæ„ï¼Œæ ¡å‡†åˆ€å…·")
            if any('Fr' in issue for issue in all_issues):
                report['recommendations'].append("é™ä½å¾„å‘è·³åŠ¨ï¼šæ”¹å–„å·¥ä»¶è£…å¤¹ï¼Œæ£€æŸ¥ä¸»è½´ç²¾åº¦")
            
            if not report['recommendations']:
                report['recommendations'].append("ç»§ç»­ä¿æŒå½“å‰åŠ å·¥å·¥è‰ºï¼Œå®šæœŸç›‘æµ‹è´¨é‡")
            
            return report
        
        # ç”ŸæˆæŠ¥å‘Š
        comprehensive_report = generate_comprehensive_analysis()
        
        # æ˜¾ç¤ºç»¼åˆè¯„åˆ†
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç»¼åˆè¯„åˆ†", f"{comprehensive_report['overall_score']:.0f}åˆ†")
        with col2:
            status_color = comprehensive_report['status_color']
            st.markdown(f"**çŠ¶æ€: <span style='color:{status_color};font-size:20px;font-weight:bold;'>{comprehensive_report['status']}</span>**", unsafe_allow_html=True)
        with col3:
            st.metric("è´¨é‡ç­‰çº§", comprehensive_report['quality_grade'])
        with col4:
            noise_color = 'green' if comprehensive_report['noise_prediction'] in ['å¾ˆä½', 'ä½'] else 'orange' if comprehensive_report['noise_prediction'] == 'ä¸­ç­‰' else 'red'
            st.markdown(f"**å™ªå£°é¢„æµ‹: <span style='color:{noise_color};'>{comprehensive_report['noise_prediction']}</span>**", unsafe_allow_html=True)
        
        # åˆ†é¡¹è¯„åˆ†
        st.markdown("### ğŸ“Š åˆ†é¡¹è¯„åˆ†")
        score_cols = st.columns(4)
        with score_cols[0]:
            profile_score = comprehensive_report['profile_analysis'].get('score', 100)
            st.metric("é½¿å½¢åå·®", f"{profile_score:.0f}åˆ†")
            st.progress(profile_score / 100)
        with score_cols[1]:
            helix_score = comprehensive_report['helix_analysis'].get('score', 100)
            st.metric("é½¿å‘åå·®", f"{helix_score:.0f}åˆ†")
            st.progress(helix_score / 100)
        with score_cols[2]:
            pitch_score = comprehensive_report['pitch_analysis'].get('score', 100)
            st.metric("å‘¨èŠ‚åå·®", f"{pitch_score:.0f}åˆ†")
            st.progress(pitch_score / 100)
        with score_cols[3]:
            spectrum_score = comprehensive_report['spectrum_analysis'].get('score', 100)
            st.metric("é¢‘è°±åˆ†æ", f"{spectrum_score:.0f}åˆ†")
            st.progress(spectrum_score / 100)
        
        # é—®é¢˜æ±‡æ€»
        st.markdown("### ğŸ“‹ é—®é¢˜æ±‡æ€»")
        if comprehensive_report['issues']:
            for issue in comprehensive_report['issues']:
                st.markdown(f"- ğŸ”´ {issue}")
        else:
            st.markdown("- âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜")
        
        # åŸå› åˆ†æ
        st.markdown("### ğŸ” åŸå› åˆ†æ")
        for cause in comprehensive_report['causes']:
            st.markdown(f"- {cause}")
        
        # æ”¹è¿›å»ºè®®
        st.markdown("### ğŸ’¡ æ”¹è¿›å»ºè®®")
        for rec in comprehensive_report['recommendations']:
            st.markdown(f"- {rec}")
        
        # è¯¦ç»†æ•°æ®
        with st.expander("ğŸ“Š è¯¦ç»†åˆ†ææ•°æ®", expanded=False):
            # é½¿å½¢æ•°æ®
            if comprehensive_report['profile_analysis']:
                st.markdown("**é½¿å½¢åå·®æ•°æ®:**")
                profile_df_data = []
                for side, data in comprehensive_report['profile_analysis'].items():
                    if isinstance(data, dict) and 'avg_FÎ±' in data:
                        profile_df_data.append({
                            'é½¿é¢': 'å·¦é½¿é¢' if side == 'left' else 'å³é½¿é¢',
                            'FÎ± (Î¼m)': f"{data['avg_FÎ±']:.2f}",
                            'fHÎ± (Î¼m)': f"{data['avg_fHÎ±']:.2f}",
                            'ffÎ± (Î¼m)': f"{data['avg_ffÎ±']:.2f}"
                        })
                if profile_df_data:
                    st.dataframe(pd.DataFrame(profile_df_data), use_container_width=True, hide_index=True)
            
            # é½¿å‘æ•°æ®
            if comprehensive_report['helix_analysis']:
                st.markdown("**é½¿å‘åå·®æ•°æ®:**")
                helix_df_data = []
                for side, data in comprehensive_report['helix_analysis'].items():
                    if isinstance(data, dict) and 'avg_FÎ²' in data:
                        helix_df_data.append({
                            'é½¿é¢': 'å·¦é½¿é¢' if side == 'left' else 'å³é½¿é¢',
                            'FÎ² (Î¼m)': f"{data['avg_FÎ²']:.2f}",
                            'fHÎ² (Î¼m)': f"{data['avg_fHÎ²']:.2f}",
                            'ffÎ² (Î¼m)': f"{data['avg_ffÎ²']:.2f}"
                        })
                if helix_df_data:
                    st.dataframe(pd.DataFrame(helix_df_data), use_container_width=True, hide_index=True)
            
            # å‘¨èŠ‚æ•°æ®
            if comprehensive_report['pitch_analysis']:
                st.markdown("**å‘¨èŠ‚åå·®æ•°æ®:**")
                pitch_df_data = []
                for side, data in comprehensive_report['pitch_analysis'].items():
                    if isinstance(data, dict) and 'fp_max' in data:
                        pitch_df_data.append({
                            'é½¿é¢': 'å·¦é½¿é¢' if side == 'left' else 'å³é½¿é¢',
                            'fp max (Î¼m)': f"{data['fp_max']:.2f}",
                            'Fp max (Î¼m)': f"{data['Fp_max']:.2f}",
                            'Fr (Î¼m)': f"{data['Fr']:.2f}"
                        })
                if pitch_df_data:
                    st.dataframe(pd.DataFrame(pitch_df_data), use_container_width=True, hide_index=True)

    elif page == 'ğŸ“ˆ å•é½¿åˆ†æ':
        st.markdown("## Single Tooth Analysis")

        # è·å–æ‰€æœ‰æœ‰æµ‹é‡æ•°æ®çš„é½¿
        measured_teeth = set()
        for side in ['left', 'right']:
            if side in profile_data:
                measured_teeth.update(profile_data[side].keys())
            if side in helix_data:
                measured_teeth.update(helix_data[side].keys())
        
        # æŒ‰é¡ºåºæ’åˆ—æœ‰æµ‹é‡æ•°æ®çš„é½¿ï¼ˆä½¿ç”¨æ•°å­—æ’åºï¼‰
        measured_teeth_list = sorted(list(measured_teeth), key=tooth_sort_key)
        
        if not measured_teeth_list:
            st.warning("æœªæ‰¾åˆ°æµ‹é‡æ•°æ®")
            st.stop()
        
        # ä½¿ç”¨ä¸‹æ‹‰æ¡†é€‰æ‹©æœ‰æµ‹é‡æ•°æ®çš„é½¿
        selected_tooth = st.selectbox("Select Tooth Number", options=measured_teeth_list)
        
        # è·å–é½¿è½®å‚æ•°
        ze = gear_params.teeth_count if gear_params else 87
        
        # é½¿å½¢åˆ†æ
        st.markdown("### Profile Analysis")
        for side in ['left', 'right']:
            side_name = 'Left Profile' if side == 'left' else 'Right Profile'
            
            if selected_tooth in profile_data.get(side, {}):
                st.markdown(f"#### {side_name} - Tooth {selected_tooth}")
                
                # è·å–æ•°æ®
                tooth_profiles = profile_data[side][selected_tooth]
                helix_mid = (helix_eval.eval_start + helix_eval.eval_end) / 2
                best_z = min(tooth_profiles.keys(), key=lambda z: abs(z - helix_mid))
                raw_values = np.array(tooth_profiles[best_z])
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                d1, d2 = analyzer.reader.d1, analyzer.reader.d2
                da, de = d1, d2  # é»˜è®¤ä½¿ç”¨è¯„ä¼°èŒƒå›´
                
                # è§£ææµ‹é‡èŒƒå›´
                da_match = re.search(r'Start\s+Messbereich.*?da\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if da_match:
                    da = float(da_match.group(1))
                de_match = re.search(r'Ende\s+der\s+Messstrecke.*?de\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if de_match:
                    de = float(de_match.group(1))
                
                # è®¡ç®—å±•é•¿èŒƒå›´
                base_radius = gear_params.base_diameter / 2 if gear_params else 80
                meas_start_radius = da / 2.0
                meas_end_radius = de / 2.0
                eval_start_radius = d1 / 2.0
                eval_end_radius = d2 / 2.0
                
                meas_start_spread = np.sqrt(max(0, meas_start_radius**2 - base_radius**2))
                meas_end_spread = np.sqrt(max(0, meas_end_radius**2 - base_radius**2))
                eval_start_spread = np.sqrt(max(0, eval_start_radius**2 - base_radius**2))
                eval_end_spread = np.sqrt(max(0, eval_end_radius**2 - base_radius**2))
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                total_spread = meas_end_spread - meas_start_spread
                if total_spread > 0:
                    start_ratio = (eval_start_spread - meas_start_spread) / total_spread
                    end_ratio = (eval_end_spread - meas_start_spread) / total_spread
                    
                    n_total = len(raw_values)
                    start_idx = max(0, int(start_ratio * n_total))
                    end_idx = min(n_total, int(end_ratio * n_total))
                    
                    if end_idx - start_idx > 10:
                        raw_values = raw_values[start_idx:end_idx]
                
                # å»é™¤é¼“å½¢å’Œæ–œç‡
                values = analyzer._remove_crown_and_slope(raw_values)
                
                # è®¡ç®—é¢‘è°±
                if len(values) > 8:
                    # åˆ›å»ºè§’åº¦æ•°ç»„ï¼ˆ0-360åº¦ï¼‰
                    angles = np.linspace(0, 360, len(values))
                    # è®¡ç®—é¢‘è°±
                    spectrum_components = analyzer._iterative_sine_decomposition(angles, values, num_components=10, max_order=50)
                    
                    # æ˜¾ç¤ºæŒ‡æ ‡
                    if spectrum_components:
                        col1, col2, col3, col4 = st.columns(4)
                        max_comp = spectrum_components[0]
                        high_order_comps = [c for c in spectrum_components if c.order >= ze]
                        
                        with col1:
                            st.metric("Max Amplitude", f"{max_comp.amplitude:.4f} Î¼m")
                        with col2:
                            st.metric("Max Order", int(max_comp.order))
                        with col3:
                            st.metric("Wave Count", len(spectrum_components))
                        with col4:
                            rms = np.sqrt(np.mean([c.amplitude**2 for c in high_order_comps])) if high_order_comps else 0
                            st.metric("High Order RMS", f"{rms:.4f} Î¼m")
                
                # åˆ›å»ºæ›²çº¿å›¾
                fig, ax = plt.subplots(figsize=(10, 5))
                
                # è®¡ç®—å±•é•¿ä½œä¸ºXè½´
                d1, d2 = analyzer.reader.d1, analyzer.reader.d2
                
                # å±•é•¿è®¡ç®—
                base_radius = gear_params.base_diameter / 2 if gear_params else 80
                eval_start_radius = d1 / 2.0
                eval_end_radius = d2 / 2.0
                eval_start_spread = np.sqrt(max(0, eval_start_radius**2 - base_radius**2))
                eval_end_spread = np.sqrt(max(0, eval_end_radius**2 - base_radius**2))
                
                x_data = np.linspace(eval_start_spread, eval_end_spread, len(values))
                
                ax.plot(x_data, values, 'b-', linewidth=1.0, label='Raw Data')
                
                # æ ‡è®°è¯„ä»·èŒƒå›´
                ax.axvline(x=eval_start_spread, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Eval Start')
                ax.axvline(x=eval_end_spread, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Eval End')
                
                ax.set_title(f"{side_name} - Tooth {selected_tooth}", fontsize=12, fontweight='bold')
                ax.set_xlabel("Spread Length (mm)")
                ax.set_ylabel("Deviation (Î¼m)")
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close(fig)
        
        # é½¿å‘åˆ†æ
        st.markdown("### Lead Analysis")
        for side in ['left', 'right']:
            side_name = 'Left Lead' if side == 'left' else 'Right Lead'
            
            if selected_tooth in helix_data.get(side, {}):
                st.markdown(f"#### {side_name} - Tooth {selected_tooth}")
                
                # è·å–æ•°æ®
                tooth_helix = helix_data[side][selected_tooth]
                profile_mid = (profile_eval.eval_start + profile_eval.eval_end) / 2
                best_d = min(tooth_helix.keys(), key=lambda d: abs(d - profile_mid))
                raw_values = np.array(tooth_helix[best_d])
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                b1, b2 = analyzer.reader.b1, analyzer.reader.b2
                ba, be = b1, b2  # é»˜è®¤ä½¿ç”¨è¯„ä¼°èŒƒå›´
                
                # è§£ææµ‹é‡èŒƒå›´
                ba_match = re.search(r'Messanfang.*?ba\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if ba_match:
                    ba = float(ba_match.group(1))
                be_match = re.search(r'Messende.*?be\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if be_match:
                    be = float(be_match.group(1))
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                meas_length = be - ba
                if meas_length > 0:
                    start_ratio = (min(b1, b2) - ba) / meas_length
                    end_ratio = (max(b1, b2) - ba) / meas_length
                    
                    n_total = len(raw_values)
                    start_idx = max(0, int(start_ratio * n_total))
                    end_idx = min(n_total, int(end_ratio * n_total))
                    
                    if end_idx - start_idx > 10:
                        raw_values = raw_values[start_idx:end_idx]
                
                # å»é™¤é¼“å½¢å’Œæ–œç‡
                values = analyzer._remove_crown_and_slope(raw_values)
                
                # è®¡ç®—é¢‘è°±
                if len(values) > 8:
                    angles = np.linspace(0, 360, len(values))
                    spectrum_components = analyzer._iterative_sine_decomposition(angles, values, num_components=10, max_order=50)
                    
                    # æ˜¾ç¤ºæŒ‡æ ‡
                    if spectrum_components:
                        col1, col2, col3, col4 = st.columns(4)
                        max_comp = spectrum_components[0]
                        high_order_comps = [c for c in spectrum_components if c.order >= ze]
                        
                        with col1:
                            st.metric("Max Amplitude", f"{max_comp.amplitude:.4f} Î¼m")
                        with col2:
                            st.metric("Max Order", int(max_comp.order))
                        with col3:
                            st.metric("Wave Count", len(spectrum_components))
                        with col4:
                            rms = np.sqrt(np.mean([c.amplitude**2 for c in high_order_comps])) if high_order_comps else 0
                            st.metric("High Order RMS", f"{rms:.4f} Î¼m")
                
                # åˆ›å»ºæ›²çº¿å›¾
                fig, ax = plt.subplots(figsize=(10, 5))
                
                # é½¿å‘ä½ç½®ä½œä¸ºXè½´
                b1, b2 = analyzer.reader.b1, analyzer.reader.b2
                
                x_data = np.linspace(b1, b2, len(values))
                
                ax.plot(x_data, values, 'g-', linewidth=1.0, label='Raw Data')
                
                # æ ‡è®°è¯„ä»·èŒƒå›´
                ax.axvline(x=b1, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label=f'b1={b1:.2f}')
                ax.axvline(x=b2, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label=f'b2={b2:.2f}')
                
                ax.set_title(f"{side_name} - Tooth {selected_tooth}", fontsize=12, fontweight='bold')
                ax.set_xlabel("Face Width Position (mm)")
                ax.set_ylabel("Deviation (Î¼m)")
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close(fig)
        
        # å•é½¿æ‰©å±•åˆå¹¶æ›²çº¿
        st.markdown("---")
        st.markdown("### Single Tooth Expanded Merged Curve (0-360Â°)")
        st.info("å°†å•é½¿æ›²çº¿å¤åˆ¶åˆ°æ‰€æœ‰é½¿ï¼Œå½¢æˆå®Œæ•´çš„0-360Â°åˆå¹¶æ›²çº¿ï¼Œç”¨äºè®¡ç®—å®Œæ•´é¢‘è°±")
        
        pitch_angle = 360.0 / ze if ze > 0 else 4.14
        
        for side in ['left', 'right']:
            side_name = 'Left Profile' if side == 'left' else 'Right Profile'
            
            if selected_tooth in profile_data.get(side, {}):
                # è·å–å•é½¿æ•°æ®
                tooth_profiles = profile_data[side][selected_tooth]
                helix_mid = (helix_eval.eval_start + helix_eval.eval_end) / 2
                best_z = min(tooth_profiles.keys(), key=lambda z: abs(z - helix_mid))
                raw_values = np.array(tooth_profiles[best_z])
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                d1, d2 = analyzer.reader.d1, analyzer.reader.d2
                da, de = d1, d2
                
                # è§£ææµ‹é‡èŒƒå›´
                da_match = re.search(r'Start\s+Messbereich.*?da\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if da_match:
                    da = float(da_match.group(1))
                de_match = re.search(r'Ende\s+der\s+Messstrecke.*?de\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if de_match:
                    de = float(de_match.group(1))
                
                # è®¡ç®—å±•é•¿èŒƒå›´
                base_radius = gear_params.base_diameter / 2 if gear_params else 80
                meas_start_radius = da / 2.0
                meas_end_radius = de / 2.0
                eval_start_radius = d1 / 2.0
                eval_end_radius = d2 / 2.0
                
                meas_start_spread = np.sqrt(max(0, meas_start_radius**2 - base_radius**2))
                meas_end_spread = np.sqrt(max(0, meas_end_radius**2 - base_radius**2))
                eval_start_spread = np.sqrt(max(0, eval_start_radius**2 - base_radius**2))
                eval_end_spread = np.sqrt(max(0, eval_end_radius**2 - base_radius**2))
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                total_spread = meas_end_spread - meas_start_spread
                if total_spread > 0:
                    start_ratio = (eval_start_spread - meas_start_spread) / total_spread
                    end_ratio = (eval_end_spread - meas_start_spread) / total_spread
                    
                    n_total = len(raw_values)
                    start_idx = max(0, int(start_ratio * n_total))
                    end_idx = min(n_total, int(end_ratio * n_total))
                    
                    if end_idx - start_idx > 10:
                        raw_values = raw_values[start_idx:end_idx]
                
                # å»é™¤é¼“å½¢å’Œæ–œç‡
                values = analyzer._remove_crown_and_slope(raw_values)
                
                if len(values) > 5:
                    # ä½¿ç”¨å±•è§’è®¡ç®—å•é½¿çš„è§’åº¦æ•°ç»„
                    # å±•è§’ Î¸ = L / rb (å±•é•¿ / åŸºåœ†åŠå¾„)
                    n = len(values)
                    spread_lengths = np.linspace(eval_start_spread, eval_end_spread, n)
                    roll_angles = spread_lengths / base_radius  # å±•è§’ï¼ˆå¼§åº¦ï¼‰
                    
                    # èµ·å§‹å±•è§’ä¸º0
                    start_roll_angle = roll_angles[0]
                    point_angles_deg = np.degrees(roll_angles - start_roll_angle)
                    single_angles = point_angles_deg  # å•é½¿å†…çš„è§’åº¦å˜åŒ–
                    
                    # æ‰©å±•åˆ°æ‰€æœ‰é½¿
                    expanded_angles = []
                    expanded_values = []
                    
                    for tooth_num in range(ze):
                        tooth_base = tooth_num * pitch_angle
                        for angle, value in zip(single_angles, values):
                            new_angle = tooth_base + angle
                            if new_angle < 360:
                                expanded_angles.append(new_angle)
                                expanded_values.append(value)
                    
                    expanded_angles = np.array(expanded_angles)
                    expanded_values = np.array(expanded_values)
                    
                    # æ’åº
                    sort_idx = np.argsort(expanded_angles)
                    expanded_angles = expanded_angles[sort_idx]
                    expanded_values = expanded_values[sort_idx]
                    
                    # è®¡ç®—é«˜é˜¶é‡å»ºä¿¡å·
                    angles_rad = np.deg2rad(expanded_angles)
                    reconstructed = np.zeros_like(expanded_values)
                    
                    # è®¡ç®—é¢‘è°±
                    if len(expanded_angles) > 8:
                        spectrum_components = analyzer._iterative_sine_decomposition(expanded_angles, expanded_values, num_components=10, max_order=5*ze)
                        high_order_comps = [c for c in spectrum_components if c.order >= ze]
                        
                        for comp in high_order_comps:
                            a = comp.amplitude * np.sin(comp.phase)
                            b = comp.amplitude * np.cos(comp.phase)
                            reconstructed += a * np.cos(comp.order * angles_rad) + b * np.sin(comp.order * angles_rad)
                        
                        # æ˜¾ç¤ºæŒ‡æ ‡
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            high_order_amplitude = sum(c.amplitude for c in high_order_comps) if high_order_comps else 0.0
                            st.metric("High Order Amplitude W", f"{high_order_amplitude:.4f} Î¼m")
                        with col2:
                            high_order_rms = np.sqrt(sum(c.amplitude**2 for c in high_order_comps)) if high_order_comps else 0.0
                            st.metric("High Order RMS", f"{high_order_rms:.4f} Î¼m")
                        with col3:
                            st.metric("High Order Wave Count", len(high_order_comps))
                        with col4:
                            if spectrum_components:
                                st.metric("Dominant Order", int(spectrum_components[0].order))
                    
                    # ç»˜åˆ¶åˆå¹¶æ›²çº¿
                    fig, ax = plt.subplots(figsize=(14, 5))
                    ax.plot(expanded_angles, expanded_values, 'b-', linewidth=0.5, alpha=0.7, label='Raw Curve')
                    ax.plot(expanded_angles, reconstructed, 'r-', linewidth=1.5, label='High Order Reconstruction')
                    
                    # æ·»åŠ é½¿æ•°æ ‡å¿—
                    for tooth_num in range(ze + 1):
                        tooth_angle = tooth_num * pitch_angle
                        if tooth_angle <= 360:
                            ax.axvline(x=tooth_angle, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
                            if tooth_num % 5 == 0 or tooth_num == ze:
                                ax.text(tooth_angle, ax.get_ylim()[1] * 0.95, str(tooth_num), 
                                       ha='center', va='top', fontsize=7, color='gray', alpha=0.7)
                    
                    ax.set_xlabel('Rotation Angle (Â°)')
                    ax.set_ylabel('Deviation (Î¼m)')
                    ax.set_title(f'{side_name} - Single Tooth Expanded Merged Curve (ZE={ze})')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    ax.set_xlim(0, 360)
                    st.pyplot(fig)
                    plt.close(fig)
                    
                    # æ˜¾ç¤ºå•é½¿æ‰©å±•åˆå¹¶æ›²çº¿çš„é¢‘è°±å›¾
                    if spectrum_components:
                        st.markdown(f"**{side_name} - Single Tooth Expanded Spectrum**")
                        
                        # è®¡ç®—æé™æ›²çº¿
                        def calculate_tolerance_curve_single(orders, R, N0, K):
                            tolerances = []
                            for O in orders:
                                if O <= 1:
                                    tolerances.append(R)
                                else:
                                    N = N0 + K / O
                                    tolerance = R / ((O - 1) ** N)
                                    tolerances.append(tolerance)
                            return tolerances

                        # æ ¹æ®å®é™…æ•°æ®è‡ªåŠ¨è®¡ç®—æé™æ›²çº¿å‚æ•°
                        orders_spec = [c.order for c in spectrum_components[:15]]
                        amplitudes_spec = [c.amplitude for c in spectrum_components[:15]]
                        
                        if amplitudes_spec and orders_spec:
                            N0_auto = 0.6
                            K_auto = 2.8
                            
                            # æ‰¾åˆ°ZEå¤„çš„å¹…å€¼
                            ze_amplitude = None
                            for o, amp in zip(orders_spec, amplitudes_spec):
                                if abs(o - ze) < 1:
                                    if ze_amplitude is None or amp > ze_amplitude:
                                        ze_amplitude = amp
                            
                            if ze_amplitude is not None:
                                N_at_ze = N0_auto + K_auto / ze
                                R_auto = ze_amplitude * 1.5 * ((ze - 1) ** N_at_ze)
                            else:
                                max_amp = max(amplitudes_spec)
                                R_auto = max_amp * 2.0 * ((ze - 1) ** (N0_auto + K_auto / ze))
                            
                            R_auto = max(0.0001, min(R_auto, 10.0))
                        else:
                            R_auto = 0.0039
                            N0_auto = 0.6
                            K_auto = 2.8
                        
                        # æ˜¾ç¤ºæé™æ›²çº¿å‚æ•°å¹¶å¯è°ƒèŠ‚
                        st.markdown("**Limit Curve Parameters**")
                        st.markdown("*Formula: Tolerance = R / (O-1)^(Nâ‚€+K/O)*")
                        col_p1, col_p2, col_p3 = st.columns(3)
                        with col_p1:
                            R_input = st.number_input("R (mm)", min_value=0.0001, max_value=10.0, value=float(R_auto), step=0.0001, format="%.4f", key=f"R_single_{side}")
                        with col_p2:
                            N0_input = st.number_input("Nâ‚€", min_value=0.0, max_value=5.0, value=float(N0_auto), step=0.1, format="%.1f", key=f"N0_single_{side}")
                        with col_p3:
                            K_input = st.number_input("K", min_value=0.0, max_value=10.0, value=float(K_auto), step=0.1, format="%.1f", key=f"K_single_{side}")
                        
                        col1, col2 = st.columns([3, 2])
                        
                        with col1:
                            # Top 10 é˜¶æ¬¡è¡¨æ ¼
                            st.markdown("**Top 10 Largest Orders:**")
                            top_10_data = []
                            for i, comp in enumerate(spectrum_components[:10], 1):
                                top_10_data.append({
                                    'Rank': i,
                                    'Order': int(comp.order),
                                    'Amplitude (Î¼m)': f"{comp.amplitude:.4f}",
                                    'Phase (Â°)': f"{np.degrees(comp.phase):.1f}"
                                })
                            st.dataframe(pd.DataFrame(top_10_data), use_container_width=True, hide_index=True)
                        
                        with col2:
                            # é¢‘è°±å›¾
                            fig2, ax2 = plt.subplots(figsize=(8, 5))
                            
                            orders = [c.order for c in spectrum_components[:15]]
                            amplitudes = [c.amplitude for c in spectrum_components[:15]]
                            
                            # è®¡ç®—æ¯ä¸ªé˜¶æ¬¡çš„æé™å€¼
                            tolerance_values = calculate_tolerance_curve_single(orders, R_input, N0_input, K_input)
                            
                            # æ ¹æ®æ˜¯å¦è¶…å‡ºæé™è®¾ç½®é¢œè‰²
                            colors = ['red' if amp > tol else 'steelblue' for amp, tol in zip(amplitudes, tolerance_values)]
                            ax2.bar(orders, amplitudes, color=colors, alpha=0.7, width=3, label='Amplitude')
                            
                            # æ ‡è®°ZEåŠå…¶å€æ•°
                            ze_multiples = [ze * i for i in range(1, 5) if ze * i <= max(orders)]
                            for i, ze_mult in enumerate(ze_multiples, 1):
                                if i == 1:
                                    ax2.axvline(x=ze_mult, color='green', linestyle='--', linewidth=2, label=f'ZE={ze}')
                                else:
                                    ax2.axvline(x=ze_mult, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)
                            
                            # ç»˜åˆ¶æé™æ›²çº¿ï¼ˆæ©˜é»„è‰²ï¼‰
                            order_range = np.linspace(2, max(orders) + 10, 200)
                            tolerance_curve = calculate_tolerance_curve_single(order_range, R_input, N0_input, K_input)
                            ax2.plot(order_range, tolerance_curve, color='darkorange', linewidth=2.5, label='Tolerance Limit', linestyle='-')
                            
                            # è®¾ç½®Yè½´èŒƒå›´
                            max_amplitude = max(amplitudes) if amplitudes else 1
                            max_tolerance = max(tolerance_curve) if len(tolerance_curve) > 0 else 1
                            y_max = max(max_amplitude, max_tolerance) * 1.2
                            ax2.set_ylim(0, y_max)
                            
                            ax2.set_title(f'Single Tooth Expanded Spectrum (ZE={ze})', fontsize=10, fontweight='bold')
                            ax2.set_xlabel('Order')
                            ax2.set_ylabel('Amplitude (Î¼m) / Tolerance (mm)')
                            ax2.legend(loc='upper right')
                            ax2.grid(True, alpha=0.3)
                            st.pyplot(fig2)
                            plt.close(fig2)
                    
                    # æ˜¾ç¤ºå‰5ä¸ªé½¿çš„æ”¾å¤§è§†å›¾
                    st.markdown(f"**{side_name} - First 5 Teeth Zoom View**")
                    
                    # è®¡ç®—å‰5ä¸ªé½¿çš„è§’åº¦èŒƒå›´
                    end_angle = 5 * pitch_angle
                    zoom_mask = expanded_angles <= end_angle
                    zoom_angles = expanded_angles[zoom_mask]
                    zoom_values = expanded_values[zoom_mask]
                    zoom_reconstructed = reconstructed[zoom_mask]
                    
                    if len(zoom_angles) > 0:
                        fig3, ax3 = plt.subplots(figsize=(12, 4))
                        
                        # é™é‡‡æ ·ä»¥æ”¹å–„æ˜¾ç¤º
                        if len(zoom_angles) > 5000:
                            step = len(zoom_angles) // 2000 + 1
                            zoom_angles = zoom_angles[::step]
                            zoom_values = zoom_values[::step]
                            zoom_reconstructed = zoom_reconstructed[::step]
                        
                        ax3.plot(zoom_angles, zoom_values, 'b-', linewidth=1.0, alpha=0.8, label='Raw Curve')
                        ax3.plot(zoom_angles, zoom_reconstructed, 'r-', linewidth=2.0, label='High Order Reconstruction')
                        
                        # æ·»åŠ é½¿æ•°æ ‡å¿—
                        for tooth_num in range(6):  # 0åˆ°5
                            tooth_angle = tooth_num * pitch_angle
                            if tooth_angle <= end_angle:
                                ax3.axvline(x=tooth_angle, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
                                ax3.text(tooth_angle, ax3.get_ylim()[1] * 0.95, str(tooth_num), 
                                        ha='center', va='top', fontsize=8, color='gray', alpha=0.7)
                        
                        ax3.set_xlabel('Rotation Angle (Â°)')
                        ax3.set_ylabel('Deviation (Î¼m)')
                        ax3.set_title(f'{side_name} - First 5 Teeth (0Â° ~ {end_angle:.1f}Â°)')
                        ax3.legend()
                        ax3.grid(True, alpha=0.3)
                        ax3.set_xlim(0, end_angle)
                        st.pyplot(fig3)
                        plt.close(fig3)
        
        # å•é½¿é½¿å‘æ‰©å±•åˆå¹¶æ›²çº¿
        st.markdown("---")
        st.markdown("### Single Tooth Lead Expanded Merged Curve (0-360Â°)")
        st.info("å°†å•é½¿é½¿å‘æ›²çº¿å¤åˆ¶åˆ°æ‰€æœ‰é½¿ï¼Œå½¢æˆå®Œæ•´çš„0-360Â°åˆå¹¶æ›²çº¿ï¼Œç”¨äºè®¡ç®—å®Œæ•´é¢‘è°±")
        
        for side in ['left', 'right']:
            side_name = 'Left Lead' if side == 'left' else 'Right Lead'
            
            if selected_tooth in helix_data.get(side, {}):
                # è·å–å•é½¿æ•°æ®
                tooth_helix = helix_data[side][selected_tooth]
                profile_mid = (profile_eval.eval_start + profile_eval.eval_end) / 2
                best_d = min(tooth_helix.keys(), key=lambda d: abs(d - profile_mid))
                raw_values = np.array(tooth_helix[best_d])
                
                # æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                b1, b2 = analyzer.reader.b1, analyzer.reader.b2
                ba, be = b1, b2
                
                # è§£ææµ‹é‡èŒƒå›´
                ba_match = re.search(r'Messanfang.*?ba\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if ba_match:
                    ba = float(ba_match.group(1))
                be_match = re.search(r'Messende.*?be\s*\[mm\]\.*:\s*([\d.]+)', analyzer.reader.raw_content or "", re.IGNORECASE)
                if be_match:
                    be = float(be_match.group(1))
                
                # è¯„ä»·èŒƒå›´
                eval_start = min(b1, b2)
                eval_end = max(b1, b2)
                
                # ä»å…¨éƒ¨æ•°æ®ä¸­æˆªå–è¯„ä»·èŒƒå›´å†…çš„æ•°æ®
                meas_length = be - ba
                if meas_length > 0:
                    start_ratio = (eval_start - ba) / meas_length
                    end_ratio = (eval_end - ba) / meas_length
                    
                    n_total = len(raw_values)
                    start_idx = max(0, int(start_ratio * n_total))
                    end_idx = min(n_total, int(end_ratio * n_total))
                    
                    if end_idx - start_idx > 10:
                        raw_values = raw_values[start_idx:end_idx]
                
                # å»é™¤é¼“å½¢å’Œæ–œç‡
                values = analyzer._remove_crown_and_slope(raw_values)
                
                if len(values) > 5:
                    # ä½¿ç”¨èºæ—‹è§’å…¬å¼è®¡ç®—å•é½¿çš„è§’åº¦æ•°ç»„
                    # æè§’ = 2 * (è¯„ä»·èŒƒå›´å†…æµ‹é‡ç‚¹ - èµ·è¯„ç‚¹) * tan(èºæ—‹è§’) / èŠ‚åœ†ç›´å¾„
                    n = len(values)
                    eval_points = np.linspace(0, eval_end - eval_start, n)
                    
                    # è·å–èºæ—‹è§’å’ŒèŠ‚åœ†ç›´å¾„
                    helix_angle = gear_params.helix_angle if gear_params else 0
                    pitch_diameter = gear_params.pitch_diameter if gear_params else 100
                    
                    # è®¡ç®—æ¯ä¸ªæµ‹é‡ç‚¹çš„æè§’å˜åŒ–
                    if pitch_diameter > 0 and abs(helix_angle) > 0.01:
                        point_angle_change = 2.0 * eval_points * np.tan(np.radians(abs(helix_angle))) / pitch_diameter
                        point_angles_deg = np.degrees(point_angle_change)
                    else:
                        # å¦‚æœèºæ—‹è§’ä¸º0ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ
                        point_angles_deg = np.linspace(0, pitch_angle * 0.95, n)
                    
                    single_angles = point_angles_deg
                    
                    # æ‰©å±•åˆ°æ‰€æœ‰é½¿
                    expanded_angles = []
                    expanded_values = []
                    
                    for tooth_num in range(ze):
                        tooth_base = tooth_num * pitch_angle
                        # å³é½¿å‘ï¼šåŠ æè§’ï¼Œå·¦é½¿å‘ï¼šå‡æè§’
                        if side == 'right':
                            for angle, value in zip(single_angles, values):
                                new_angle = tooth_base + angle
                                if new_angle < 360:
                                    expanded_angles.append(new_angle)
                                    expanded_values.append(value)
                        else:
                            for angle, value in zip(single_angles, values):
                                new_angle = tooth_base - angle
                                if new_angle >= 0:
                                    expanded_angles.append(new_angle)
                                    expanded_values.append(value)
                    
                    expanded_angles = np.array(expanded_angles)
                    expanded_values = np.array(expanded_values)
                    
                    # æ’åº
                    sort_idx = np.argsort(expanded_angles)
                    expanded_angles = expanded_angles[sort_idx]
                    expanded_values = expanded_values[sort_idx]
                    
                    # è®¡ç®—é«˜é˜¶é‡å»ºä¿¡å·
                    angles_rad = np.deg2rad(expanded_angles)
                    reconstructed = np.zeros_like(expanded_values)
                    
                    # è®¡ç®—é¢‘è°±
                    if len(expanded_angles) > 8:
                        spectrum_components = analyzer._iterative_sine_decomposition(expanded_angles, expanded_values, num_components=10, max_order=5*ze)
                        high_order_comps = [c for c in spectrum_components if c.order >= ze]
                        
                        for comp in high_order_comps:
                            a = comp.amplitude * np.sin(comp.phase)
                            b = comp.amplitude * np.cos(comp.phase)
                            reconstructed += a * np.cos(comp.order * angles_rad) + b * np.sin(comp.order * angles_rad)
                        
                        # æ˜¾ç¤ºæŒ‡æ ‡
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            high_order_amplitude = sum(c.amplitude for c in high_order_comps) if high_order_comps else 0.0
                            st.metric("High Order Amplitude W", f"{high_order_amplitude:.4f} Î¼m")
                        with col2:
                            high_order_rms = np.sqrt(sum(c.amplitude**2 for c in high_order_comps)) if high_order_comps else 0.0
                            st.metric("High Order RMS", f"{high_order_rms:.4f} Î¼m")
                        with col3:
                            st.metric("High Order Wave Count", len(high_order_comps))
                        with col4:
                            if spectrum_components:
                                st.metric("Dominant Order", int(spectrum_components[0].order))
                    
                    # ç»˜åˆ¶åˆå¹¶æ›²çº¿
                    fig, ax = plt.subplots(figsize=(14, 5))
                    ax.plot(expanded_angles, expanded_values, 'b-', linewidth=0.5, alpha=0.7, label='Raw Curve')
                    ax.plot(expanded_angles, reconstructed, 'r-', linewidth=1.5, label='High Order Reconstruction')
                    
                    # æ·»åŠ é½¿æ•°æ ‡å¿—
                    for tooth_num in range(ze + 1):
                        tooth_angle = tooth_num * pitch_angle
                        if tooth_angle <= 360:
                            ax.axvline(x=tooth_angle, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
                            if tooth_num % 5 == 0 or tooth_num == ze:
                                ax.text(tooth_angle, ax.get_ylim()[1] * 0.95, str(tooth_num), 
                                       ha='center', va='top', fontsize=7, color='gray', alpha=0.7)
                    
                    ax.set_xlabel('Rotation Angle (Â°)')
                    ax.set_ylabel('Deviation (Î¼m)')
                    ax.set_title(f'{side_name} - Single Tooth Expanded Merged Curve (ZE={ze})')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    ax.set_xlim(0, 360)
                    st.pyplot(fig)
                    plt.close(fig)
                    
                    # æ˜¾ç¤ºé¢‘è°±å›¾
                    if spectrum_components:
                        st.markdown(f"**{side_name} - Single Tooth Expanded Spectrum**")
                        
                        col1, col2 = st.columns([3, 2])
                        
                        with col1:
                            # Top 10 é˜¶æ¬¡è¡¨æ ¼
                            st.markdown("**Top 10 Largest Orders:**")
                            top_10_data = []
                            for i, comp in enumerate(spectrum_components[:10], 1):
                                top_10_data.append({
                                    'Rank': i,
                                    'Order': int(comp.order),
                                    'Amplitude (Î¼m)': f"{comp.amplitude:.4f}",
                                    'Phase (Â°)': f"{np.degrees(comp.phase):.1f}"
                                })
                            st.dataframe(pd.DataFrame(top_10_data), use_container_width=True, hide_index=True)
                        
                        with col2:
                            # é¢‘è°±å›¾
                            fig2, ax2 = plt.subplots(figsize=(8, 5))
                            
                            orders = [c.order for c in spectrum_components[:15]]
                            amplitudes = [c.amplitude for c in spectrum_components[:15]]
                            
                            colors = ['red' if o >= ze else 'steelblue' for o in orders]
                            ax2.bar(orders, amplitudes, color=colors, alpha=0.7)
                            
                            # æ ‡è®°ZEåŠå…¶å€æ•°
                            ze_multiples = [ze * i for i in range(1, 5) if ze * i <= max(orders)]
                            for i, ze_mult in enumerate(ze_multiples, 1):
                                if i == 1:
                                    ax2.axvline(x=ze_mult, color='green', linestyle='--', linewidth=2, label=f'ZE={ze}')
                                else:
                                    ax2.axvline(x=ze_mult, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)
                            
                            ax2.set_title(f'Single Tooth Expanded Spectrum (ZE={ze})', fontsize=10, fontweight='bold')
                            ax2.set_xlabel('Order')
                            ax2.set_ylabel('Amplitude (Î¼m)')
                            ax2.legend()
                            ax2.grid(True, alpha=0.3)
                            st.pyplot(fig2)
                            plt.close(fig2)
                    
                    # æ˜¾ç¤ºå‰5ä¸ªé½¿çš„æ”¾å¤§è§†å›¾
                    st.markdown(f"**{side_name} - First 5 Teeth Zoom View**")
                    
                    # è®¡ç®—å‰5ä¸ªé½¿çš„è§’åº¦èŒƒå›´
                    end_angle = 5 * pitch_angle
                    zoom_mask = expanded_angles <= end_angle
                    zoom_angles = expanded_angles[zoom_mask]
                    zoom_values = expanded_values[zoom_mask]
                    zoom_reconstructed = reconstructed[zoom_mask]
                    
                    if len(zoom_angles) > 0:
                        fig3, ax3 = plt.subplots(figsize=(12, 4))
                        
                        # é™é‡‡æ ·ä»¥æ”¹å–„æ˜¾ç¤º
                        if len(zoom_angles) > 5000:
                            step = len(zoom_angles) // 2000 + 1
                            zoom_angles = zoom_angles[::step]
                            zoom_values = zoom_values[::step]
                            zoom_reconstructed = zoom_reconstructed[::step]
                        
                        ax3.plot(zoom_angles, zoom_values, 'b-', linewidth=1.0, alpha=0.8, label='Raw Curve')
                        ax3.plot(zoom_angles, zoom_reconstructed, 'r-', linewidth=2.0, label='High Order Reconstruction')
                        
                        # æ·»åŠ é½¿æ•°æ ‡å¿—
                        for tooth_num in range(6):  # 0åˆ°5
                            tooth_angle = tooth_num * pitch_angle
                            if tooth_angle <= end_angle:
                                ax3.axvline(x=tooth_angle, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
                                ax3.text(tooth_angle, ax3.get_ylim()[1] * 0.95, str(tooth_num), 
                                        ha='center', va='top', fontsize=8, color='gray', alpha=0.7)
                        
                        ax3.set_xlabel('Rotation Angle (Â°)')
                        ax3.set_ylabel('Deviation (Î¼m)')
                        ax3.set_title(f'{side_name} - First 5 Teeth (0Â° ~ {end_angle:.1f}Â°)')
                        ax3.legend()
                        ax3.grid(True, alpha=0.3)
                        ax3.set_xlim(0, end_angle)
                        st.pyplot(fig3)
                        plt.close(fig3)
    
    elif page == 'ğŸ“‰ åˆå¹¶æ›²çº¿':
        st.markdown("## Merged Curve Analysis (0-360Â°)")

        ze = gear_params.teeth_count if gear_params else 87

        name_mapping = {
            'profile_left': 'Left Profile',
            'profile_right': 'Right Profile',
            'helix_left': 'Left Lead',
            'helix_right': 'Right Lead'
        }

        # æŒ‰éœ€è®¡ç®—åˆ†æç»“æœ
        with st.spinner("æ­£åœ¨è®¡ç®—åˆå¹¶æ›²çº¿..."):
            results = {
                'profile_left': analyzer.analyze_profile('left', verbose=False),
                'profile_right': analyzer.analyze_profile('right', verbose=False),
                'helix_left': analyzer.analyze_helix('left', verbose=False),
                'helix_right': analyzer.analyze_helix('right', verbose=False)
            }

        for name, result in results.items():
            if result is None or len(result.angles) == 0:
                continue

            display_name = name_mapping.get(name, name)

            with st.expander(f"ğŸ“ˆ {display_name}", expanded=True):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("High Order Amplitude W", f"{result.high_order_amplitude:.4f} Î¼m")
                with col2:
                    st.metric("High Order RMS", f"{result.high_order_rms:.4f} Î¼m")
                with col3:
                    st.metric("High Order Wave Count", len(result.high_order_waves))
                with col4:
                    if result.spectrum_components and len(result.spectrum_components) > 0:
                        max_order = result.spectrum_components[0].order
                        st.metric("Dominant Order", int(max_order))
                    else:
                        st.metric("Dominant Order", "-")

                # è®¡ç®—èŠ‚è·è§’
                pitch_angle = 360.0 / ze if ze > 0 else 4.14
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå•é½¿æ‰©å±•æ•°æ®
                unique_teeth_in_data = len(set(result.angles // pitch_angle))
                is_single_tooth_expanded = unique_teeth_in_data < ze
                
                fig, ax = plt.subplots(figsize=(14, 5))
                ax.plot(result.angles, result.values, 'b-', linewidth=0.5, alpha=0.7, label='Raw Curve')
                ax.plot(result.angles, result.reconstructed_signal, 'r-', linewidth=1.5, label='High Order Reconstruction')
                
                # æ·»åŠ é½¿æ•°æ ‡å¿— - åœ¨æ¯ä¸ªé½¿çš„èµ·å§‹ä½ç½®æ·»åŠ è™šçº¿
                for tooth_num in range(ze + 1):  # ä»0åˆ°é½¿æ•°
                    tooth_angle = tooth_num * pitch_angle
                    if tooth_angle <= 360:
                        # æ·»åŠ è™šçº¿æ ‡è®°æ¯ä¸ªé½¿çš„ä½ç½®
                        ax.axvline(x=tooth_angle, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
                        # åœ¨é¡¶éƒ¨æ·»åŠ é½¿å·æ ‡è®°ï¼ˆæ¯5ä¸ªé½¿æˆ–ç¬¬ä¸€ä¸ªé½¿æ˜¾ç¤ºæ•°å­—ï¼‰
                        if tooth_num % 5 == 0 or tooth_num == ze:
                            ax.text(tooth_angle, ax.get_ylim()[1] * 0.95, str(tooth_num), 
                                   ha='center', va='top', fontsize=7, color='gray', alpha=0.7)
                
                ax.set_xlabel('Rotation Angle (Â°)')
                ax.set_ylabel('Deviation (Î¼m)')
                
                # å¦‚æœæ˜¯å•é½¿æ‰©å±•ï¼Œåœ¨æ ‡é¢˜ä¸­æ ‡è¯†
                if is_single_tooth_expanded:
                    ax.set_title(f'{display_name} - Merged Curve (ZE={ze}, Single Tooth Expanded)')
                else:
                    ax.set_title(f'{display_name} - Merged Curve (ZE={ze})')
                
                ax.legend()
                ax.grid(True, alpha=0.3)
                ax.set_xlim(0, 360)
                st.pyplot(fig)
                plt.close(fig)

        st.markdown("---")
        st.markdown("### First 5 Teeth Zoom View")

        pitch_angle = 360.0 / ze if ze > 0 else 4.14
        end_angle = 5 * pitch_angle

        for name, result in [
            ('Left Profile', results.get('profile_left')),
            ('Right Profile', results.get('profile_right')),
            ('Left Lead', results.get('helix_left')),
            ('Right Lead', results.get('helix_right'))
        ]:
            if result is None or len(result.angles) == 0:
                continue

            display_name = name

            mask = (result.angles >= 0) & (result.angles <= end_angle)
            if np.sum(mask) > 0:
                zoom_angles = result.angles[mask]
                zoom_values = result.values[mask]
                zoom_reconstructed = result.reconstructed_signal[mask]

                fig, ax = plt.subplots(figsize=(10, 4))
                # å¦‚æœæ•°æ®ç‚¹è¿‡å¤šï¼Œè¿›è¡Œé™é‡‡æ ·ä»¥æ”¹å–„çº¿æ¡æ˜¾ç¤º
                if len(zoom_angles) > 5000:
                    step = len(zoom_angles) // 2000 + 1
                    zoom_angles = zoom_angles[::step]
                    zoom_values = zoom_values[::step]
                    zoom_reconstructed = zoom_reconstructed[::step]
                ax.plot(zoom_angles, zoom_values, 'b-', linewidth=1.0, alpha=0.8, label='Raw Curve')
                ax.plot(zoom_angles, zoom_reconstructed, 'r-', linewidth=2.0, label='High Order Reconstruction')
                
                # æ·»åŠ é½¿æ•°æ ‡å¿—
                pitch_angle = 360.0 / ze if ze > 0 else 4.14
                for tooth_num in range(ze + 1):  # ä»0åˆ°é½¿æ•°
                    tooth_angle = tooth_num * pitch_angle
                    if tooth_angle <= end_angle:
                        # æ·»åŠ è™šçº¿æ ‡è®°æ¯ä¸ªé½¿çš„ä½ç½®
                        ax.axvline(x=tooth_angle, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
                        # åœ¨é¡¶éƒ¨æ·»åŠ é½¿å·æ ‡è®°ï¼ˆæ¯5ä¸ªé½¿æˆ–ç¬¬ä¸€ä¸ªé½¿æ˜¾ç¤ºæ•°å­—ï¼‰
                        if tooth_num % 5 == 0 or tooth_num == ze:
                            ax.text(tooth_angle, ax.get_ylim()[1] * 0.95, str(tooth_num), 
                                   ha='center', va='top', fontsize=7, color='gray', alpha=0.7)
                
                ax.set_xlabel('Rotation Angle (Â°)')
                ax.set_ylabel('Deviation (Î¼m)')
                ax.set_title(f'{display_name} - First 5 Teeth (0Â° ~ {end_angle:.1f}Â°)')
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close(fig)
    
    elif page == 'ğŸ“Š é¢‘è°±åˆ†æ':
        st.markdown("## Spectrum Analysis")

        ze = gear_params.teeth_count if gear_params else 87

        name_mapping = {
            'profile_left': 'Left Profile',
            'profile_right': 'Right Profile',
            'helix_left': 'Left Lead',
            'helix_right': 'Right Lead'
        }

        # æŒ‰éœ€è®¡ç®—åˆ†æç»“æœ
        with st.spinner("æ­£åœ¨è®¡ç®—é¢‘è°±åˆ†æ..."):
            results = {
                'profile_left': analyzer.analyze_profile('left', verbose=False),
                'profile_right': analyzer.analyze_profile('right', verbose=False),
                'helix_left': analyzer.analyze_helix('left', verbose=False),
                'helix_right': analyzer.analyze_helix('right', verbose=False)
            }

        # ========== PDFæŠ¥è¡¨ç”ŸæˆæŒ‰é’® ==========
        st.markdown("### ğŸ“„ ç”Ÿæˆé¢‘è°±åˆ†ææŠ¥è¡¨")
        
        if st.button("ğŸ“¥ ç”Ÿæˆé¢‘è°±åˆ†æPDFæŠ¥è¡¨", type="primary"):
            with st.spinner("æ­£åœ¨ç”ŸæˆPDFæŠ¥è¡¨..."):
                try:
                    from reportlab.lib.pagesizes import A4
                    from reportlab.lib import colors
                    from reportlab.lib.units import mm
                    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak
                    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                    from reportlab.pdfbase import pdfmetrics
                    from reportlab.pdfbase.ttfonts import TTFont
                    import io
                    import os
                    
                    # è®¡ç®—æé™æ›²çº¿å‡½æ•°
                    def calc_tolerance(orders, R, N0, K):
                        tolerances = []
                        for O in orders:
                            if O <= 1:
                                tolerances.append(R)
                            else:
                                N = N0 + K / O
                                tolerance = R / ((O - 1) ** N)
                                tolerances.append(tolerance)
                        return tolerances
                    
                    # åˆ›å»ºPDF
                    pdf_buffer = io.BytesIO()
                    doc = SimpleDocTemplate(pdf_buffer, pagesize=A4, 
                                           leftMargin=15*mm, rightMargin=15*mm,
                                           topMargin=15*mm, bottomMargin=15*mm)
                    
                    elements = []
                    styles = getSampleStyleSheet()
                    
                    # ä½¿ç”¨è‹±æ–‡å­—ä½“ï¼ˆé¿å…ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼‰
                    title_style = ParagraphStyle('Title', fontName='Helvetica-Bold', fontSize=16, alignment=1, spaceAfter=10)
                    heading_style = ParagraphStyle('Heading', fontName='Helvetica-Bold', fontSize=12, spaceAfter=6)
                    normal_style = ParagraphStyle('Normal', fontName='Helvetica', fontSize=10)
                    
                    # æ ‡é¢˜
                    elements.append(Paragraph("Spectrum Analysis Report", title_style))
                    elements.append(Spacer(1, 5*mm))
                    
                    # ä¸ºæ¯ä¸ªåˆ†æç»“æœç”ŸæˆæŠ¥è¡¨
                    for name, result in results.items():
                        if result is None or len(result.angles) == 0:
                            continue
                        
                        display_name = name_mapping.get(name, name)
                        
                        # è·å–ç•Œé¢å®é™…å‚æ•°
                        R_key = f"R_{name}"
                        N0_key = f"N0_{name}"
                        K_key = f"K_{name}"
                        
                        # ä»session_stateè·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                        if R_key in st.session_state:
                            current_R = st.session_state[R_key]
                        else:
                            current_R = 0.0039
                        
                        if N0_key in st.session_state:
                            current_N0 = st.session_state[N0_key]
                        else:
                            current_N0 = 0.6
                        
                        if K_key in st.session_state:
                            current_K = st.session_state[K_key]
                        else:
                            current_K = 2.8
                        
                        # å°æ ‡é¢˜
                        elements.append(Paragraph(f"<b>{display_name}</b>", heading_style))
                        
                        # æé™æ›²çº¿å‚æ•°ï¼ˆè‹±æ–‡ï¼‰
                        param_text = f"Limit Curve: R = {current_R:.4f} mm, N0 = {current_N0:.1f}, K = {current_K:.1f}"
                        elements.append(Paragraph(param_text, normal_style))
                        elements.append(Paragraph("Formula: Tolerance = R / (O-1)^(N0+K/O)", normal_style))
                        elements.append(Spacer(1, 3*mm))
                        
                        # ç”Ÿæˆé¢‘è°±å›¾
                        sorted_components = sorted(result.spectrum_components[:20], key=lambda c: c.order)
                        orders = [c.order for c in sorted_components]
                        amplitudes = [c.amplitude for c in sorted_components]
                        
                        if orders and amplitudes:
                            # åˆ›å»ºå›¾è¡¨
                            fig, ax = plt.subplots(figsize=(7, 3.5))
                            
                            tolerance_values = calc_tolerance(orders, current_R, current_N0, current_K)
                            colors_bar = ['red' if amp > tol else 'steelblue' for amp, tol in zip(amplitudes, tolerance_values)]
                            ax.bar(orders, amplitudes, color=colors_bar, alpha=0.7, width=3, label='Amplitude')
                            
                            ze_multiples = [ze * i for i in range(1, 5) if ze * i <= max(orders) + 20]
                            for i, ze_mult in enumerate(ze_multiples, 1):
                                if i == 1:
                                    ax.axvline(x=ze_mult, color='green', linestyle='--', linewidth=2, label=f'ZE={ze}')
                                else:
                                    ax.axvline(x=ze_mult, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)
                            
                            order_range = np.linspace(2, max(orders) + 20, 200)
                            tolerance_curve = calc_tolerance(order_range, current_R, current_N0, current_K)
                            ax.plot(order_range, tolerance_curve, color='darkorange', linewidth=2.5, label='Tolerance Limit')
                            
                            max_amplitude = max(amplitudes) if amplitudes else 1
                            max_tolerance = max(tolerance_curve) if len(tolerance_curve) > 0 else 1
                            y_max = max(max_amplitude, max_tolerance) * 1.2
                            ax.set_ylim(0, y_max)
                            ax.set_xlim(0, max(orders) + 20)
                            
                            ax.set_xlabel('Order')
                            ax.set_ylabel('Amplitude (Î¼m) / Tolerance (mm)')
                            ax.set_title(f'{display_name} - Spectrum (ZE={ze})')
                            ax.legend(loc='upper right', fontsize=8)
                            ax.grid(True, alpha=0.3)
                            plt.tight_layout()
                            
                            # ä¿å­˜å›¾è¡¨åˆ°å†…å­˜
                            img_buffer = io.BytesIO()
                            fig.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
                            img_buffer.seek(0)
                            plt.close(fig)
                            
                            # æ·»åŠ å›¾è¡¨åˆ°PDF
                            img = Image(img_buffer, width=170*mm, height=85*mm)
                            elements.append(img)
                            elements.append(Spacer(1, 3*mm))
                        
                        # æ•°æ®è¡¨ï¼ˆè‹±æ–‡ï¼‰
                        table_data = [['Rank', 'Order', 'Amplitude (Î¼m)', 'Phase (Â°)', 'Type', 'Status']]
                        for i, comp in enumerate(result.spectrum_components[:10]):
                            order_type = 'High' if comp.order >= ze else 'Low'
                            # è®¡ç®—çŠ¶æ€
                            tol = calc_tolerance([comp.order], current_R, current_N0, current_K)[0]
                            status = 'FAIL' if comp.amplitude > tol else 'PASS'
                            table_data.append([
                                str(i + 1),
                                str(int(comp.order)),
                                f"{comp.amplitude:.4f}",
                                f"{np.degrees(comp.phase):.1f}",
                                order_type,
                                status
                            ])
                        
                        table = Table(table_data, colWidths=[20*mm, 25*mm, 35*mm, 30*mm, 20*mm, 25*mm])
                        table.setStyle(TableStyle([
                            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
                            ('FONTSIZE', (0, 0), (-1, 0), 9),
                            ('FONTSIZE', (0, 1), (-1, -1), 8),
                            ('BOTTOMPADDING', (0, 0), (-1, 0), 6),
                            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
                        ]))
                        elements.append(table)
                        elements.append(Spacer(1, 5*mm))
                        
                        # æ¯ä¸ªåˆ†æç»“æœåæ·»åŠ åˆ†é¡µï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
                        if name != list(results.keys())[-1]:
                            elements.append(PageBreak())
                    
                    # ç”ŸæˆPDF
                    doc.build(elements)
                    pdf_buffer.seek(0)
                    
                    st.success("âœ… PDF Report Generated Successfully!")
                    st.download_button(
                        label="ğŸ“¥ Download Spectrum Analysis PDF Report",
                        data=pdf_buffer,
                        file_name=f"spectrum_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                        mime="application/pdf"
                    )
                    
                except Exception as e:
                    st.error(f"PDF Generation Failed: {e}")
                    import traceback
                    st.error(traceback.format_exc())
        
        st.markdown("---")

        for name, result in results.items():
            if result is None or len(result.angles) == 0:
                continue

            display_name = name_mapping.get(name, name)

            with st.expander(f"ğŸ“ˆ {display_name}", expanded=True):
                st.markdown("#### Top 10 Largest Orders")

                spectrum_data = []
                for i, comp in enumerate(result.spectrum_components[:10]):
                    order_type = 'High Order' if comp.order >= ze else 'Low Order'
                    spectrum_data.append({
                        'Rank': i + 1,
                        'Order': int(comp.order),
                        'Amplitude (Î¼m)': f"{comp.amplitude:.4f}",
                        'Phase (Â°)': f"{np.degrees(comp.phase):.1f}",
                        'Type': order_type
                    })
                st.table(spectrum_data)

                st.markdown("#### Spectrum Chart")

                # æ˜¾ç¤ºå…¬å·®æ›²çº¿å®šä¹‰å’ŒåŸç†
                with st.expander("ğŸ“– å…¬å·®æ›²çº¿å®šä¹‰ä¸åŸç†", expanded=False):
                    st.markdown("""
                    **å…¬å·®æ›²çº¿ï¼ˆTolerance Limit Curveï¼‰**
                    
                    å…¬å·®æ›²çº¿ä»¥æé™æ›²çº¿çš„å½¢å¼æè¿°è¿ç»­çš„å…¬å·®èŒƒå›´ï¼Œé€šè¿‡ä¸‰ä¸ªå‚æ•°ç¡®å®šï¼š
                    
                    - **R**ï¼šå…è®¸æ³¢æ·±ï¼ˆå‚è€ƒå¹…å€¼ï¼Œå•ä½ï¼šmmï¼‰
                    - **Nâ‚€**ï¼šç”¨äºæè¿°å…¬å·®æ›²çº¿çš„å¸¸æ•°ï¼ˆåŸºç¡€æŒ‡æ•°ï¼‰
                    - **K**ï¼šä¿®æ­£å€¼
                    
                    **è®¡ç®—å…¬å¼ï¼š**
                    
                    ```
                    å…¬å·® = R / (O - 1)^N
                    
                    å…¶ä¸­ï¼šN = Nâ‚€ + K / O
                    
                    O = é˜¶æ¬¡ï¼ˆOrderï¼‰
                    ```
                    
                    **ç‰©ç†æ„ä¹‰ï¼š**
                    - ä½é˜¶æ¬¡ï¼ˆOè¾ƒå°ï¼‰ï¼šå…¬å·®è¾ƒå¤§ï¼Œå…è®¸è¾ƒå¤§çš„æ³¢çº¹åº¦
                    - é«˜é˜¶æ¬¡ï¼ˆOè¾ƒå¤§ï¼‰ï¼šå…¬å·®è¾ƒå°ï¼Œè¦æ±‚æ›´ä¸¥æ ¼çš„æ³¢çº¹åº¦æ§åˆ¶
                    - éšç€é˜¶æ¬¡å¢åŠ ï¼Œå…è®¸çš„æ³¢çº¹åº¦å¹…å€¼å‘ˆæŒ‡æ•°è¡°å‡
                    
                    **åº”ç”¨ï¼š**
                    - è“è‰²æŸ±ï¼šå¹…å€¼åœ¨å…¬å·®èŒƒå›´å†…ï¼ˆåˆæ ¼ï¼‰
                    - çº¢è‰²æŸ±ï¼šå¹…å€¼è¶…å‡ºå…¬å·®èŒƒå›´ï¼ˆä¸åˆæ ¼ï¼Œéœ€å…³æ³¨ï¼‰
                    - æ©˜é»„çº¿ï¼šå…¬å·®æé™æ›²çº¿
                    """)

                # è®¡ç®—æé™æ›²çº¿
                def calculate_tolerance_curve(orders, R, N0, K):
                    """è®¡ç®—æé™æ›²çº¿å…¬å·®å€¼"""
                    tolerances = []
                    for O in orders:
                        if O <= 1:
                            tolerances.append(R)
                        else:
                            N = N0 + K / O
                            tolerance = R / ((O - 1) ** N)
                            tolerances.append(tolerance)
                    return tolerances

                fig, ax = plt.subplots(figsize=(12, 5))
                sorted_components = sorted(result.spectrum_components[:20], key=lambda c: c.order)
                orders = [c.order for c in sorted_components]
                amplitudes = [c.amplitude for c in sorted_components]

                # æ ¹æ®å®é™…æ•°æ®è‡ªåŠ¨è®¡ç®—æé™æ›²çº¿å‚æ•°
                # ç›®æ ‡ï¼šå…¬å·®æ›²çº¿åœ¨ZEå¤„é«˜äºä¸»å¯¼é˜¶æ¬¡çš„å¹…å€¼
                if amplitudes and orders:
                    N0_auto = 0.6
                    K_auto = 2.8
                    
                    # æ‰¾åˆ°ZEå¤„çš„å¹…å€¼æˆ–æœ€æ¥è¿‘ZEçš„å¹…å€¼
                    # é¦–å…ˆå°è¯•æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ZEçš„é˜¶æ¬¡
                    ze_amplitude = None
                    for o, amp in zip(orders, amplitudes):
                        if abs(o - ze) < 1:  # ZE Â± 1èŒƒå›´å†…
                            if ze_amplitude is None or amp > ze_amplitude:
                                ze_amplitude = amp
                    
                    if ze_amplitude is not None:
                        # è®¡ç®—Rï¼Œä½¿å¾—åœ¨ZEå¤„çš„å…¬å·®ä¸ºZEå¤„å¹…å€¼çš„1.5å€
                        # tolerance = R / ((ZE-1)^N), å…¶ä¸­ N = N0 + K/ZE
                        N_at_ze = N0_auto + K_auto / ze
                        R_auto = ze_amplitude * 1.5 * ((ze - 1) ** N_at_ze)
                    else:
                        # å¦‚æœæ²¡æœ‰ZEé™„è¿‘çš„æ•°æ®ï¼Œä½¿ç”¨å…¨å±€æœ€å¤§å¹…å€¼ï¼Œå¹¶ä¹˜ä»¥æ›´å¤§ç³»æ•°
                        max_amp = max(amplitudes)
                        R_auto = max_amp * 2.0 * ((ze - 1) ** (N0_auto + K_auto / ze))
                    
                    # æ”¾å®½Rçš„ä¸Šé™é™åˆ¶
                    R_auto = max(0.0001, min(R_auto, 10.0))
                else:
                    R_auto = 0.0039
                    N0_auto = 0.6
                    K_auto = 2.8

                # æ˜¾ç¤ºæé™æ›²çº¿å‚æ•°å¹¶å¯è°ƒèŠ‚
                st.markdown("**Limit Curve Parameters**")
                st.markdown("*Formula: Tolerance = R / (O-1)^(Nâ‚€+K/O)*")
                col1, col2, col3 = st.columns(3)
                with col1:
                    R_input = st.number_input("R (mm)", min_value=0.0001, max_value=10.0, value=float(R_auto), step=0.0001, format="%.4f", key=f"R_{name}")
                with col2:
                    N0_input = st.number_input("Nâ‚€", min_value=0.0, max_value=5.0, value=float(N0_auto), step=0.1, format="%.1f", key=f"N0_{name}")
                with col3:
                    K_input = st.number_input("K", min_value=0.0, max_value=10.0, value=float(K_auto), step=0.1, format="%.1f", key=f"K_{name}")

                # ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„å‚æ•°
                R = R_input
                N0 = N0_input
                K = K_input

                if orders and amplitudes:
                    # è®¡ç®—æ¯ä¸ªé˜¶æ¬¡çš„æé™å€¼
                    tolerance_values = calculate_tolerance_curve(orders, R, N0, K)
                    
                    # æ ¹æ®æ˜¯å¦è¶…å‡ºæé™è®¾ç½®é¢œè‰²ï¼šè“è‰²ï¼ˆæœªè¶…å‡ºï¼‰ï¼Œçº¢è‰²ï¼ˆè¶…å‡ºï¼‰
                    colors_bar = ['red' if amp > tol else 'steelblue' for amp, tol in zip(amplitudes, tolerance_values)]
                    ax.bar(orders, amplitudes, color=colors_bar, alpha=0.7, width=3, label='Amplitude')

                    # æ ‡è¯† ZE åŠå…¶å€æ•°
                    ze_multiples = [ze * i for i in range(1, 5) if ze * i <= max(orders) + 20]
                    for i, ze_mult in enumerate(ze_multiples, 1):
                        if i == 1:
                            ax.axvline(x=ze_mult, color='green', linestyle='--', linewidth=2, label=f'ZE={ze}')
                        else:
                            ax.axvline(x=ze_mult, color='orange', linestyle=':', linewidth=1.5, alpha=0.7, label=f'{i}Ã—ZE={ze_mult}')

                    # ç»˜åˆ¶æé™æ›²çº¿ï¼ˆæ©˜é»„è‰²ï¼‰
                    order_range = np.linspace(2, max(orders) + 20, 200)
                    tolerance_curve = calculate_tolerance_curve(order_range, R, N0, K)
                    ax.plot(order_range, tolerance_curve, color='darkorange', linewidth=2.5, label='Tolerance Limit', linestyle='-')

                    # è®¾ç½®Yè½´èŒƒå›´
                    max_amplitude = max(amplitudes) if amplitudes else 1
                    max_tolerance = max(tolerance_curve) if tolerance_curve else 1
                    y_max = max(max_amplitude, max_tolerance) * 1.2
                    ax.set_ylim(0, y_max)
                    ax.set_xlim(0, max(orders) + 20)

                ax.set_xlabel('Order')
                ax.set_ylabel('Amplitude (Î¼m) / Tolerance (mm)')
                ax.set_title(f'{display_name} - Spectrum (ZE={ze})')
                ax.legend(loc='upper right')
                ax.grid(True, alpha=0.3)

                st.pyplot(fig)
                plt.close(fig)
                
                # ========== AIæ™ºèƒ½åˆ†æ ==========
                st.markdown("---")
                st.markdown("#### ğŸ¤– AIæ™ºèƒ½åˆ†æ")
                
                # åˆ†æé¢‘è°±æ•°æ®
                def analyze_spectrum_ai(components, ze, tolerance_func, R, N0, K, display_name):
                    """AIåˆ†æé¢‘è°±æ•°æ®ï¼Œè¿”å›çŠ¶æ€ã€åŸå› å’Œå»ºè®®"""
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    high_order_components = [c for c in components if c.order >= ze]
                    low_order_components = [c for c in components if c.order < ze]
                    
                    # è®¡ç®—è¶…å‡ºå…¬å·®çš„æ•°é‡
                    out_of_tolerance = []
                    out_of_tolerance_details = []
                    for comp in components[:20]:
                        tol = tolerance_func([comp.order], R, N0, K)[0]
                        if comp.amplitude > tol:
                            out_of_tolerance.append(comp)
                            out_of_tolerance_details.append({
                                'order': comp.order,
                                'amplitude': comp.amplitude,
                                'tolerance': tol,
                                'excess': comp.amplitude - tol
                            })
                    
                    # ZEåŠå…¶å€æ•°çš„å¹…å€¼
                    ze_multiples_amp = {}
                    for i in range(1, 6):
                        ze_mult = ze * i
                        for comp in components:
                            if abs(comp.order - ze_mult) < 1:
                                ze_multiples_amp[i] = comp.amplitude
                                break
                    
                    # è®¡ç®—é¢‘è°±èƒ½é‡åˆ†å¸ƒ
                    total_energy = sum(c.amplitude ** 2 for c in components[:20])
                    low_order_energy = sum(c.amplitude ** 2 for c in low_order_components[:10])
                    high_order_energy = sum(c.amplitude ** 2 for c in high_order_components[:10])
                    ze_energy = sum((ze_multiples_amp.get(i, 0) ** 2) for i in range(1, 5))
                    
                    low_order_ratio = low_order_energy / total_energy if total_energy > 0 else 0
                    high_order_ratio = high_order_energy / total_energy if total_energy > 0 else 0
                    ze_ratio = ze_energy / total_energy if total_energy > 0 else 0
                    
                    # åˆ†æç»“æœ
                    analysis = {
                        'status': 'normal',
                        'status_text': 'æ­£å¸¸',
                        'status_color': 'green',
                        'score': 100,
                        'issues': [],
                        'causes': [],
                        'recommendations': [],
                        'noise_prediction': 'ä½',
                        'noise_level': 1,
                        'energy_distribution': {
                            'low_order': low_order_ratio,
                            'high_order': high_order_ratio,
                            'ze_related': ze_ratio
                        },
                        'out_of_tolerance_details': out_of_tolerance_details
                    }
                    
                    # è®¡ç®—ç»¼åˆè¯„åˆ†
                    score = 100
                    score -= len(out_of_tolerance) * 5  # æ¯ä¸ªè¶…å·®æ‰£5åˆ†
                    score -= int(ze_multiples_amp.get(1, 0) * 100)  # ZEå¹…å€¼æ‰£åˆ†
                    score -= int(ze_multiples_amp.get(2, 0) * 50)  # 2ZEå¹…å€¼æ‰£åˆ†
                    score -= len([c for c in high_order_components[:10] if c.amplitude > 0.03]) * 3  # é«˜é˜¶æ¬¡æ‰£åˆ†
                    score = max(0, min(100, score))
                    analysis['score'] = score
                    
                    # åˆ¤æ–­çŠ¶æ€
                    if score < 50:
                        analysis['status'] = 'critical'
                        analysis['status_text'] = 'ä¸¥é‡å¼‚å¸¸'
                        analysis['status_color'] = 'red'
                        analysis['noise_prediction'] = 'å¾ˆé«˜'
                        analysis['noise_level'] = 5
                    elif score < 70:
                        analysis['status'] = 'warning'
                        analysis['status_text'] = 'è­¦å‘Š'
                        analysis['status_color'] = 'orange'
                        analysis['noise_prediction'] = 'é«˜'
                        analysis['noise_level'] = 4
                    elif score < 85:
                        analysis['status'] = 'attention'
                        analysis['status_text'] = 'éœ€å…³æ³¨'
                        analysis['status_color'] = 'yellow'
                        analysis['noise_prediction'] = 'ä¸­ç­‰'
                        analysis['noise_level'] = 3
                    elif score < 95:
                        analysis['status'] = 'good'
                        analysis['status_text'] = 'è‰¯å¥½'
                        analysis['status_color'] = 'lightgreen'
                        analysis['noise_prediction'] = 'ä½'
                        analysis['noise_level'] = 2
                    else:
                        analysis['status'] = 'excellent'
                        analysis['status_text'] = 'ä¼˜ç§€'
                        analysis['status_color'] = 'green'
                        analysis['noise_prediction'] = 'å¾ˆä½'
                        analysis['noise_level'] = 1
                    
                    # æ ¹æ®åˆ†æç±»å‹è°ƒæ•´é˜ˆå€¼
                    is_profile = 'Profile' in display_name
                    is_helix = 'Lead' in display_name
                    
                    # åˆ†æé—®é¢˜ - ä¸»å¯¼é˜¶æ¬¡ZE
                    ze_amp = ze_multiples_amp.get(1, 0)
                    if ze_amp > 0.15:
                        analysis['issues'].append(f"ğŸ”´ ä¸»å¯¼é˜¶æ¬¡ZE={ze}å¹…å€¼ä¸¥é‡åé«˜({ze_amp:.4f}Î¼m)")
                        analysis['causes'].append("é½¿è½®åŠ å·¥åˆ†åº¦è¯¯å·®ä¸¥é‡ï¼Œæˆ–åˆ€å…·ç£¨æŸä¸¥é‡")
                        analysis['recommendations'].append("ç«‹å³æ£€æŸ¥æœºåºŠåˆ†åº¦ç²¾åº¦ï¼Œæ›´æ¢æˆ–é‡ç£¨åˆ€å…·")
                    elif ze_amp > 0.08:
                        analysis['issues'].append(f"ğŸŸ  ä¸»å¯¼é˜¶æ¬¡ZE={ze}å¹…å€¼è¾ƒé«˜({ze_amp:.4f}Î¼m)")
                        analysis['causes'].append("é½¿è½®åŠ å·¥æ—¶å­˜åœ¨åˆ†åº¦è¯¯å·®æˆ–åˆ€å…·è¯¯å·®")
                        analysis['recommendations'].append("æ£€æŸ¥é½¿è½®åŠ å·¥æœºåºŠçš„åˆ†åº¦ç²¾åº¦ï¼Œæ£€æŸ¥åˆ€å…·ç£¨æŸæƒ…å†µ")
                    elif ze_amp > 0.03:
                        analysis['issues'].append(f"ğŸŸ¡ ä¸»å¯¼é˜¶æ¬¡ZE={ze}å¹…å€¼ç•¥é«˜({ze_amp:.4f}Î¼m)")
                        analysis['causes'].append("è½»å¾®çš„åˆ†åº¦è¯¯å·®æˆ–åˆ€å…·ç£¨æŸ")
                        analysis['recommendations'].append("å…³æ³¨æœºåºŠåˆ†åº¦çŠ¶æ€ï¼Œå®šæœŸæ£€æŸ¥åˆ€å…·")
                    
                    # 2å€é¢‘åˆ†æ
                    ze2_amp = ze_multiples_amp.get(2, 0)
                    if ze2_amp > 0.08:
                        analysis['issues'].append(f"ğŸ”´ 2å€é¢‘(2ZE={2*ze})å¹…å€¼ä¸¥é‡åé«˜({ze2_amp:.4f}Î¼m)")
                        analysis['causes'].append("é½¿è½®å­˜åœ¨ä¸¥é‡åå¿ƒæˆ–æ¤­åœ†åº¦è¯¯å·®")
                        analysis['recommendations'].append("æ£€æŸ¥é½¿è½®å®‰è£…åå¿ƒé‡ï¼Œæ£€æŸ¥é½¿è½®å†…å­”ç²¾åº¦ï¼Œå¿…è¦æ—¶é‡æ–°åŠ å·¥")
                    elif ze2_amp > 0.04:
                        analysis['issues'].append(f"ğŸŸ  2å€é¢‘(2ZE={2*ze})å¹…å€¼è¾ƒé«˜({ze2_amp:.4f}Î¼m)")
                        analysis['causes'].append("é½¿è½®å¯èƒ½å­˜åœ¨åå¿ƒæˆ–æ¤­åœ†åº¦")
                        analysis['recommendations'].append("æ£€æŸ¥é½¿è½®å®‰è£…åå¿ƒé‡ï¼Œæ£€æŸ¥é½¿è½®å†…å­”ç²¾åº¦")
                    elif ze2_amp > 0.02:
                        analysis['issues'].append(f"ğŸŸ¡ 2å€é¢‘(2ZE={2*ze})å¹…å€¼ç•¥é«˜({ze2_amp:.4f}Î¼m)")
                        analysis['causes'].append("è½»å¾®çš„åå¿ƒæˆ–æ¤­åœ†åº¦")
                        analysis['recommendations'].append("å…³æ³¨é½¿è½®å®‰è£…ç²¾åº¦")
                    
                    # 3å€é¢‘åˆ†æ
                    ze3_amp = ze_multiples_amp.get(3, 0)
                    if ze3_amp > 0.03:
                        analysis['issues'].append(f"ğŸŸ  3å€é¢‘(3ZE={3*ze})å¹…å€¼è¾ƒé«˜({ze3_amp:.4f}Î¼m)")
                        analysis['causes'].append("é½¿è½®å­˜åœ¨ä¸‰æ£±åº¦è¯¯å·®")
                        analysis['recommendations'].append("æ£€æŸ¥é½¿è½®çš„è£…å¤¹æ–¹å¼ï¼Œæ£€æŸ¥æœºåºŠä¸»è½´ç²¾åº¦")
                    
                    # é«˜é˜¶æ¬¡åˆ†æ
                    high_order_large = [c for c in high_order_components[:10] if c.amplitude > 0.03]
                    if len(high_order_large) > 5:
                        analysis['issues'].append(f"ğŸ”´ é«˜é˜¶æ¬¡({len(high_order_large)}ä¸ª)å¹…å€¼ä¸¥é‡åé«˜")
                        analysis['causes'].append("é½¿é¢ç²—ç³™åº¦ä¸¥é‡è¶…æ ‡ï¼Œå­˜åœ¨ä¸¥é‡çš„å¾®è§‚å‡ ä½•è¯¯å·®")
                        analysis['recommendations'].append("ä¼˜åŒ–ç£¨é½¿æˆ–ç©é½¿å·¥è‰ºï¼Œæ£€æŸ¥ç ‚è½®çŠ¶æ€ï¼Œé™ä½é½¿é¢ç²—ç³™åº¦")
                    elif len(high_order_large) > 3:
                        analysis['issues'].append(f"ğŸŸ  é«˜é˜¶æ¬¡({len(high_order_large)}ä¸ª)å¹…å€¼è¾ƒé«˜")
                        analysis['causes'].append("é½¿é¢ç²—ç³™åº¦è¾ƒå¤§æˆ–å­˜åœ¨å¾®è§‚å‡ ä½•è¯¯å·®")
                        analysis['recommendations'].append("ä¼˜åŒ–ç£¨é½¿æˆ–ç©é½¿å·¥è‰ºï¼Œé™ä½é½¿é¢ç²—ç³™åº¦")
                    elif len(high_order_large) > 1:
                        analysis['issues'].append(f"ğŸŸ¡ é«˜é˜¶æ¬¡({len(high_order_large)}ä¸ª)å¹…å€¼ç•¥é«˜")
                        analysis['causes'].append("é½¿é¢å­˜åœ¨è½»å¾®ç²—ç³™åº¦é—®é¢˜")
                        analysis['recommendations'].append("å…³æ³¨é½¿é¢åŠ å·¥è´¨é‡")
                    
                    # ä½é˜¶æ¬¡åˆ†æ
                    low_order_large = [c for c in low_order_components[:5] if c.amplitude > 0.05]
                    if len(low_order_large) > 3:
                        analysis['issues'].append(f"ğŸ”´ ä½é˜¶æ¬¡({len(low_order_large)}ä¸ª)å¹…å€¼ä¸¥é‡åé«˜")
                        analysis['causes'].append("é½¿è½®å­˜åœ¨ä¸¥é‡çš„å®è§‚å‡ ä½•è¯¯å·®ï¼ˆé½¿å½¢è¯¯å·®ã€é½¿å‘è¯¯å·®ï¼‰")
                        analysis['recommendations'].append("å…¨é¢æ£€æŸ¥é½¿è½®çš„é½¿å½¢å’Œé½¿å‘åå·®ï¼Œé‡æ–°è°ƒæ•´åŠ å·¥å·¥è‰º")
                    elif len(low_order_large) > 2:
                        analysis['issues'].append(f"ğŸŸ  ä½é˜¶æ¬¡({len(low_order_large)}ä¸ª)å¹…å€¼è¾ƒé«˜")
                        analysis['causes'].append("é½¿è½®å­˜åœ¨å®è§‚å‡ ä½•è¯¯å·®ï¼Œå¦‚é½¿å½¢è¯¯å·®ã€é½¿å‘è¯¯å·®")
                        analysis['recommendations'].append("æ£€æŸ¥é½¿è½®çš„é½¿å½¢å’Œé½¿å‘åå·®ï¼Œä¼˜åŒ–åŠ å·¥å·¥è‰º")
                    
                    # èƒ½é‡åˆ†å¸ƒåˆ†æ
                    if ze_ratio > 0.5:
                        analysis['issues'].append(f"ğŸ”´ ZEç›¸å…³é˜¶æ¬¡èƒ½é‡å æ¯”è¿‡é«˜({ze_ratio*100:.1f}%)")
                        analysis['causes'].append("é½¿è½®çš„ä¸»è¦è¯¯å·®é›†ä¸­åœ¨é½¿é¢‘åŠå…¶å€é¢‘")
                        analysis['recommendations'].append("é‡ç‚¹è§£å†³åˆ†åº¦è¯¯å·®å’Œåˆ€å…·è¯¯å·®é—®é¢˜")
                    
                    if high_order_ratio > 0.6:
                        analysis['issues'].append(f"ğŸŸ  é«˜é˜¶æ¬¡èƒ½é‡å æ¯”è¿‡é«˜({high_order_ratio*100:.1f}%)")
                        analysis['causes'].append("é½¿é¢è´¨é‡é—®é¢˜çªå‡º")
                        analysis['recommendations'].append("é‡ç‚¹æ”¹å–„é½¿é¢ç²—ç³™åº¦")
                    
                    # è¿ç»­å¤šé˜¶æ¬¡å¼‚å¸¸
                    consecutive_issues = []
                    for i in range(len(components) - 2):
                        if components[i].amplitude > 0.02 and components[i+1].amplitude > 0.02 and components[i+2].amplitude > 0.02:
                            consecutive_issues.append((components[i].order, components[i+2].order))
                    
                    if len(consecutive_issues) > 3:
                        analysis['issues'].append(f"ğŸ”´ è¿ç»­å¤šé˜¶æ¬¡({len(consecutive_issues)}å¤„)å‡ºç°å¼‚å¸¸")
                        analysis['causes'].append("å­˜åœ¨ç³»ç»Ÿæ€§çš„åŠ å·¥è¯¯å·®æˆ–å‘¨æœŸæ€§è¯¯å·®")
                        analysis['recommendations'].append("å…¨é¢æ£€æŸ¥åŠ å·¥æœºåºŠçš„å‘¨æœŸæ€§è¯¯å·®ï¼Œæ£€æŸ¥å·¥ä»¶è£…å¤¹ç¨³å®šæ€§")
                    elif len(consecutive_issues) > 1:
                        analysis['issues'].append(f"ğŸŸ¡ è¿ç»­å¤šé˜¶æ¬¡({len(consecutive_issues)}å¤„)å‡ºç°å¼‚å¸¸")
                        analysis['causes'].append("å¯èƒ½å­˜åœ¨å‘¨æœŸæ€§è¯¯å·®")
                        analysis['recommendations'].append("æ£€æŸ¥åŠ å·¥æœºåºŠçš„å‘¨æœŸæ€§è¯¯å·®")
                    
                    # é½¿å½¢/é½¿å‘ç‰¹å®šåˆ†æ
                    if is_profile:
                        if analysis['score'] < 80:
                            analysis['recommendations'].append("ğŸ’¡ é½¿å½¢è¯¯å·®ä¼šç›´æ¥å½±å“é½¿è½®çš„å•®åˆå™ªå£°ï¼Œå»ºè®®ä¼˜å…ˆä¼˜åŒ–")
                    elif is_helix:
                        if analysis['score'] < 80:
                            analysis['recommendations'].append("ğŸ’¡ é½¿å‘è¯¯å·®ä¼šå¯¼è‡´é½¿è½®å•®åˆä¸è‰¯ï¼Œå»ºè®®æ£€æŸ¥é½¿å‘ä¿®å½¢å‚æ•°")
                    
                    # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜
                    if not analysis['issues']:
                        analysis['issues'].append("âœ… æœªå‘ç°æ˜æ˜¾å¼‚å¸¸")
                        analysis['causes'].append("é½¿è½®æ³¢çº¹åº¦åœ¨æ­£å¸¸èŒƒå›´å†…")
                        analysis['recommendations'].append("ç»§ç»­ä¿æŒå½“å‰åŠ å·¥å·¥è‰ºï¼Œå®šæœŸç›‘æµ‹")
                    
                    return analysis
                
                # æ‰§è¡ŒAIåˆ†æ
                ai_analysis = analyze_spectrum_ai(
                    sorted_components, ze, calculate_tolerance_curve, R, N0, K, display_name
                )
                
                # æ˜¾ç¤ºåˆ†æç»“æœ
                status_color = ai_analysis['status_color']
                status_text = ai_analysis['status_text']
                score = ai_analysis['score']
                
                # çŠ¶æ€å’Œè¯„åˆ†æ˜¾ç¤º
                col_status, col_score = st.columns([2, 1])
                with col_status:
                    st.markdown(f"**é½¿è½®çŠ¶æ€: <span style='color:{status_color};font-size:22px;font-weight:bold;'>{status_text}</span>**", unsafe_allow_html=True)
                with col_score:
                    st.metric("ç»¼åˆè¯„åˆ†", f"{score}åˆ†")
                
                # å™ªå£°é¢„æµ‹
                noise_level = ai_analysis['noise_level']
                noise_prediction = ai_analysis['noise_prediction']
                st.markdown(f"**ğŸ”Š å™ªå£°é¢„æµ‹: <span style='color:{'green' if noise_level <= 2 else 'orange' if noise_level <= 3 else 'red'};'>{noise_prediction}</span>** (åŸºäºé¢‘è°±åˆ†æ)", unsafe_allow_html=True)
                
                # èƒ½é‡åˆ†å¸ƒ
                energy = ai_analysis['energy_distribution']
                st.markdown("**ğŸ“Š èƒ½é‡åˆ†å¸ƒ:**")
                ecol1, ecol2, ecol3 = st.columns(3)
                with ecol1:
                    st.progress(min(energy['low_order'], 1.0))
                    st.caption(f"ä½é˜¶æ¬¡: {energy['low_order']*100:.1f}%")
                with ecol2:
                    st.progress(min(energy['ze_related'], 1.0))
                    st.caption(f"ZEç›¸å…³: {energy['ze_related']*100:.1f}%")
                with ecol3:
                    st.progress(min(energy['high_order'], 1.0))
                    st.caption(f"é«˜é˜¶æ¬¡: {energy['high_order']*100:.1f}%")
                
                st.markdown("---")
                
                # é—®é¢˜åˆ—è¡¨
                if ai_analysis['issues']:
                    st.markdown("**ğŸ“‹ å‘ç°é—®é¢˜:**")
                    for issue in ai_analysis['issues']:
                        st.markdown(f"- {issue}")
                
                # åŸå› åˆ†æ
                if ai_analysis['causes']:
                    st.markdown("**ğŸ” åŸå› åˆ†æ:**")
                    for cause in ai_analysis['causes']:
                        st.markdown(f"- {cause}")
                
                # æ”¹è¿›å»ºè®®
                if ai_analysis['recommendations']:
                    st.markdown("**ğŸ’¡ æ”¹è¿›å»ºè®®:**")
                    for rec in ai_analysis['recommendations']:
                        st.markdown(f"- {rec}")
                
                # è¯¦ç»†æ•°æ®æ‘˜è¦
                with st.expander("ğŸ“Š è¯¦ç»†æ•°æ®æ‘˜è¦", expanded=False):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»è°æ³¢æ•°", len(sorted_components))
                        st.metric("é«˜é˜¶è°æ³¢æ•°", len([c for c in sorted_components if c.order >= ze]))
                    with col2:
                        st.metric("æœ€å¤§å¹…å€¼", f"{max(amplitudes):.4f} Î¼m")
                        st.metric("è¶…å·®æ•°é‡", len([c for c in sorted_components[:20] if c.amplitude > calculate_tolerance_curve([c.order], R, N0, K)[0]]))
                    with col3:
                        st.metric("ä¸»å¯¼é˜¶æ¬¡å¹…å€¼", f"{next((c.amplitude for c in sorted_components if abs(c.order - ze) < 1), 0):.4f} Î¼m")
                        st.metric("2å€é¢‘å¹…å€¼", f"{next((c.amplitude for c in sorted_components if abs(c.order - 2*ze) < 1), 0):.4f} Î¼m")
                    
                    # è¶…å·®è¯¦æƒ…
                    if ai_analysis['out_of_tolerance_details']:
                        st.markdown("**è¶…å·®è¯¦æƒ…:**")
                        oot_df = pd.DataFrame(ai_analysis['out_of_tolerance_details'])
                        oot_df.columns = ['é˜¶æ¬¡', 'å¹…å€¼(Î¼m)', 'å…¬å·®(Î¼m)', 'è¶…å·®é‡(Î¼m)']
                        st.dataframe(oot_df, use_container_width=True, hide_index=True)
    
    elif page == 'ğŸ” ä¸‰æˆªé¢æ‰­æ›²æ•°æ®':
        st.markdown("## ä¸‰æˆªé¢æ‰­æ›²æ•°æ®æŠ¥å‘Š")
        
        # æ£€æµ‹æ•°æ®æ ¼å¼ï¼šæ£€æŸ¥æ˜¯å¦æœ‰1a,1b,1cè¿™æ ·çš„ä¸‰æˆªé¢æ•°æ®
        all_teeth = set()
        for side in ['left', 'right']:
            if side in profile_data:
                all_teeth.update(profile_data[side].keys())
            if side in helix_data:
                all_teeth.update(helix_data[side].keys())
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‰æˆªé¢æ•°æ®ï¼ˆ1a, 1b, 1cï¼‰
        has_three_section = any(t in all_teeth for t in ['1a', '1b', '1c'])
        
        if has_three_section:
            st.markdown("### é½¿å· 1a, 1b, 1c çš„é½¿å½¢/é½¿å‘åå·®åˆ†æ")
            tooth_sections = ['1a', '1b', '1c']
        else:
            # å¦‚æœæ²¡æœ‰ä¸‰æˆªé¢æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é½¿å·1çš„æ•°æ®
            if '1' in all_teeth:
                st.markdown("### é½¿å· 1 çš„é½¿å½¢/é½¿å‘åå·®åˆ†æ")
                tooth_sections = ['1']
            else:
                # æ˜¾ç¤ºå‰3ä¸ªå¯ç”¨çš„é½¿
                available_teeth = sorted(list(all_teeth), key=tooth_sort_key)[:3]
                if available_teeth:
                    st.markdown(f"### é½¿å· {', '.join(available_teeth)} çš„é½¿å½¢/é½¿å‘åå·®åˆ†æ")
                    tooth_sections = available_teeth
                else:
                    st.warning("æœªæ‰¾åˆ°å¯ç”¨çš„é½¿æ•°æ®")
                    st.stop()
        
        # å…ˆæ”¶é›†æ‰€æœ‰æ•°æ®ï¼ˆç”¨äºåé¢çš„è¡¨æ ¼æ˜¾ç¤ºï¼‰
        profile_sections_data = []
        helix_sections_data = []
        
        for section in tooth_sections:
            # é½¿å½¢æ•°æ®
            row_data_profile = {'Tooth': section}
            has_profile_data = False
            
            # å·¦é½¿é¢
            if 'left' in profile_data and section in profile_data['left']:
                tooth_data = profile_data['left'][section]
                if tooth_data:
                    z_positions = list(tooth_data.keys())
                    if z_positions:
                        mid_z = z_positions[len(z_positions) // 2]
                        values = np.array(tooth_data[mid_z])
                        F_a, fH_a, ff_a, Ca = calc_profile_deviations(values)
                        if F_a is not None:
                            row_data_profile['fHÎ±_L'] = fH_a
                            row_data_profile['ffÎ±_L'] = ff_a
                            row_data_profile['FÎ±_L'] = F_a
                            row_data_profile['Ca_L'] = Ca
                            has_profile_data = True
            
            # å³é½¿é¢
            if 'right' in profile_data and section in profile_data['right']:
                tooth_data = profile_data['right'][section]
                if tooth_data:
                    z_positions = list(tooth_data.keys())
                    if z_positions:
                        mid_z = z_positions[len(z_positions) // 2]
                        values = np.array(tooth_data[mid_z])
                        F_a, fH_a, ff_a, Ca = calc_profile_deviations(values)
                        if F_a is not None:
                            row_data_profile['fHÎ±_R'] = fH_a
                            row_data_profile['ffÎ±_R'] = ff_a
                            row_data_profile['FÎ±_R'] = F_a
                            row_data_profile['Ca_R'] = Ca
                            has_profile_data = True
            
            if has_profile_data:
                profile_sections_data.append(row_data_profile)
            
            # é½¿å‘æ•°æ®
            row_data_helix = {'Tooth': section}
            has_helix_data = False
            
            # å·¦é½¿é¢
            if 'left' in helix_data and section in helix_data['left']:
                tooth_data = helix_data['left'][section]
                if tooth_data:
                    d_positions = list(tooth_data.keys())
                    if d_positions:
                        mid_d = d_positions[len(d_positions) // 2]
                        values = np.array(tooth_data[mid_d])
                        F_b, fH_b, ff_b, Cb = calc_lead_deviations(values)
                        if F_b is not None:
                            row_data_helix['fHÎ²_L'] = fH_b
                            row_data_helix['ffÎ²_L'] = ff_b
                            row_data_helix['FÎ²_L'] = F_b
                            row_data_helix['Cb_L'] = Cb
                            has_helix_data = True
            
            # å³é½¿é¢
            if 'right' in helix_data and section in helix_data['right']:
                tooth_data = helix_data['right'][section]
                if tooth_data:
                    d_positions = list(tooth_data.keys())
                    if d_positions:
                        mid_d = d_positions[len(d_positions) // 2]
                        values = np.array(tooth_data[mid_d])
                        F_b, fH_b, ff_b, Cb = calc_lead_deviations(values)
                        if F_b is not None:
                            row_data_helix['fHÎ²_R'] = fH_b
                            row_data_helix['ffÎ²_R'] = ff_b
                            row_data_helix['FÎ²_R'] = F_b
                            row_data_helix['Cb_R'] = Cb
                            has_helix_data = True
            
            if has_helix_data:
                helix_sections_data.append(row_data_helix)
        
        # æ˜¾ç¤ºè¯¦ç»†æ›²çº¿å›¾ - æŒ‰ç±»å‹åˆ†ç»„ï¼šå·¦é½¿å½¢ã€å³é½¿å½¢ã€å·¦é½¿å‘ã€å³é½¿å‘
        st.markdown("#### è¯¦ç»†æ›²çº¿å›¾")
        
        # ===== å·¦é½¿é¢é½¿å½¢ (Left Profile) =====
        st.markdown("**Left Profile å·¦é½¿é¢é½¿å½¢**")
        cols = st.columns(3)
        for i, section in enumerate(tooth_sections):
            with cols[i]:
                if 'left' in profile_data and section in profile_data['left']:
                    tooth_profiles = profile_data['left'][section]
                    if tooth_profiles:
                        best_z = list(tooth_profiles.keys())[len(tooth_profiles)//2]
                        values = np.array(tooth_profiles[best_z])
                        
                        fig, ax = plt.subplots(figsize=(3.5, 5))
                        y_positions = np.linspace(da, de, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'r-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = de - da
                        idx_eval_start = int((d1 - da) / meas_length * (n - 1))
                        idx_eval_end = int((d2 - da) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=8, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=8, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=8, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=8, color='red')
                        
                        ax.set_ylim(da - 1, de + 1)
                        ax.set_yticks([da, d1, d2, de])
                        ax.set_yticklabels([f'{da:.1f}', f'{d1:.1f}', f'{d2:.1f}', f'{de:.1f}'], fontsize=8)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=8)
                        ax.grid(True, linestyle=':', linewidth=0.5, color='gray')
                        ax.set_xlabel(f'{section}', fontsize=10, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
        
        # å·¦é½¿é¢é½¿å½¢æ•°æ®è¡¨
        if profile_sections_data:
            st.markdown("**Left Profile æ•°æ®**")
            df_left_profile = pd.DataFrame(profile_sections_data)[['Tooth', 'fHÎ±_L', 'ffÎ±_L', 'FÎ±_L', 'Ca_L']]
            df_left_profile = df_left_profile.dropna()
            if not df_left_profile.empty:
                st.dataframe(df_left_profile.style.format({
                    'fHÎ±_L': '{:.2f}', 'ffÎ±_L': '{:.2f}', 'FÎ±_L': '{:.2f}', 'Ca_L': '{:.2f}'
                }), use_container_width=True, hide_index=True)
        
        # ===== å³é½¿é¢é½¿å½¢ (Right Profile) =====
        st.markdown("**Right Profile å³é½¿é¢é½¿å½¢**")
        cols = st.columns(3)
        for i, section in enumerate(tooth_sections):
            with cols[i]:
                if 'right' in profile_data and section in profile_data['right']:
                    tooth_profiles = profile_data['right'][section]
                    if tooth_profiles:
                        best_z = list(tooth_profiles.keys())[len(tooth_profiles)//2]
                        values = np.array(tooth_profiles[best_z])
                        
                        fig, ax = plt.subplots(figsize=(3.5, 5))
                        y_positions = np.linspace(da, de, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'r-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = de - da
                        idx_eval_start = int((d1 - da) / meas_length * (n - 1))
                        idx_eval_end = int((d2 - da) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=8, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=8, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=8, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=8, color='red')
                        
                        ax.set_ylim(da - 1, de + 1)
                        ax.set_yticks([da, d1, d2, de])
                        ax.set_yticklabels([f'{da:.1f}', f'{d1:.1f}', f'{d2:.1f}', f'{de:.1f}'], fontsize=8)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=8)
                        ax.grid(True, linestyle=':', linewidth=0.5, color='gray')
                        ax.set_xlabel(f'{section}', fontsize=10, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
        
        # å³é½¿é¢é½¿å½¢æ•°æ®è¡¨
        if profile_sections_data:
            st.markdown("**Right Profile æ•°æ®**")
            df_right_profile = pd.DataFrame(profile_sections_data)[['Tooth', 'fHÎ±_R', 'ffÎ±_R', 'FÎ±_R', 'Ca_R']]
            df_right_profile = df_right_profile.dropna()
            if not df_right_profile.empty:
                st.dataframe(df_right_profile.style.format({
                    'fHÎ±_R': '{:.2f}', 'ffÎ±_R': '{:.2f}', 'FÎ±_R': '{:.2f}', 'Ca_R': '{:.2f}'
                }), use_container_width=True, hide_index=True)
        
        # ===== å·¦é½¿é¢é½¿å‘ (Left Helix) =====
        st.markdown("**Left Helix å·¦é½¿é¢é½¿å‘**")
        cols = st.columns(3)
        for i, section in enumerate(tooth_sections):
            with cols[i]:
                if 'left' in helix_data and section in helix_data['left']:
                    tooth_helix = helix_data['left'][section]
                    if tooth_helix:
                        best_d = list(tooth_helix.keys())[len(tooth_helix)//2]
                        values = np.array(tooth_helix[best_d])
                        
                        fig, ax = plt.subplots(figsize=(3.5, 5))
                        y_positions = np.linspace(ba, be, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'k-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = be - ba
                        idx_eval_start = int((b1 - ba) / meas_length * (n - 1))
                        idx_eval_end = int((b2 - ba) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=8, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=8, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=8, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=8, color='red')
                        
                        ax.set_ylim(ba - 1, be + 1)
                        ax.set_yticks([ba, b1, b2, be])
                        ax.set_yticklabels([f'{ba:.1f}', f'{b1:.1f}', f'{b2:.1f}', f'{be:.1f}'], fontsize=8)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=8)
                        ax.grid(True, linestyle=':', linewidth=0.5, color='gray')
                        ax.set_xlabel(f'{section}', fontsize=10, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
        
        # å·¦é½¿é¢é½¿å‘æ•°æ®è¡¨
        if helix_sections_data:
            st.markdown("**Left Helix æ•°æ®**")
            df_left_helix = pd.DataFrame(helix_sections_data)[['Tooth', 'fHÎ²_L', 'ffÎ²_L', 'FÎ²_L', 'Cb_L']]
            df_left_helix = df_left_helix.dropna()
            if not df_left_helix.empty:
                st.dataframe(df_left_helix.style.format({
                    'fHÎ²_L': '{:.2f}', 'ffÎ²_L': '{:.2f}', 'FÎ²_L': '{:.2f}', 'Cb_L': '{:.2f}'
                }), use_container_width=True, hide_index=True)
        
        # ===== å³é½¿é¢é½¿å‘ (Right Helix) =====
        st.markdown("**Right Helix å³é½¿é¢é½¿å‘**")
        cols = st.columns(3)
        for i, section in enumerate(tooth_sections):
            with cols[i]:
                if 'right' in helix_data and section in helix_data['right']:
                    tooth_helix = helix_data['right'][section]
                    if tooth_helix:
                        best_d = list(tooth_helix.keys())[len(tooth_helix)//2]
                        values = np.array(tooth_helix[best_d])
                        
                        fig, ax = plt.subplots(figsize=(3.5, 5))
                        y_positions = np.linspace(ba, be, len(values))
                        ax.plot(values / 50.0 + 1, y_positions, 'k-', linewidth=1.0)
                        ax.axvline(x=1, color='black', linestyle='-', linewidth=0.5)
                        
                        n = len(values)
                        meas_length = be - ba
                        idx_eval_start = int((b1 - ba) / meas_length * (n - 1))
                        idx_eval_end = int((b2 - ba) / meas_length * (n - 1))
                        
                        ax.plot(1, y_positions[0], 'v', markersize=8, color='blue')
                        ax.plot(1, y_positions[idx_eval_start], 'v', markersize=8, color='green')
                        ax.plot(1, y_positions[idx_eval_end], '^', markersize=8, color='orange')
                        ax.plot(1, y_positions[-1], '^', markersize=8, color='red')
                        
                        ax.set_ylim(ba - 1, be + 1)
                        ax.set_yticks([ba, b1, b2, be])
                        ax.set_yticklabels([f'{ba:.1f}', f'{b1:.1f}', f'{b2:.1f}', f'{be:.1f}'], fontsize=8)
                        ax.set_xlim(0.3, 1.7)
                        ax.set_xticks([0.5, 1.0, 1.5])
                        ax.set_xticklabels(['-25', '0', '+25'], fontsize=8)
                        ax.grid(True, linestyle=':', linewidth=0.5, color='gray')
                        ax.set_xlabel(f'{section}', fontsize=10, fontweight='bold')
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
        
        # å³é½¿é¢é½¿å‘æ•°æ®è¡¨
        if helix_sections_data:
            st.markdown("**Right Helix æ•°æ®**")
            df_right_helix = pd.DataFrame(helix_sections_data)[['Tooth', 'fHÎ²_R', 'ffÎ²_R', 'FÎ²_R', 'Cb_R']]
            df_right_helix = df_right_helix.dropna()
            if not df_right_helix.empty:
                st.dataframe(df_right_helix.style.format({
                    'fHÎ²_R': '{:.2f}', 'ffÎ²_R': '{:.2f}', 'FÎ²_R': '{:.2f}', 'Cb_R': '{:.2f}'
                }), use_container_width=True, hide_index=True)
    
    elif page == 'ğŸ—ºï¸ é½¿é¢æ‹“æ™®å›¾':
        st.markdown("## ğŸ—ºï¸ é½¿é¢TOPOGRAFIEæ‹“æ™®å›¾")
        st.markdown("### é½¿é¢åå·®çƒ­åŠ›å›¾åˆ†æ")
        
        # è§£æTOPOGRAFIEæ•°æ®
        def parse_topografie_data(file_path):
            with open(file_path, 'r', encoding='latin-1') as f:
                lines = f.readlines()
            
            topografie_data = {
                'rechts': {'profiles': [], 'flank': None},
                'links': {'profiles': [], 'flank': None}
            }
            
            current_section = None
            current_values = []
            current_meta = {}
            undefined_value = -2147483.648
            
            for line in lines:
                line_stripped = line.strip()
                
                if line_stripped.startswith('TOPOGRAFIE:'):
                    if current_section and current_values:
                        if current_meta.get('type') == 'Profil':
                            side = current_meta.get('side', 'rechts')
                            topografie_data[side]['profiles'].append({
                                'position': current_meta.get('position', 0),
                                'values': np.array(current_values)
                            })
                        elif current_meta.get('type') == 'Flankenlinie':
                            side = current_meta.get('side', 'rechts')
                            topografie_data[side]['flank'] = {
                                'diameter': current_meta.get('diameter', 0),
                                'values': np.array(current_values)
                            }
                    
                    current_values = []
                    current_meta = {}
                    
                    if '/Profil:' in line_stripped:
                        current_meta['type'] = 'Profil'
                        match = re.search(r'Profil:(\d+)\s+(rechts|links)', line_stripped)
                        if match:
                            current_meta['profile_num'] = int(match.group(1))
                            current_meta['side'] = match.group(2)
                        match_z = re.search(r'z=\s*(\d+\.\d+)', line_stripped)
                        if match_z:
                            current_meta['position'] = float(match_z.group(1))
                            
                    elif '/Flankenlinie:' in line_stripped:
                        current_meta['type'] = 'Flankenlinie'
                        match = re.search(r'Flankenlinie:\d+\s+(rechts|links)', line_stripped)
                        if match:
                            current_meta['side'] = match.group(1)
                        match_d = re.search(r'd=\s*(\d+\.\d+)', line_stripped)
                        if match_d:
                            current_meta['diameter'] = float(match_d.group(1))
                    
                    current_section = 'data'
                    
                elif current_section == 'data' and line_stripped:
                    values = re.findall(r'[-+]?\d*\.\d+', line_stripped)
                    for v in values:
                        val = float(v)
                        if val != undefined_value:
                            current_values.append(val)
            
            if current_section and current_values:
                if current_meta.get('type') == 'Profil':
                    side = current_meta.get('side', 'rechts')
                    topografie_data[side]['profiles'].append({
                        'position': current_meta.get('position', 0),
                        'values': np.array(current_values)
                    })
                elif current_meta.get('type') == 'Flankenlinie':
                    side = current_meta.get('side', 'rechts')
                    topografie_data[side]['flank'] = {
                        'diameter': current_meta.get('diameter', 0),
                        'values': np.array(current_values)
                    }
            
            for side in ['rechts', 'links']:
                topografie_data[side]['profiles'].sort(key=lambda x: x['position'])
            
            return topografie_data
        
        def create_topography_map(topografie_data, side='rechts'):
            profiles = topografie_data[side]['profiles']
            if not profiles:
                return None, None, None
            
            n_profiles = len(profiles)
            n_points = min(len(p['values']) for p in profiles)
            z_positions = [p['position'] for p in profiles]
            
            data_matrix = np.zeros((n_profiles, n_points))
            for i, profile in enumerate(profiles):
                values = profile['values'][:n_points]
                data_matrix[i, :] = values
            
            return data_matrix, z_positions, n_points
        
        def plot_topography(data_matrix, z_positions, n_points, side='rechts', title_suffix=''):
            fig, ax = plt.subplots(figsize=(10, 6))
            
            colors = ['#0000FF', '#00FFFF', '#00FF00', '#FFFF00', '#FF0000']
            cmap = LinearSegmentedColormap.from_list('gear_topo', colors, N=256)
            
            im = ax.imshow(data_matrix, aspect='auto', cmap=cmap, origin='lower',
                           extent=[0, n_points-1, z_positions[0], z_positions[-1]])
            
            cbar = plt.colorbar(im, ax=ax, label='åå·® (Âµm)')
            
            ax.set_xlabel('é½¿é«˜æ–¹å‘ (æµ‹é‡ç‚¹)', fontsize=11)
            ax.set_ylabel('é½¿å®½æ–¹å‘ z (mm)', fontsize=11)
            ax.set_title(f'é½¿é¢TOPOGRAFIEæ‹“æ™®å›¾ - {side}ä¾§{title_suffix}', fontsize=13)
            
            return fig, ax
        
        with st.spinner("æ­£åœ¨è§£æTOPOGRAFIEæ•°æ®..."):
            topografie_data = parse_topografie_data(temp_path)
        
        col1, col2 = st.columns(2)
        
        for idx, side in enumerate(['rechts', 'links']):
            side_name = 'å³é½¿é¢' if side == 'rechts' else 'å·¦é½¿é¢'
            profiles = topografie_data[side]['profiles']
            
            with [col1, col2][idx]:
                st.markdown(f"### {side_name}")
                
                if profiles:
                    st.markdown(f"**æ•°æ®ç»Ÿè®¡:** Profilæ•°é‡: {len(profiles)}, zèŒƒå›´: {profiles[0]['position']:.1f}-{profiles[-1]['position']:.1f} mm")
                    
                    data_matrix, z_positions, n_points = create_topography_map(topografie_data, side)
                    
                    if data_matrix is not None:
                        fig, ax = plot_topography(data_matrix, z_positions, n_points, side_name, f" ({uploaded_file.name})")
                        st.pyplot(fig)
                        plt.close(fig)
                        
                        st.markdown(f"**åå·®èŒƒå›´:**")
                        col_a, col_b, col_c, col_d = st.columns(4)
                        with col_a:
                            st.metric("æœ€å°å€¼", f"{np.min(data_matrix):.2f} Âµm")
                        with col_b:
                            st.metric("æœ€å¤§å€¼", f"{np.max(data_matrix):.2f} Âµm")
                        with col_c:
                            st.metric("å¹³å‡å€¼", f"{np.mean(data_matrix):.2f} Âµm")
                        with col_d:
                            st.metric("æ ‡å‡†å·®", f"{np.std(data_matrix):.2f} Âµm")
                else:
                    st.warning(f"æœªæ‰¾åˆ°{side_name}çš„TOPOGRAFIEæ•°æ®")
        
        st.markdown("---")
        st.markdown("### ğŸ“– æ‹“æ™®å›¾è¯´æ˜")
        st.info("""
        **é½¿é¢TOPOGRAFIEæ‹“æ™®å›¾** æ˜¾ç¤ºæ•´ä¸ªé½¿é¢çš„åå·®åˆ†å¸ƒæƒ…å†µï¼š
        - **Xè½´**: é½¿é«˜æ–¹å‘ï¼ˆä»é½¿æ ¹åˆ°é½¿é¡¶ï¼‰
        - **Yè½´**: é½¿å®½æ–¹å‘ï¼ˆä»ä¸€ç«¯åˆ°å¦ä¸€ç«¯ï¼‰
        - **é¢œè‰²**: åå·®å€¼ï¼ˆè“è‰²=è´Ÿåå·®ï¼Œçº¢è‰²=æ­£åå·®ï¼‰
        
        é€šè¿‡æ‹“æ™®å›¾å¯ä»¥ç›´è§‚åœ°çœ‹åˆ°é½¿é¢çš„åŠ å·¥è¯¯å·®åˆ†å¸ƒï¼Œè¯†åˆ«ç³»ç»Ÿæ€§åå·®å’Œå±€éƒ¨ç¼ºé™·ã€‚
        """)
    
    elif page == 'ğŸ¤– AIç»¼åˆåˆ†ææŠ¥å‘Š':
        st.markdown("## ğŸ¤– AIç»¼åˆåˆ†ææŠ¥å‘Š")
        
        # è®¡ç®—é¢‘è°±åˆ†æç»“æœ
        with st.spinner("æ­£åœ¨è®¡ç®—é¢‘è°±åˆ†æ..."):
            results = {
                'profile_left': analyzer.analyze_profile('left', verbose=False),
                'profile_right': analyzer.analyze_profile('right', verbose=False),
                'helix_left': analyzer.analyze_helix('left', verbose=False),
                'helix_right': analyzer.analyze_helix('right', verbose=False)
            }
        
        name_mapping = {
            'profile_left': 'Left Profile',
            'profile_right': 'Right Profile',
            'helix_left': 'Left Lead',
            'helix_right': 'Right Lead'
        }
        
        # æ”¶é›†æ‰€æœ‰åˆ†ææ•°æ®
        def generate_comprehensive_analysis():
            """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š - æ™ºèƒ½åˆ†æé½¿è½®é—®é¢˜"""
            report = {
                'overall_score': 0,
                'status': 'æ­£å¸¸',
                'status_color': 'green',
                'profile_analysis': {},
                'helix_analysis': {},
                'pitch_analysis': {},
                'spectrum_analysis': {},
                'issues': [],
                'causes': [],
                'recommendations': [],
                'noise_prediction': 'ä½',
                'quality_grade': 'Q6',
                'detailed_diagnosis': {}
            }
            
            scores = []
            
            # ========== 1. é½¿å½¢åå·®æ™ºèƒ½åˆ†æ ==========
            profile_score = 100
            profile_issues = []
            profile_diagnosis = {}
            
            if profile_eval:
                for side in ['left', 'right']:
                    side_data = profile_data.get(side, {})
                    if side_data:
                        deviations = []
                        all_ffa = []
                        all_fHa = []
                        all_Fa = []
                        
                        for tooth_id, tooth_profiles in side_data.items():
                            helix_mid = (helix_eval.eval_start + helix_eval.eval_end) / 2
                            best_z = min(tooth_profiles.keys(), key=lambda z: abs(z - helix_mid))
                            values = np.array(tooth_profiles[best_z])
                            F_a, fH_a, ff_a, Ca = calc_profile_deviations(values)
                            if F_a is not None:
                                deviations.append({'FÎ±': F_a, 'fHÎ±': fH_a, 'ffÎ±': ff_a, 'Ca': Ca})
                                all_Fa.append(F_a)
                                all_fHa.append(fH_a)
                                all_ffa.append(ff_a)
                        
                        if deviations:
                            avg_Fa = np.mean(all_Fa)
                            avg_fHa = np.mean(all_fHa)
                            avg_ffa = np.mean(all_ffa)
                            std_Fa = np.std(all_Fa) if len(all_Fa) > 1 else 0
                            
                            report['profile_analysis'][side] = {
                                'avg_FÎ±': avg_Fa,
                                'avg_fHÎ±': avg_fHa,
                                'avg_ffÎ±': avg_ffa,
                                'std_FÎ±': std_Fa
                            }
                            
                            # æ™ºèƒ½è¯Šæ–­é½¿å½¢é—®é¢˜
                            side_name = 'å·¦' if side == 'left' else 'å³'
                            
                            # é½¿å½¢æ€»åå·®åˆ†æ
                            if avg_Fa > 20:
                                profile_score -= 25
                                profile_issues.append(f"ğŸ”´ {side_name}é½¿é¢é½¿å½¢æ€»åå·®FÎ±ä¸¥é‡è¶…æ ‡({avg_Fa:.2f}Î¼m)")
                                profile_diagnosis[side] = {'severity': 'critical', 'type': 'FÎ±_excessive'}
                            elif avg_Fa > 15:
                                profile_score -= 15
                                profile_issues.append(f"ğŸŸ  {side_name}é½¿é¢é½¿å½¢æ€»åå·®FÎ±è¿‡å¤§({avg_Fa:.2f}Î¼m)")
                                profile_diagnosis[side] = {'severity': 'warning', 'type': 'FÎ±_high'}
                            elif avg_Fa > 10:
                                profile_score -= 8
                                profile_issues.append(f"ğŸŸ¡ {side_name}é½¿é¢é½¿å½¢æ€»åå·®FÎ±åå¤§({avg_Fa:.2f}Î¼m)")
                            
                            # é½¿å½¢å€¾æ–œåå·®åˆ†æ - å‹åŠ›è§’è¯¯å·®
                            if abs(avg_fHa) > 10:
                                profile_score -= 15
                                direction = "æ­£" if avg_fHa > 0 else "è´Ÿ"
                                profile_issues.append(f"ğŸ”´ {side_name}é½¿é¢å‹åŠ›è§’è¯¯å·®ä¸¥é‡({direction}å‘å€¾æ–œ{abs(avg_fHa):.2f}Î¼m)")
                                profile_diagnosis.setdefault(side, {})['pressure_angle'] = 'severe'
                            elif abs(avg_fHa) > 6:
                                profile_score -= 8
                                direction = "æ­£" if avg_fHa > 0 else "è´Ÿ"
                                profile_issues.append(f"ğŸŸ  {side_name}é½¿é¢å­˜åœ¨å‹åŠ›è§’è¯¯å·®({direction}å‘å€¾æ–œ{abs(avg_fHa):.2f}Î¼m)")
                                profile_diagnosis.setdefault(side, {})['pressure_angle'] = 'moderate'
                            
                            # é½¿å½¢å½¢çŠ¶åå·®åˆ†æ - é½¿é¢æ³¢çº¹
                            if avg_ffa > 8:
                                profile_score -= 10
                                profile_issues.append(f"ğŸŸ  {side_name}é½¿é¢å½¢çŠ¶åå·®ffÎ±è¿‡å¤§({avg_ffa:.2f}Î¼m)ï¼Œå­˜åœ¨æ³¢çº¹")
                                profile_diagnosis.setdefault(side, {})['waviness'] = True
                            
                            # é½¿å½¢ä¸€è‡´æ€§åˆ†æ
                            if std_Fa > 5:
                                profile_score -= 8
                                profile_issues.append(f"ğŸŸ¡ {side_name}é½¿é¢å„é½¿é½¿å½¢åå·®ä¸ä¸€è‡´(æ ‡å‡†å·®{std_Fa:.2f}Î¼m)")
                                profile_diagnosis.setdefault(side, {})['inconsistency'] = True
            
            scores.append(max(0, profile_score))
            report['profile_analysis']['score'] = max(0, profile_score)
            report['profile_analysis']['issues'] = profile_issues
            report['detailed_diagnosis']['profile'] = profile_diagnosis
            
            # ========== 2. é½¿å‘åå·®æ™ºèƒ½åˆ†æ ==========
            helix_score = 100
            helix_issues = []
            helix_diagnosis = {}
            
            if helix_eval:
                for side in ['left', 'right']:
                    side_data = helix_data.get(side, {})
                    if side_data:
                        deviations = []
                        all_Fb = []
                        all_fHb = []
                        all_ffb = []
                        
                        for tooth_id, tooth_helix in side_data.items():
                            profile_mid = (profile_eval.eval_start + profile_eval.eval_end) / 2
                            best_d = min(tooth_helix.keys(), key=lambda d: abs(d - profile_mid))
                            values = np.array(tooth_helix[best_d])
                            F_b, fH_b, ff_b, Cb = calc_lead_deviations(values)
                            if F_b is not None:
                                deviations.append({'FÎ²': F_b, 'fHÎ²': fH_b, 'ffÎ²': ff_b, 'Cb': Cb})
                                all_Fb.append(F_b)
                                all_fHb.append(fH_b)
                                all_ffb.append(ff_b)
                        
                        if deviations:
                            avg_Fb = np.mean(all_Fb)
                            avg_fHb = np.mean(all_fHb)
                            avg_ffb = np.mean(all_ffb)
                            std_Fb = np.std(all_Fb) if len(all_Fb) > 1 else 0
                            
                            report['helix_analysis'][side] = {
                                'avg_FÎ²': avg_Fb,
                                'avg_fHÎ²': avg_fHb,
                                'avg_ffÎ²': avg_ffb,
                                'std_FÎ²': std_Fb
                            }
                            
                            side_name = 'å·¦' if side == 'left' else 'å³'
                            
                            # é½¿å‘æ€»åå·®åˆ†æ
                            if avg_Fb > 20:
                                helix_score -= 25
                                helix_issues.append(f"ğŸ”´ {side_name}é½¿é¢é½¿å‘æ€»åå·®FÎ²ä¸¥é‡è¶…æ ‡({avg_Fb:.2f}Î¼m)")
                                helix_diagnosis[side] = {'severity': 'critical', 'type': 'FÎ²_excessive'}
                            elif avg_Fb > 15:
                                helix_score -= 15
                                helix_issues.append(f"ğŸŸ  {side_name}é½¿é¢é½¿å‘æ€»åå·®FÎ²è¿‡å¤§({avg_Fb:.2f}Î¼m)")
                                helix_diagnosis[side] = {'severity': 'warning', 'type': 'FÎ²_high'}
                            elif avg_Fb > 10:
                                helix_score -= 8
                                helix_issues.append(f"ğŸŸ¡ {side_name}é½¿é¢é½¿å‘æ€»åå·®FÎ²åå¤§({avg_Fb:.2f}Î¼m)")
                            
                            # é½¿å‘å€¾æ–œåå·®åˆ†æ - èºæ—‹è§’è¯¯å·®
                            if abs(avg_fHb) > 10:
                                helix_score -= 15
                                direction = "æ­£" if avg_fHb > 0 else "è´Ÿ"
                                helix_issues.append(f"ğŸ”´ {side_name}é½¿é¢èºæ—‹è§’è¯¯å·®ä¸¥é‡({direction}å‘å€¾æ–œ{abs(avg_fHb):.2f}Î¼m)")
                                helix_diagnosis.setdefault(side, {})['helix_angle'] = 'severe'
                            elif abs(avg_fHb) > 6:
                                helix_score -= 8
                                direction = "æ­£" if avg_fHb > 0 else "è´Ÿ"
                                helix_issues.append(f"ğŸŸ  {side_name}é½¿é¢å­˜åœ¨èºæ—‹è§’è¯¯å·®({direction}å‘å€¾æ–œ{abs(avg_fHb):.2f}Î¼m)")
                                helix_diagnosis.setdefault(side, {})['helix_angle'] = 'moderate'
                            
                            # é½¿å‘å½¢çŠ¶åå·®åˆ†æ
                            if avg_ffb > 8:
                                helix_score -= 10
                                helix_issues.append(f"ğŸŸ  {side_name}é½¿é¢é½¿å‘å½¢çŠ¶åå·®ffÎ²è¿‡å¤§({avg_ffb:.2f}Î¼m)")
                                helix_diagnosis.setdefault(side, {})['shape_error'] = True
                            
                            # é½¿å‘ä¸€è‡´æ€§åˆ†æ
                            if std_Fb > 5:
                                helix_score -= 8
                                helix_issues.append(f"ğŸŸ¡ {side_name}é½¿é¢å„é½¿é½¿å‘åå·®ä¸ä¸€è‡´(æ ‡å‡†å·®{std_Fb:.2f}Î¼m)")
                                helix_diagnosis.setdefault(side, {})['inconsistency'] = True
            
            scores.append(max(0, helix_score))
            report['helix_analysis']['score'] = max(0, helix_score)
            report['helix_analysis']['issues'] = helix_issues
            report['detailed_diagnosis']['helix'] = helix_diagnosis
            
            # ========== 3. å‘¨èŠ‚åå·®æ™ºèƒ½åˆ†æ ==========
            pitch_score = 100
            pitch_issues = []
            pitch_diagnosis = {}
            
            if pitch_left:
                report['pitch_analysis']['left'] = {
                    'fp_max': pitch_left.fp_max,
                    'Fp_max': pitch_left.Fp_max,
                    'Fr': pitch_left.Fr
                }
                
                # å•ä¸ªé½¿è·åå·®
                if pitch_left.fp_max > 15:
                    pitch_score -= 20
                    pitch_issues.append(f"ğŸ”´ å·¦é½¿é¢å•ä¸ªé½¿è·åå·®fpä¸¥é‡è¶…æ ‡({pitch_left.fp_max:.2f}Î¼m)")
                    pitch_diagnosis['left_fp'] = 'critical'
                elif pitch_left.fp_max > 10:
                    pitch_score -= 12
                    pitch_issues.append(f"ğŸŸ  å·¦é½¿é¢å•ä¸ªé½¿è·åå·®fpè¿‡å¤§({pitch_left.fp_max:.2f}Î¼m)")
                    pitch_diagnosis['left_fp'] = 'warning'
                elif pitch_left.fp_max > 6:
                    pitch_score -= 5
                    pitch_issues.append(f"ğŸŸ¡ å·¦é½¿é¢å•ä¸ªé½¿è·åå·®fpåå¤§({pitch_left.fp_max:.2f}Î¼m)")
                
                # é½¿è·ç´¯ç§¯åå·®
                if pitch_left.Fp_max > 40:
                    pitch_score -= 20
                    pitch_issues.append(f"ğŸ”´ å·¦é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpä¸¥é‡è¶…æ ‡({pitch_left.Fp_max:.2f}Î¼m)")
                    pitch_diagnosis['left_Fp'] = 'critical'
                elif pitch_left.Fp_max > 30:
                    pitch_score -= 12
                    pitch_issues.append(f"ğŸŸ  å·¦é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpè¿‡å¤§({pitch_left.Fp_max:.2f}Î¼m)")
                    pitch_diagnosis['left_Fp'] = 'warning'
                elif pitch_left.Fp_max > 20:
                    pitch_score -= 5
                    pitch_issues.append(f"ğŸŸ¡ å·¦é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpåå¤§({pitch_left.Fp_max:.2f}Î¼m)")
                
                # å¾„å‘è·³åŠ¨
                if pitch_left.Fr > 25:
                    pitch_score -= 15
                    pitch_issues.append(f"ğŸ”´ å·¦é½¿é¢å¾„å‘è·³åŠ¨Frä¸¥é‡è¶…æ ‡({pitch_left.Fr:.2f}Î¼m)")
                    pitch_diagnosis['left_Fr'] = 'critical'
                elif pitch_left.Fr > 20:
                    pitch_score -= 10
                    pitch_issues.append(f"ğŸŸ  å·¦é½¿é¢å¾„å‘è·³åŠ¨Frè¿‡å¤§({pitch_left.Fr:.2f}Î¼m)")
                    pitch_diagnosis['left_Fr'] = 'warning'
                elif pitch_left.Fr > 15:
                    pitch_score -= 5
                    pitch_issues.append(f"ğŸŸ¡ å·¦é½¿é¢å¾„å‘è·³åŠ¨Fråå¤§({pitch_left.Fr:.2f}Î¼m)")
            
            if pitch_right:
                report['pitch_analysis']['right'] = {
                    'fp_max': pitch_right.fp_max,
                    'Fp_max': pitch_right.Fp_max,
                    'Fr': pitch_right.Fr
                }
                
                if pitch_right.fp_max > 15:
                    pitch_score -= 20
                    pitch_issues.append(f"ğŸ”´ å³é½¿é¢å•ä¸ªé½¿è·åå·®fpä¸¥é‡è¶…æ ‡({pitch_right.fp_max:.2f}Î¼m)")
                elif pitch_right.fp_max > 10:
                    pitch_score -= 12
                    pitch_issues.append(f"ğŸŸ  å³é½¿é¢å•ä¸ªé½¿è·åå·®fpè¿‡å¤§({pitch_right.fp_max:.2f}Î¼m)")
                elif pitch_right.fp_max > 6:
                    pitch_score -= 5
                    pitch_issues.append(f"ğŸŸ¡ å³é½¿é¢å•ä¸ªé½¿è·åå·®fpåå¤§({pitch_right.fp_max:.2f}Î¼m)")
                
                if pitch_right.Fp_max > 40:
                    pitch_score -= 20
                    pitch_issues.append(f"ğŸ”´ å³é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpä¸¥é‡è¶…æ ‡({pitch_right.Fp_max:.2f}Î¼m)")
                elif pitch_right.Fp_max > 30:
                    pitch_score -= 12
                    pitch_issues.append(f"ğŸŸ  å³é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpè¿‡å¤§({pitch_right.Fp_max:.2f}Î¼m)")
                elif pitch_right.Fp_max > 20:
                    pitch_score -= 5
                    pitch_issues.append(f"ğŸŸ¡ å³é½¿é¢é½¿è·ç´¯ç§¯åå·®Fpåå¤§({pitch_right.Fp_max:.2f}Î¼m)")
                
                if pitch_right.Fr > 25:
                    pitch_score -= 15
                    pitch_issues.append(f"ğŸ”´ å³é½¿é¢å¾„å‘è·³åŠ¨Frä¸¥é‡è¶…æ ‡({pitch_right.Fr:.2f}Î¼m)")
                elif pitch_right.Fr > 20:
                    pitch_score -= 10
                    pitch_issues.append(f"ğŸŸ  å³é½¿é¢å¾„å‘è·³åŠ¨Frè¿‡å¤§({pitch_right.Fr:.2f}Î¼m)")
                elif pitch_right.Fr > 15:
                    pitch_score -= 5
                    pitch_issues.append(f"ğŸŸ¡ å³é½¿é¢å¾„å‘è·³åŠ¨Fråå¤§({pitch_right.Fr:.2f}Î¼m)")
            
            scores.append(max(0, pitch_score))
            report['pitch_analysis']['score'] = max(0, pitch_score)
            report['pitch_analysis']['issues'] = pitch_issues
            report['detailed_diagnosis']['pitch'] = pitch_diagnosis
            
            # ========== 4. é¢‘è°±åˆ†ææ™ºèƒ½è¯Šæ–­ ==========
            spectrum_score = 100
            spectrum_issues = []
            spectrum_diagnosis = {}
            ze = gear_params.teeth_count if gear_params else 87
            
            for name in ['profile_left', 'profile_right', 'helix_left', 'helix_right']:
                if name in results and results[name]:
                    result = results[name]
                    sorted_components = sorted(result.spectrum_components[:15], key=lambda c: c.order)
                    
                    # ZEä¸»å¯¼é˜¶æ¬¡åˆ†æ
                    ze_amp = 0
                    for comp in sorted_components:
                        if abs(comp.order - ze) < 1:
                            ze_amp = comp.amplitude
                            break
                    
                    if ze_amp > 0.15:
                        spectrum_score -= 15
                        spectrum_issues.append(f"ğŸ”´ {name_mapping.get(name, name)}ä¸»å¯¼é˜¶æ¬¡ZEå¹…å€¼ä¸¥é‡åé«˜({ze_amp:.4f}Î¼m)")
                        spectrum_diagnosis[name] = {'ze_severity': 'critical'}
                    elif ze_amp > 0.1:
                        spectrum_score -= 10
                        spectrum_issues.append(f"ğŸŸ  {name_mapping.get(name, name)}ä¸»å¯¼é˜¶æ¬¡ZEå¹…å€¼åé«˜({ze_amp:.4f}Î¼m)")
                        spectrum_diagnosis[name] = {'ze_severity': 'warning'}
                    elif ze_amp > 0.05:
                        spectrum_score -= 5
                        spectrum_issues.append(f"ğŸŸ¡ {name_mapping.get(name, name)}ä¸»å¯¼é˜¶æ¬¡ZEå¹…å€¼ç•¥é«˜({ze_amp:.4f}Î¼m)")
                    
                    # 2ZEåˆ†æ - åå¿ƒ/æ¤­åœ†åº¦
                    ze2_amp = 0
                    for comp in sorted_components:
                        if abs(comp.order - 2*ze) < 1:
                            ze2_amp = comp.amplitude
                            break
                    
                    if ze2_amp > 0.08:
                        spectrum_score -= 10
                        spectrum_issues.append(f"ğŸŸ  {name_mapping.get(name, name)}2å€é¢‘å¹…å€¼åé«˜({ze2_amp:.4f}Î¼m)ï¼Œå¯èƒ½å­˜åœ¨åå¿ƒ")
                        spectrum_diagnosis.setdefault(name, {})['eccentricity'] = True
            
            scores.append(max(0, spectrum_score))
            report['spectrum_analysis']['score'] = max(0, spectrum_score)
            report['spectrum_analysis']['issues'] = spectrum_issues
            report['detailed_diagnosis']['spectrum'] = spectrum_diagnosis
            
            # ========== 5. è®¡ç®—ç»¼åˆè¯„åˆ† ==========
            overall_score = np.mean(scores) if scores else 100
            report['overall_score'] = overall_score
            
            # ========== 6. æ™ºèƒ½çŠ¶æ€åˆ¤æ–­ ==========
            if overall_score >= 95:
                report['status'] = 'ä¼˜ç§€'
                report['status_color'] = 'green'
                report['noise_prediction'] = 'å¾ˆä½'
                report['quality_grade'] = 'Q5'
            elif overall_score >= 85:
                report['status'] = 'è‰¯å¥½'
                report['status_color'] = 'lightgreen'
                report['noise_prediction'] = 'ä½'
                report['quality_grade'] = 'Q6'
            elif overall_score >= 70:
                report['status'] = 'åˆæ ¼'
                report['status_color'] = 'yellow'
                report['noise_prediction'] = 'ä¸­ç­‰'
                report['quality_grade'] = 'Q7'
            elif overall_score >= 50:
                report['status'] = 'éœ€å…³æ³¨'
                report['status_color'] = 'orange'
                report['noise_prediction'] = 'é«˜'
                report['quality_grade'] = 'Q8'
            else:
                report['status'] = 'ä¸åˆæ ¼'
                report['status_color'] = 'red'
                report['noise_prediction'] = 'å¾ˆé«˜'
                report['quality_grade'] = 'Q9+'
            
            # ========== 7. æ™ºèƒ½åŸå› åˆ†æ ==========
            all_issues = profile_issues + helix_issues + pitch_issues + spectrum_issues
            report['issues'] = all_issues
            
            diagnosis = report['detailed_diagnosis']
            
            # é½¿å½¢é—®é¢˜åŸå› 
            if any('FÎ±' in issue for issue in all_issues):
                if diagnosis.get('profile', {}).get('left', {}).get('pressure_angle') == 'severe' or \
                   diagnosis.get('profile', {}).get('right', {}).get('pressure_angle') == 'severe':
                    report['causes'].append("ğŸ”§ å‹åŠ›è§’è¯¯å·®ä¸¥é‡ï¼šåˆ€å…·é½¿å½¢è§’è¯¯å·®å¤§æˆ–ç ‚è½®ä¿®æ•´è§’åº¦ä¸æ­£ç¡®")
                else:
                    report['causes'].append("ğŸ”§ é½¿å½¢è¯¯å·®ï¼šå¯èƒ½ç”±åˆ€å…·ç£¨æŸã€ç ‚è½®ä¿®æ•´ä¸è‰¯æˆ–åŠ å·¥å‚æ•°ä¸å½“å¼•èµ·")
            
            if any('å‹åŠ›è§’' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ å‹åŠ›è§’åå·®ï¼šæ£€æŸ¥åˆ€å…·/ç ‚è½®çš„é½¿å½¢è§’ï¼Œè°ƒæ•´åŠ å·¥å‚æ•°")
            
            if any('ffÎ±' in issue for issue in all_issues) or any('æ³¢çº¹' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ é½¿é¢æ³¢çº¹ï¼šå¯èƒ½ç”±ç£¨å‰ŠæŒ¯åŠ¨ã€ç ‚è½®ä¸å¹³è¡¡æˆ–ä¸»è½´è·³åŠ¨å¼•èµ·")
            
            # é½¿å‘é—®é¢˜åŸå› 
            if any('FÎ²' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ é½¿å‘è¯¯å·®ï¼šå¯èƒ½ç”±æœºåºŠå¯¼è½¨è¯¯å·®ã€å·¥ä»¶è£…å¤¹å˜å½¢æˆ–çƒ­å˜å½¢å¼•èµ·")
            
            if any('èºæ—‹è§’' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ èºæ—‹è§’åå·®ï¼šæ£€æŸ¥å·®åŠ¨æŒ‚è½®è®¡ç®—ï¼Œè°ƒæ•´æœºåºŠèºæ—‹è§’è®¾ç½®")
            
            # å‘¨èŠ‚é—®é¢˜åŸå› 
            if any('fp' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ é½¿è·è¯¯å·®ï¼šå¯èƒ½ç”±åˆ†åº¦æœºæ„è¯¯å·®ã€åˆ€å…·è¯¯å·®æˆ–å·¥ä»¶åå¿ƒå¼•èµ·")
            
            if any('Fp' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ é½¿è·ç´¯ç§¯è¯¯å·®ï¼šæ£€æŸ¥åˆ†åº¦ç›˜ç²¾åº¦ï¼Œæ£€æŸ¥å·¥ä»¶å®‰è£…åå¿ƒ")
            
            if any('Fr' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ å¾„å‘è·³åŠ¨ï¼šå¯èƒ½ç”±å·¥ä»¶å®‰è£…åå¿ƒã€è½´æ‰¿é—´éš™æˆ–ä¸»è½´è·³åŠ¨å¼•èµ·")
            
            # é¢‘è°±é—®é¢˜åŸå› 
            if any('ZE' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ ä¸»å¯¼é˜¶æ¬¡å¼‚å¸¸ï¼šåˆ†åº¦è¯¯å·®æˆ–åˆ€å…·è¯¯å·®å¯¼è‡´")
            
            if any('åå¿ƒ' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ åå¿ƒé—®é¢˜ï¼šæ£€æŸ¥å·¥ä»¶å®‰è£…åå¿ƒé‡å’Œå†…å­”ç²¾åº¦")
            
            # ä¸€è‡´æ€§é—®é¢˜
            if any('ä¸ä¸€è‡´' in issue for issue in all_issues):
                report['causes'].append("ğŸ”§ å„é½¿åå·®ä¸ä¸€è‡´ï¼šæ£€æŸ¥åŠ å·¥è¿‡ç¨‹ç¨³å®šæ€§ï¼Œæ£€æŸ¥å¤¹ç´§åŠ›æ˜¯å¦å‡åŒ€")
            
            if not report['causes']:
                report['causes'].append("âœ… é½¿è½®å„é¡¹æŒ‡æ ‡æ­£å¸¸ï¼ŒåŠ å·¥è´¨é‡è‰¯å¥½")
            
            # ========== 8. æ™ºèƒ½æ”¹è¿›å»ºè®® ==========
            if overall_score < 60:
                report['recommendations'].append("âš ï¸ å»ºè®®ç«‹å³åœæœºæ£€æŸ¥ï¼Œå…¨é¢æ’æŸ¥åŠ å·¥è®¾å¤‡ç²¾åº¦")
            elif overall_score < 80:
                report['recommendations'].append("ğŸ“‹ å»ºè®®å…¨é¢æ£€æŸ¥åŠ å·¥æœºåºŠç²¾åº¦å’Œåˆ€å…·çŠ¶æ€")
            
            # é½¿å½¢æ”¹è¿›
            if any('FÎ±' in issue or 'å‹åŠ›è§’' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ é½¿å½¢ä¼˜åŒ–ï¼šæ£€æŸ¥åˆ€å…·/ç ‚è½®ç£¨æŸï¼Œé‡æ–°ä¿®æ•´ç ‚è½®ï¼Œè°ƒæ•´åŠ å·¥å‚æ•°")
            
            if any('ffÎ±' in issue or 'æ³¢çº¹' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ å‡å°‘æ³¢çº¹ï¼šæ£€æŸ¥ç ‚è½®å¹³è¡¡ï¼Œæ£€æŸ¥ä¸»è½´ç²¾åº¦ï¼Œé™ä½ç£¨å‰Šç”¨é‡")
            
            # é½¿å‘æ”¹è¿›
            if any('FÎ²' in issue or 'èºæ—‹è§’' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ é½¿å‘ä¼˜åŒ–ï¼šæ£€æŸ¥å¯¼è½¨ç²¾åº¦ï¼Œæ ¡å‡†èºæ—‹è§’è®¾ç½®ï¼Œæ”¹å–„è£…å¤¹æ–¹å¼")
            
            # å‘¨èŠ‚æ”¹è¿›
            if any('fp' in issue or 'Fp' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ é½¿è·ä¼˜åŒ–ï¼šæ£€æŸ¥åˆ†åº¦æœºæ„ç²¾åº¦ï¼Œæ ¡å‡†åˆ†åº¦ç›˜ï¼Œæ£€æŸ¥èœ—è½®èœ—æ†ç£¨æŸ")
            
            if any('Fr' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ é™ä½è·³åŠ¨ï¼šæ”¹å–„å·¥ä»¶è£…å¤¹ï¼Œæ£€æŸ¥å¤¹å…·ç²¾åº¦ï¼Œæ£€æŸ¥ä¸»è½´è½´æ‰¿")
            
            # é¢‘è°±æ”¹è¿›
            if any('ZE' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ é™ä½ä¸»å¯¼é˜¶æ¬¡ï¼šä¼˜åŒ–åˆ†åº¦ç²¾åº¦ï¼Œæ£€æŸ¥åˆ€å…·/ç ‚è½®çŠ¶æ€")
            
            if any('åå¿ƒ' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ æ¶ˆé™¤åå¿ƒï¼šé‡æ–°å®‰è£…å·¥ä»¶ï¼Œæ£€æŸ¥å†…å­”ä¸å¿ƒè½´é…åˆ")
            
            # ä¸€è‡´æ€§æ”¹è¿›
            if any('ä¸ä¸€è‡´' in issue for issue in all_issues):
                report['recommendations'].append("ğŸ“ æé«˜ä¸€è‡´æ€§ï¼šæ£€æŸ¥å¤¹ç´§åŠ›å‡åŒ€æ€§ï¼Œæ£€æŸ¥åŠ å·¥è¿‡ç¨‹ç¨³å®šæ€§")
            
            if not report['recommendations']:
                report['recommendations'].append("âœ… ç»§ç»­ä¿æŒå½“å‰åŠ å·¥å·¥è‰ºï¼Œå®šæœŸç›‘æµ‹è´¨é‡")
            
            return report
        
        # ç”ŸæˆæŠ¥å‘Š
        comprehensive_report = generate_comprehensive_analysis()
        
        # ========== ç»¼åˆè¯„ä¼°ä»ªè¡¨æ¿ ==========
        st.markdown(f"""
        <div class="card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; margin-bottom: 1.5rem;">
            <div style="text-align: center; padding: 1.5rem;">
                <div style="font-size: 3.5rem; font-weight: 700;">{comprehensive_report['overall_score']:.0f}</div>
                <div style="font-size: 1rem; opacity: 0.9;">ç»¼åˆè¯„åˆ†</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # çŠ¶æ€å¡ç‰‡
        col1, col2, col3 = st.columns(3)
        
        status_color = comprehensive_report['status_color']
        status_text = comprehensive_report['status']
        
        with col1:
            status_class = 'status-excellent' if status_text in ['ä¼˜ç§€', 'è‰¯å¥½'] else 'status-warning' if status_text in ['åˆæ ¼', 'éœ€å…³æ³¨'] else 'status-danger'
            st.markdown(f"""
            <div class="card" style="text-align: center;">
                <div style="font-size: 0.9rem; color: #6b7280; margin-bottom: 0.5rem;">é½¿è½®çŠ¶æ€</div>
                <div class="{status_class}" style="display: inline-block;">{status_text}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="card" style="text-align: center;">
                <div style="font-size: 0.9rem; color: #6b7280; margin-bottom: 0.5rem;">è´¨é‡ç­‰çº§</div>
                <div style="font-size: 1.5rem; font-weight: 700; color: #1f2937;">{comprehensive_report['quality_grade']}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            noise = comprehensive_report['noise_prediction']
            noise_icon = 'ğŸ”‡' if noise == 'å¾ˆä½' else 'ğŸ”ˆ' if noise == 'ä½' else 'ğŸ”‰' if noise == 'ä¸­ç­‰' else 'ğŸ”Š'
            noise_class = 'status-excellent' if noise in ['å¾ˆä½', 'ä½'] else 'status-warning' if noise == 'ä¸­ç­‰' else 'status-danger'
            st.markdown(f"""
            <div class="card" style="text-align: center;">
                <div style="font-size: 0.9rem; color: #6b7280; margin-bottom: 0.5rem;">å™ªå£°é¢„æµ‹</div>
                <div class="{noise_class}" style="display: inline-block;">{noise_icon} {noise}</div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ========== åˆ†é¡¹è¯„åˆ†ä»ªè¡¨æ¿ ==========
        st.markdown("### ğŸ“Š åˆ†é¡¹è¯„åˆ†è¯¦æƒ…")
        
        profile_score = comprehensive_report['profile_analysis'].get('score', 100)
        helix_score = comprehensive_report['helix_analysis'].get('score', 100)
        pitch_score = comprehensive_report['pitch_analysis'].get('score', 100)
        spectrum_score = comprehensive_report['spectrum_analysis'].get('score', 100)
        
        score_cols = st.columns(4)
        
        with score_cols[0]:
            color = '#10b981' if profile_score >= 85 else '#f59e0b' if profile_score >= 70 else '#ef4444'
            st.markdown(f"""
            <div class="card" style="border-left: 4px solid {color};">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <div>
                        <div style="font-size: 0.85rem; color: #6b7280;">é½¿å½¢åå·®</div>
                        <div style="font-size: 1.8rem; font-weight: 700; color: {color};">{profile_score:.0f}<span style="font-size: 0.9rem; color: #9ca3af;">/100</span></div>
                    </div>
                    <div style="font-size: 2rem;">ğŸ“Š</div>
                </div>
                <div style="margin-top: 0.5rem; background: #e5e7eb; border-radius: 4px; height: 6px;">
                    <div style="background: {color}; border-radius: 4px; height: 100%; width: {profile_score}%;"></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        with score_cols[1]:
            color = '#10b981' if helix_score >= 85 else '#f59e0b' if helix_score >= 70 else '#ef4444'
            st.markdown(f"""
            <div class="card" style="border-left: 4px solid {color};">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <div>
                        <div style="font-size: 0.85rem; color: #6b7280;">é½¿å‘åå·®</div>
                        <div style="font-size: 1.8rem; font-weight: 700; color: {color};">{helix_score:.0f}<span style="font-size: 0.9rem; color: #9ca3af;">/100</span></div>
                    </div>
                    <div style="font-size: 2rem;">ğŸ“</div>
                </div>
                <div style="margin-top: 0.5rem; background: #e5e7eb; border-radius: 4px; height: 6px;">
                    <div style="background: {color}; border-radius: 4px; height: 100%; width: {helix_score}%;"></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        with score_cols[2]:
            color = '#10b981' if pitch_score >= 85 else '#f59e0b' if pitch_score >= 70 else '#ef4444'
            st.markdown(f"""
            <div class="card" style="border-left: 4px solid {color};">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <div>
                        <div style="font-size: 0.85rem; color: #6b7280;">å‘¨èŠ‚åå·®</div>
                        <div style="font-size: 1.8rem; font-weight: 700; color: {color};">{pitch_score:.0f}<span style="font-size: 0.9rem; color: #9ca3af;">/100</span></div>
                    </div>
                    <div style="font-size: 2rem;">âš™ï¸</div>
                </div>
                <div style="margin-top: 0.5rem; background: #e5e7eb; border-radius: 4px; height: 6px;">
                    <div style="background: {color}; border-radius: 4px; height: 100%; width: {pitch_score}%;"></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        with score_cols[3]:
            color = '#10b981' if spectrum_score >= 85 else '#f59e0b' if spectrum_score >= 70 else '#ef4444'
            st.markdown(f"""
            <div class="card" style="border-left: 4px solid {color};">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <div>
                        <div style="font-size: 0.85rem; color: #6b7280;">é¢‘è°±åˆ†æ</div>
                        <div style="font-size: 1.8rem; font-weight: 700; color: {color};">{spectrum_score:.0f}<span style="font-size: 0.9rem; color: #9ca3af;">/100</span></div>
                    </div>
                    <div style="font-size: 2rem;">ğŸ“ˆ</div>
                </div>
                <div style="margin-top: 0.5rem; background: #e5e7eb; border-radius: 4px; height: 6px;">
                    <div style="background: {color}; border-radius: 4px; height: 100%; width: {spectrum_score}%;"></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ========== é—®é¢˜è¯Šæ–­ ==========
        st.markdown("### ğŸ” é—®é¢˜è¯Šæ–­")
        
        if comprehensive_report['issues']:
            # åˆ†ç±»æ˜¾ç¤ºé—®é¢˜
            critical_issues = [i for i in comprehensive_report['issues'] if 'ğŸ”´' in i]
            warning_issues = [i for i in comprehensive_report['issues'] if 'ğŸŸ ' in i]
            info_issues = [i for i in comprehensive_report['issues'] if 'ğŸŸ¡' in i]
            success_issues = [i for i in comprehensive_report['issues'] if 'âœ…' in i]
            
            if critical_issues:
                st.markdown("<div style='font-weight: 600; color: #ef4444; margin-bottom: 0.5rem;'>âš ï¸ ä¸¥é‡é—®é¢˜</div>", unsafe_allow_html=True)
                for issue in critical_issues:
                    st.markdown(f"<div class='issue-critical'>{issue}</div>", unsafe_allow_html=True)
            
            if warning_issues:
                st.markdown("<div style='font-weight: 600; color: #f59e0b; margin-bottom: 0.5rem; margin-top: 1rem;'>âš¡ è­¦å‘Šé—®é¢˜</div>", unsafe_allow_html=True)
                for issue in warning_issues:
                    st.markdown(f"<div class='issue-warning'>{issue}</div>", unsafe_allow_html=True)
            
            if info_issues:
                st.markdown("<div style='font-weight: 600; color: #06b6d4; margin-bottom: 0.5rem; margin-top: 1rem;'>â„¹ï¸ æç¤ºä¿¡æ¯</div>", unsafe_allow_html=True)
                for issue in info_issues:
                    st.markdown(f"<div class='issue-info'>{issue}</div>", unsafe_allow_html=True)
            
            if success_issues:
                st.markdown("<div style='font-weight: 600; color: #10b981; margin-bottom: 0.5rem; margin-top: 1rem;'>âœ… æ­£å¸¸çŠ¶æ€</div>", unsafe_allow_html=True)
                for issue in success_issues:
                    st.markdown(f"<div class='issue-success'>{issue}</div>", unsafe_allow_html=True)
        else:
            st.markdown("<div class='issue-success'>âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼Œé½¿è½®çŠ¶æ€è‰¯å¥½</div>", unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ========== åŸå› åˆ†æ ==========
        st.markdown("### ğŸ”¬ åŸå› åˆ†æ")
        
        causes = comprehensive_report['causes']
        for cause in causes:
            st.markdown(f"- {cause}")
        
        st.markdown("---")
        
        # ========== æ”¹è¿›å»ºè®® ==========
        st.markdown("### ğŸ’¡ æ”¹è¿›å»ºè®®")
        
        recommendations = comprehensive_report['recommendations']
        for rec in recommendations:
            st.markdown(f"- {rec}")
        
        # ========== è¯¦ç»†æ•°æ® ==========
        with st.expander("ğŸ“Š è¯¦ç»†åˆ†ææ•°æ®", expanded=False):
            # é½¿å½¢æ•°æ®
            if comprehensive_report['profile_analysis']:
                st.markdown("**é½¿å½¢åå·®æ•°æ®:**")
                profile_df_data = []
                for side, data in comprehensive_report['profile_analysis'].items():
                    if isinstance(data, dict) and 'avg_FÎ±' in data:
                        profile_df_data.append({
                            'é½¿é¢': 'å·¦é½¿é¢' if side == 'left' else 'å³é½¿é¢',
                            'FÎ± (Î¼m)': f"{data['avg_FÎ±']:.2f}",
                            'fHÎ± (Î¼m)': f"{data['avg_fHÎ±']:.2f}",
                            'ffÎ± (Î¼m)': f"{data['avg_ffÎ±']:.2f}"
                        })
                if profile_df_data:
                    st.dataframe(pd.DataFrame(profile_df_data), use_container_width=True, hide_index=True)
            
            # é½¿å‘æ•°æ®
            if comprehensive_report['helix_analysis']:
                st.markdown("**é½¿å‘åå·®æ•°æ®:**")
                helix_df_data = []
                for side, data in comprehensive_report['helix_analysis'].items():
                    if isinstance(data, dict) and 'avg_FÎ²' in data:
                        helix_df_data.append({
                            'é½¿é¢': 'å·¦é½¿é¢' if side == 'left' else 'å³é½¿é¢',
                            'FÎ² (Î¼m)': f"{data['avg_FÎ²']:.2f}",
                            'fHÎ² (Î¼m)': f"{data['avg_fHÎ²']:.2f}",
                            'ffÎ² (Î¼m)': f"{data['avg_ffÎ²']:.2f}"
                        })
                if helix_df_data:
                    st.dataframe(pd.DataFrame(helix_df_data), use_container_width=True, hide_index=True)
            
            # å‘¨èŠ‚æ•°æ®
            if comprehensive_report['pitch_analysis']:
                st.markdown("**å‘¨èŠ‚åå·®æ•°æ®:**")
                pitch_df_data = []
                for side, data in comprehensive_report['pitch_analysis'].items():
                    if isinstance(data, dict) and 'fp_max' in data:
                        pitch_df_data.append({
                            'é½¿é¢': 'å·¦é½¿é¢' if side == 'left' else 'å³é½¿é¢',
                            'fp max (Î¼m)': f"{data['fp_max']:.2f}",
                            'Fp max (Î¼m)': f"{data['Fp_max']:.2f}",
                            'Fr (Î¼m)': f"{data['Fr']:.2f}"
                        })
                if pitch_df_data:
                    st.dataframe(pd.DataFrame(pitch_df_data), use_container_width=True, hide_index=True)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(temp_path):
        os.remove(temp_path)

else:
    # ========== æ¬¢è¿é¡µé¢ ==========
    st.markdown("""
    <div style="text-align: center; padding: 2rem;">
        <h1 class="main-title">âš™ï¸ é½¿è½®æµ‹é‡åˆ†æç³»ç»Ÿ</h1>
        <p style="font-size: 1.2rem; color: #666;">ä¸“ä¸šç‰ˆ - é½¿è½®æ³¢çº¹åº¦åˆ†æä¸è´¨é‡è¯„ä¼°</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # åŠŸèƒ½å¡ç‰‡
    st.markdown("### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="card">
            <div class="card-header">ğŸ“Š åå·®åˆ†æ</div>
            <ul style="list-style: none; padding: 0;">
                <li>âœ… é½¿å½¢åå·® FÎ± åˆ†æ</li>
                <li>âœ… é½¿å‘åå·® FÎ² åˆ†æ</li>
                <li>âœ… å‘¨èŠ‚åå·® fp/Fp åˆ†æ</li>
                <li>âœ… å¾„å‘è·³åŠ¨ Fr åˆ†æ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="card">
            <div class="card-header">ğŸ“ˆ é¢‘è°±åˆ†æ</div>
            <ul style="list-style: none; padding: 0;">
                <li>âœ… é˜¶æ¬¡æŒ¯å¹…åˆ†æ</li>
                <li>âœ… æé™æ›²çº¿è¯„ä¼°</li>
                <li>âœ… ä¸»å¯¼é˜¶æ¬¡è¯†åˆ«</li>
                <li>âœ… æ³¢çº¹åº¦è¯„ä»·</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="card">
            <div class="card-header">ğŸ¤– AIæ™ºèƒ½åˆ†æ</div>
            <ul style="list-style: none; padding: 0;">
                <li>âœ… ç»¼åˆè´¨é‡è¯„åˆ†</li>
                <li>âœ… é—®é¢˜æ™ºèƒ½è¯Šæ–­</li>
                <li>âœ… åŸå› æ·±åº¦åˆ†æ</li>
                <li>âœ… æ”¹è¿›å»ºè®®ç”Ÿæˆ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ä½¿ç”¨è¯´æ˜
    st.markdown("### ğŸ“‹ ä½¿ç”¨è¯´æ˜")
    
    st.markdown("""
    <div class="card">
        <div style="display: flex; align-items: center; margin-bottom: 1rem;">
            <div style="background: #1f77b4; color: white; width: 30px; height: 30px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 1rem;">1</div>
            <div><b>ä¸Šä¼ æ•°æ®</b> - åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼  MKA æ ¼å¼çš„é½¿è½®æµ‹é‡æ•°æ®æ–‡ä»¶</div>
        </div>
        <div style="display: flex; align-items: center; margin-bottom: 1rem;">
            <div style="background: #1f77b4; color: white; width: 30px; height: 30px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 1rem;">2</div>
            <div><b>é€‰æ‹©åŠŸèƒ½</b> - åœ¨å·¦ä¾§å¯¼èˆªæ é€‰æ‹©éœ€è¦ä½¿ç”¨çš„åˆ†æåŠŸèƒ½</div>
        </div>
        <div style="display: flex; align-items: center; margin-bottom: 1rem;">
            <div style="background: #1f77b4; color: white; width: 30px; height: 30px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 1rem;">3</div>
            <div><b>æŸ¥çœ‹æŠ¥å‘Š</b> - ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œæ”¯æŒPDFå¯¼å‡º</div>
        </div>
        <div style="display: flex; align-items: center;">
            <div style="background: #1f77b4; color: white; width: 30px; height: 30px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 1rem;">4</div>
            <div><b>AIåˆ†æ</b> - æŸ¥çœ‹AIç»¼åˆåˆ†ææŠ¥å‘Šï¼Œè·å–è´¨é‡è¯„ä¼°å’Œæ”¹è¿›å»ºè®®</div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # æŠ€æœ¯è§„æ ¼
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### ğŸ“ æ”¯æŒæ ‡å‡†
        - GB/T 10095.1-2008
        - ISO 1328-1:2014
        - DIN 3962
        - AGMA 2015-1-A01
        """)
    
    with col2:
        st.markdown("""
        #### ğŸ“ æ”¯æŒæ ¼å¼
        - Klingelnberg MKA æ ¼å¼
        - é½¿è½®æ³¢çº¹åº¦æ•°æ®
        - é½¿å½¢/é½¿å‘æµ‹é‡æ•°æ®
        - å‘¨èŠ‚æµ‹é‡æ•°æ®
        """)
    
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
        <p>é½¿è½®æ³¢çº¹åº¦åˆ†æç³»ç»Ÿ ä¸“ä¸šç‰ˆ | åŸºäº Python + Streamlit æ„å»º</p>
        <p style="font-size: 0.8rem;">Â© 2024 Gear Measurement Analysis System</p>
    </div>
    """, unsafe_allow_html=True)
